{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6d40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from technicals.indicators import *\n",
    "from technicals.patterns import apply_patterns\n",
    "from technicals.patternsInRange import apply_patterns_in_range\n",
    "from guruTester import GuruTester,GuruTester2\n",
    "from plotting import CandlePlot\n",
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime\n",
    "from getCandle import Rates\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be830d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(df):\n",
    "    candle_patterns = ['HANGING_MAN', 'SHOOTING_STAR',\n",
    "           'SPINNING_TOP', 'MARUBOZU', 'ENGULFING', 'TWEEZER_TOP',\n",
    "           'TWEEZER_BOTTOM', 'MORNING_STAR', 'EVENING_STAR']\n",
    "    df = apply_patterns_in_range(df)\n",
    "    for cp in candle_patterns:\n",
    "        df[cp] = df[cp].astype(float)\n",
    "\n",
    "    df = BollingerBandsFeature(df)\n",
    "    df = ATRFeature(df)\n",
    "    df = KeltnerChannelsFeature(df)\n",
    "    df = RSIFeature(df)\n",
    "    df = MACDFeature(df)\n",
    "    df['pivots_l'] = False\n",
    "    df['pivots_h'] = False\n",
    "\n",
    "    df['low_perv'] = df.low.shift(1)\n",
    "    df['high_perv'] = df.high.shift(1)\n",
    "    df['low_next'] = df.low.shift(-1)\n",
    "    df['high_next'] = df.high.shift(-1)\n",
    "    df['pivots_l'] = (df.low_perv > df.low) & (df.low_next > df.low)\n",
    "    df['pivots_h'] = (df.high_perv < df.high) & (df.high_next < df.high)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.pivots_l = df.pivots_l.astype(float)\n",
    "    df.pivots_h = df.pivots_h.astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652f688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY = 2\n",
    "SELL = 0\n",
    "NONE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573d9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(df):\n",
    "    df['SIGNAL_LABEL'] = NONE\n",
    "    df['TP'] = 0\n",
    "    df['SL'] = 0\n",
    "    \n",
    "    for i in range(1,len(df)):\n",
    "        if df.pivots_l[i-1]:\n",
    "            for j in range(i,len(df)):\n",
    "                if( df.low[j] <= df.low[i-1] ):\n",
    "                    break\n",
    "                else:\n",
    "                    if(df.high[j] > 2*(df.close[i] - df.low[i-1] ) + df.close[i]):\n",
    "                        df.SIGNAL_LABEL[i] = BUY\n",
    "                        break\n",
    "\n",
    "            df['SL'][i] = df.low[i-1] \n",
    "            df['TP'][i] = 2*(df.close[i] - df.low[i-1] ) + df.close[i]\n",
    "        if df.pivots_h[i-1]:\n",
    "            for j in range(i,len(df)):\n",
    "                if( df.high[j] >= df.high[i-1] ):\n",
    "                    break\n",
    "                else:\n",
    "                    if(df.low[j] < 2*(df.close[i] - df.high[i-1] ) + df.close[i]):\n",
    "                        df.SIGNAL_LABEL[i] = SELL\n",
    "                        break\n",
    "            df['SL'][i] = df.high[i-1] \n",
    "            df['TP'][i] = 2*(df.close[i] - df.high[i-1] ) + df.close[i]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe8df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"GBPUSD\"\n",
    "NB_H1_CANDLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39ffb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.000000000014552e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates = Rates(pair, NB_H1_CANDLES, mt5.TIMEFRAME_H1)\n",
    "SPREAD = rates.get_spread()\n",
    "df_an = rates.get_rates_from_now()\n",
    "df_an.drop(NB_H1_CANDLES-1,inplace=True) \n",
    "df_an.drop(['tick_volume', 'spread', 'real_volume'], axis=1, inplace=True)\n",
    "SPREAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17728150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPREAD = (SPREAD//1e-5)*1e-5 # todo: do it right!!!\n",
    "SPREAD # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a331cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIT_INDEX = int(0.8*len(df_an))\n",
    "df_train = df_an.iloc[:SLIT_INDEX]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test = df_an.iloc[SLIT_INDEX:]\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a11d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = Rates(pair, 13*len(df_test), mt5.TIMEFRAME_M5)\n",
    "df_m5 = rates.get_rates_from_now()\n",
    "df_m5.reset_index(drop=True, inplace=True)\n",
    "df_m5.drop(['tick_volume', 'spread', 'real_volume'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe0b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SL'][i] = df.high[i-1]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TP'][i] = 2*(df.close[i] - df.high[i-1] ) + df.close[i]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.SIGNAL_LABEL[i] = SELL\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.SIGNAL_LABEL[i] = BUY\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SL'][i] = df.low[i-1]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TP'][i] = 2*(df.close[i] - df.low[i-1] ) + df.close[i]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.SIGNAL_LABEL[i] = SELL\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_9984\\757576024.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.SIGNAL_LABEL[i] = BUY\n"
     ]
    }
   ],
   "source": [
    "df_train = featureExtraction(df_train)\n",
    "df_train = labeling(df_train)\n",
    "df_test = featureExtraction(df_test)\n",
    "df_test = labeling(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d54344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3966"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37fc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    \n",
    "    'Feat_BB_MA_c', 'Feat_BB_UP_c', 'Feat_BB_LW_c',\n",
    "    'Feat_EMA_c', 'Feat_KeUp_c', 'Feat_KeLo_c',\n",
    "    \n",
    "    'Feat_BB_MA_o', 'Feat_BB_UP_o', 'Feat_BB_LW_o',\n",
    "    'Feat_EMA_o', 'Feat_KeUp_o', 'Feat_KeLo_o', \n",
    "    \n",
    "    'Feat_BB_MA_l', 'Feat_BB_UP_l', 'Feat_BB_LW_l',\n",
    "    'Feat_EMA_l', 'Feat_KeUp_l', 'Feat_KeLo_l',\n",
    "    \n",
    "    'Feat_BB_MA_h', 'Feat_BB_UP_h', 'Feat_BB_LW_h',\n",
    "    'Feat_EMA_h', 'Feat_KeUp_h', 'Feat_KeLo_h',\n",
    "    \n",
    "    'Feat_ATR_14',\n",
    "    'Feat_gains','Feat_wins_rma', 'Feat_losses_rma', 'Feat_RSI_14', \n",
    "#     'Feat_MACD', 'Feat_SIGNAL_MACD', 'Feat_HIST',\n",
    "    \n",
    "        'full_range',# this is added ...\n",
    "       'body_lower', 'body_upper', \n",
    "        'body_bottom_perc', 'body_top_perc',\n",
    "       'body_perc', 'direction', 'body_size', 'low_change', 'high_change',\n",
    "    'mid_point', 'mid_point_prev_2', 'body_size_prev',\n",
    "       'direction_prev', 'direction_prev_2', 'body_perc_prev','body_perc_prev_2',\n",
    "        'HANGING_MAN', 'SHOOTING_STAR', 'SPINNING_TOP',\n",
    "       'MARUBOZU', 'ENGULFING',\n",
    "    'TWEEZER_TOP', 'TWEEZER_BOTTOM',\n",
    "       'MORNING_STAR', 'EVENING_STAR'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c37528b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, batch_size, input_size, hidden_dim,lstm_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.LSTM_layers = lstm_layers\n",
    "    \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=self.hidden_dim, num_layers=self.LSTM_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_dim, out_features=3)\n",
    "#         self.fc2 = nn.Linear(257, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim))\n",
    "        c = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim))\n",
    "        torch.nn.init.xavier_normal_(h)\n",
    "        torch.nn.init.xavier_normal_(c)\n",
    "        out, (hidden, cell) = self.lstm(x, (h,c))\n",
    "#         out = self.dropout(out)\n",
    "        out = self.fc(out[:,-1,:]) \n",
    "#         out = torch.sigmoid(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39a96dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,df,sequence_lenght,feature_col):\n",
    "        self.df = df\n",
    "        self.sequence_lenght = sequence_lenght\n",
    "        self.feature_col = feature_col\n",
    "        self.X = []\n",
    "        self.Y = [] \n",
    "        self.indeces = []\n",
    "        print(\"preparing data..\")\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        for i in range(self.sequence_lenght+1,len(self.df)):\n",
    "            if self.df.pivots_h[i-1] or self.df.pivots_l[i-1]:\n",
    "                X_feat = [] \n",
    "                for j in range(self.sequence_lenght):\n",
    "                    feature = []\n",
    "                    feature.append(self.df.pivots_h[i-self.sequence_lenght+j])\n",
    "                    feature.append(self.df.pivots_l[i-self.sequence_lenght+j])\n",
    "                    for fc in self.feature_col:\n",
    "                        feature.append(self.df[fc][i-self.sequence_lenght+j+1])\n",
    "                        \n",
    "                    X_feat.append(feature)  \n",
    "                self.X.append(np.array(X_feat))# TODO: use torch tensor \n",
    "                self.Y.append(self.df.SIGNAL_LABEL[i])\n",
    "                self.indeces.append(i)\n",
    "                \n",
    "    def get_feature_len(self):\n",
    "        return self.X[0].shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return torch.from_numpy(self.X[index]).float(),self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb561ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd456bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "batch_size = 600\n",
    "sequence_lenght = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2495bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data..\n",
      "preparing data..\n"
     ]
    }
   ],
   "source": [
    "ds_train = dataset(df_train,sequence_lenght,feature_col)\n",
    "ds_test = dataset(df_test,sequence_lenght,feature_col) \n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size)\n",
    "loader_test = DataLoader(ds_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62b50d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "3\n",
      "6860\n",
      "1690\n"
     ]
    }
   ],
   "source": [
    "print(len(loader_train))\n",
    "print(len(loader_test))\n",
    "print(len(ds_train))\n",
    "print(len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db9a1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ds_train.get_feature_len() \n",
    "hidden_dim = 60\n",
    "lstm_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad4e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(batch_size, input_size, hidden_dim,lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b8f4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.Tensor([0.4,0.2,0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17083d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f1e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1cb2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b3e0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0889968574047089 0.6\n",
      "1.078487515449524 0.6\n",
      "1.070744256178538 0.6\n",
      "1.0568132400512695 0.5970414201183432\n",
      "1.0235792150100071 0.5556213017751479\n",
      "0.9527058998743693 0.4863905325443787\n",
      "0.8801776667435964 0.45384615384615384\n",
      "0.8205914547046026 0.4437869822485207\n",
      "0.7788264701763788 0.4319526627218935\n",
      "0.7592440545558929 0.4372781065088757\n",
      "0.7498241563638052 0.4331360946745562\n",
      "0.7427043318748474 0.4349112426035503\n",
      "0.7379875729481379 0.43372781065088756\n",
      "0.7358802060286204 0.44733727810650886\n",
      "0.7340131203333536 0.4396449704142012\n",
      "0.7321237872044245 0.4437869822485207\n",
      "0.7302048802375793 0.4349112426035503\n",
      "0.7291756669680277 0.4502958579881657\n",
      "0.7279917945464452 0.4408284023668639\n",
      "0.7267005443572998 0.45798816568047335\n",
      "0.7255240976810455 0.4650887573964497\n",
      "0.7244363725185394 0.4556213017751479\n",
      "0.722898930311203 0.44970414201183434\n",
      "0.7214390337467194 0.4437869822485207\n",
      "0.7200078219175339 0.4467455621301775\n",
      "0.7186364829540253 0.44497041420118344\n",
      "0.7173129270474116 0.4532544378698225\n",
      "0.7162064164876938 0.47218934911242605\n",
      "0.7157289783159891 0.5023668639053255\n",
      "0.7154053300619125 0.5011834319526627\n",
      "0.7142669608195623 0.4840236686390533\n",
      "0.7115054180224737 0.4526627218934911\n",
      "0.7090360075235367 0.42662721893491123\n",
      "0.7069878280162811 0.43550295857988164\n",
      "0.7049689491589864 0.44497041420118344\n",
      "0.7030128339926401 0.45621301775147927\n",
      "0.701154758532842 0.46272189349112425\n",
      "0.699516624212265 0.46449704142011833\n",
      "0.6973728438218435 0.46568047337278107\n",
      "0.6953619221846262 0.4650887573964497\n",
      "0.6934290925661722 0.4668639053254438\n",
      "0.691511794924736 0.46982248520710057\n",
      "0.6895247449477514 0.4751479289940828\n",
      "0.6874300589164098 0.47455621301775147\n",
      "0.6852500836054484 0.48284023668639053\n",
      "0.6830858141183853 0.4822485207100592\n",
      "0.681029831369718 0.48284023668639053\n",
      "0.6792745093504587 0.48579881656804735\n",
      "0.6781517167886099 0.4840236686390533\n",
      "0.6785672008991241 0.4952662721893491\n",
      "0.6803096681833267 0.5360946745562131\n",
      "0.6776165664196014 0.5207100591715976\n",
      "0.6726576735575994 0.514792899408284\n",
      "0.6763777186473211 0.5414201183431953\n",
      "0.6749852846066157 0.5177514792899408\n",
      "0.675702765583992 0.5668639053254438\n",
      "0.6816039631764094 0.5532544378698225\n",
      "0.6841330826282501 0.5047337278106508\n",
      "0.6710975815852483 0.4390532544378698\n",
      "0.6662229200204214 0.46331360946745564\n",
      "0.663572778304418 0.48284023668639053\n",
      "0.6622262845436732 0.49230769230769234\n",
      "0.6608119060595831 0.4940828402366864\n",
      "0.6584689766168594 0.5011834319526627\n",
      "0.6563134044408798 0.5088757396449705\n",
      "0.6547627697388331 0.51301775147929\n",
      "0.6533193836609522 0.5118343195266272\n",
      "0.6511236280202866 0.5088757396449705\n",
      "0.648130069176356 0.5005917159763313\n",
      "0.6447607974211375 0.49467455621301776\n",
      "0.6420566290616989 0.506508875739645\n",
      "0.6406114349762598 0.5159763313609468\n",
      "0.6388576229413351 0.5402366863905326\n",
      "0.6402276655038198 0.5142011834319526\n",
      "0.6384270439545313 0.5242603550295858\n",
      "0.6303110917409261 0.506508875739645\n",
      "0.6265105406443278 0.5366863905325444\n",
      "0.6267672677834829 0.5449704142011834\n",
      "0.6231756806373596 0.5313609467455621\n",
      "0.6210685968399048 0.5023668639053255\n",
      "0.6190151870250702 0.4976331360946746\n",
      "0.6206095566352209 0.4751479289940828\n",
      "0.6169163982073466 0.4834319526627219\n",
      "0.6135794545213381 0.4893491124260355\n",
      "0.6077951242526373 0.46745562130177515\n",
      "0.6012974008917809 0.48757396449704143\n",
      "0.5910328800479571 0.4834319526627219\n",
      "0.5943609923124313 0.4893491124260355\n",
      "0.6126568814118704 0.4976331360946746\n",
      "0.6039539848764738 0.5029585798816568\n",
      "0.6049063056707382 0.49467455621301776\n",
      "0.6098038206497828 0.4710059171597633\n",
      "0.5948041379451752 0.4751479289940828\n",
      "0.5826898093024889 0.5005917159763313\n",
      "0.5771583467721939 0.49230769230769234\n",
      "0.5812244688471159 0.4822485207100592\n",
      "0.581094354391098 0.4952662721893491\n",
      "0.5702513381838799 0.49230769230769234\n",
      "0.5610931292176247 0.5023668639053255\n",
      "0.5519955704609553 0.5023668639053255\n",
      "0.5581118588646253 0.506508875739645\n",
      "0.557654636601607 0.49940828402366866\n",
      "0.5472288802266121 0.5118343195266272\n",
      "0.5397196312745413 0.4982248520710059\n",
      "0.5402630095680555 0.5094674556213018\n",
      "0.5441795289516449 0.5100591715976331\n",
      "0.5336360608537992 0.5106508875739645\n",
      "0.5321143642067909 0.5088757396449705\n",
      "0.5239820058147112 0.5076923076923077\n",
      "0.5203232342998186 0.5076923076923077\n",
      "0.5177557468414307 0.5272189349112426\n",
      "0.5025202706456184 0.5360946745562131\n",
      "0.49650945514440536 0.5230769230769231\n",
      "0.5019617031017939 0.5307692307692308\n",
      "0.4976898431777954 0.514792899408284\n",
      "0.48353813340266544 0.5106508875739645\n",
      "0.4763764540354411 0.521301775147929\n",
      "0.4702724466721217 0.5301775147928994\n",
      "0.4613773872454961 0.5177514792899408\n",
      "0.4494152180850506 0.5189349112426036\n",
      "0.44435257092118263 0.5396449704142012\n",
      "0.43408484881122905 0.5319526627218935\n",
      "0.42955493306120235 0.5467455621301776\n",
      "0.4338424156109492 0.5266272189349113\n",
      "0.4442121585210164 0.5076923076923077\n",
      "0.4331357417007287 0.5218934911242603\n",
      "0.42495659614602727 0.5236686390532544\n",
      "0.42713205019632977 0.5248520710059171\n",
      "0.4133016417423884 0.5118343195266272\n",
      "0.42945630724231404 0.51301775147929\n",
      "0.41816385214527446 0.5248520710059171\n",
      "0.42167293280363083 0.5236686390532544\n",
      "0.43143464004000026 0.5443786982248521\n",
      "0.4240541805823644 0.5218934911242603\n",
      "0.4039255753159523 0.5136094674556213\n",
      "0.401953832556804 0.5372781065088758\n",
      "0.38784734656413394 0.5366863905325444\n",
      "0.37356995791196823 0.521301775147929\n",
      "0.35299740980068844 0.5218934911242603\n",
      "0.3375844818850358 0.5195266272189349\n",
      "0.3283681198954582 0.5307692307692308\n",
      "0.32285777231057483 0.5266272189349113\n",
      "0.3083754243950049 0.5272189349112426\n",
      "0.30414701749881107 0.5313609467455621\n",
      "0.30174772317210835 0.5260355029585799\n",
      "0.30242591351270676 0.5171597633136095\n",
      "0.3082391507923603 0.5201183431952663\n",
      "0.3205635795990626 0.5289940828402366\n",
      "0.3325401619076729 0.5349112426035503\n",
      "0.3445747842391332 0.5384615384615384\n",
      "0.32525918384393054 0.5396449704142012\n",
      "0.3143676308294137 0.5159763313609468\n",
      "0.3189610590537389 0.5301775147928994\n",
      "0.302091371268034 0.5467455621301776\n",
      "0.2840451126297315 0.5355029585798816\n",
      "0.263868506376942 0.5372781065088758\n",
      "0.26809874549508095 0.5266272189349113\n",
      "0.2702917568385601 0.5307692307692308\n",
      "0.25709574731687707 0.5248520710059171\n",
      "0.24974563717842102 0.5366863905325444\n",
      "0.24138492966691652 0.5349112426035503\n",
      "0.22717133847375712 0.5360946745562131\n",
      "0.22897998926540217 0.5372781065088758\n",
      "0.21571051267286143 0.5177514792899408\n",
      "0.20436442022522291 0.5301775147928994\n",
      "0.19895538066824278 0.5402366863905326\n",
      "0.19251998327672482 0.5295857988165681\n",
      "0.18135583524902663 0.5242603550295858\n",
      "0.17716259136795998 0.5307692307692308\n",
      "0.1819293238222599 0.5355029585798816\n",
      "0.17583795512715975 0.5230769230769231\n",
      "0.17936219833791256 0.5366863905325444\n",
      "0.17999284714460373 0.5414201183431953\n",
      "0.17814110033214092 0.5366863905325444\n",
      "0.17508992863198122 0.5319526627218935\n",
      "0.1758273902038733 0.5431952662721894\n",
      "0.18300521622101465 0.5491124260355029\n",
      "0.18289130677779517 0.5449704142011834\n",
      "0.1767677441239357 0.5272189349112426\n",
      "0.1658415204534928 0.5325443786982249\n",
      "0.15991103121389946 0.5366863905325444\n",
      "0.1504702608411511 0.5313609467455621\n",
      "0.1361214304342866 0.5420118343195266\n",
      "0.13164760544896126 0.5295857988165681\n",
      "0.13586185220628977 0.5319526627218935\n",
      "0.13175596420963606 0.5360946745562131\n",
      "0.13888335910936198 0.5426035502958579\n",
      "0.13781669549643993 0.5366863905325444\n",
      "0.13756160624325275 0.5301775147928994\n",
      "0.13730160177995762 0.5366863905325444\n",
      "0.153100257118543 0.5390532544378698\n",
      "0.13846941230197748 0.5360946745562131\n",
      "0.12863527424633503 0.5295857988165681\n",
      "0.11994590144604445 0.5284023668639053\n",
      "0.10758103057742119 0.5301775147928994\n",
      "0.09493903225908677 0.5366863905325444\n",
      "0.08575453733404477 0.5319526627218935\n",
      "0.07826090821375449 0.5343195266272189\n",
      "0.07250964579482873 0.5366863905325444\n",
      "0.06700106135879953 0.5301775147928994\n",
      "0.06458865261326234 0.5337278106508876\n",
      "0.06047524915387233 0.5378698224852071\n",
      "0.05671720439568162 0.5408284023668639\n",
      "0.05666610086336732 0.5325443786982249\n",
      "0.05546513355026642 0.5343195266272189\n",
      "0.05346929561346769 0.5343195266272189\n",
      "0.053157547333588205 0.5366863905325444\n",
      "0.05229255541538199 0.5402366863905326\n",
      "0.05249194156688949 0.5301775147928994\n",
      "0.05353705274562041 0.5366863905325444\n",
      "0.05022877369386455 0.5355029585798816\n",
      "0.05057351818929116 0.5325443786982249\n",
      "0.04514261451549828 0.5384615384615384\n",
      "0.04386983051275214 0.5420118343195266\n",
      "0.040506651469816767 0.5295857988165681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03894387767650187 0.5284023668639053\n",
      "0.03689646457011501 0.5301775147928994\n",
      "0.03652586632718643 0.5384615384615384\n",
      "0.03555926331318915 0.5301775147928994\n",
      "0.0343068679018567 0.5384615384615384\n",
      "0.033677061165993415 0.5349112426035503\n",
      "0.035662546986714005 0.5337278106508876\n",
      "0.0328370724649479 0.5360946745562131\n",
      "0.03377493044051031 0.5260355029585799\n",
      "0.03848291599812607 0.5414201183431953\n",
      "0.044251559457431235 0.5396449704142012\n",
      "0.050923618177572884 0.5331360946745562\n",
      "0.05526078213006258 0.5402366863905326\n",
      "0.07130432361736894 0.5349112426035503\n",
      "0.10237380241354306 0.5337278106508876\n",
      "0.12947590090334415 0.5520710059171597\n",
      "0.13795611634850502 0.5443786982248521\n",
      "0.15210479063292345 0.5207100591715976\n",
      "0.13204275816679 0.5396449704142012\n",
      "0.13252702013899884 0.5313609467455621\n",
      "0.1197121621419986 0.5467455621301776\n",
      "0.09667598564798634 0.5502958579881657\n",
      "0.07512759106854598 0.5284023668639053\n",
      "0.05800904675076405 0.5384615384615384\n",
      "0.04034591435144345 0.5349112426035503\n",
      "0.032813334527115025 0.5378698224852071\n",
      "0.02649508137255907 0.5396449704142012\n",
      "0.02326885622460395 0.5366863905325444\n",
      "0.021152515507613618 0.5402366863905326\n",
      "0.019780348055064678 0.5408284023668639\n",
      "0.018795558678296704 0.5378698224852071\n",
      "0.01800113539987554 0.5384615384615384\n",
      "0.017298487131483853 0.5372781065088758\n",
      "0.01666988878666113 0.5360946745562131\n",
      "0.016097692889161408 0.5349112426035503\n",
      "0.015567638639671108 0.5337278106508876\n",
      "0.015076571920265755 0.5313609467455621\n",
      "0.014617771298314134 0.5313609467455621\n",
      "0.014185436302796006 0.5319526627218935\n",
      "0.01378028312077125 0.5337278106508876\n",
      "0.01339550370660921 0.5337278106508876\n",
      "0.013031563760402301 0.5331360946745562\n",
      "0.012684866359146932 0.5319526627218935\n",
      "0.012355644721537828 0.5313609467455621\n",
      "0.012040891141320268 0.5319526627218935\n",
      "0.011740694443384806 0.5313609467455621\n",
      "0.01145276784275969 0.5313609467455621\n",
      "0.011177000279227892 0.5307692307692308\n",
      "0.010912492677258948 0.5307692307692308\n",
      "0.010658527976678064 0.5319526627218935\n",
      "0.01041426338876287 0.5325443786982249\n",
      "0.010178573992258558 0.5319526627218935\n",
      "0.009951702551916242 0.5319526627218935\n",
      "0.009733842161949724 0.5319526627218935\n",
      "0.009522275746955225 0.5319526627218935\n",
      "0.00931833505940934 0.5331360946745562\n",
      "0.0091212133023267 0.5325443786982249\n",
      "0.008930797727468113 0.5319526627218935\n",
      "0.00874500818705807 0.5301775147928994\n",
      "0.008566838204084585 0.5307692307692308\n",
      "0.008393351919949055 0.5295857988165681\n",
      "0.008225348234797517 0.5301775147928994\n",
      "0.008062366648421934 0.5295857988165681\n",
      "0.007904155121650547 0.5307692307692308\n",
      "0.007750539361344029 0.5301775147928994\n",
      "0.007600976949712883 0.5301775147928994\n",
      "0.007456277555320412 0.5301775147928994\n",
      "0.00731569790514186 0.5301775147928994\n",
      "0.007178160342543076 0.5289940828402366\n",
      "0.007045418082270771 0.5284023668639053\n",
      "0.00691527754922087 0.5289940828402366\n",
      "0.006789381674025208 0.5295857988165681\n",
      "0.006666819894841562 0.5313609467455621\n",
      "0.006546911550685763 0.5313609467455621\n",
      "0.006430276242705683 0.5307692307692308\n",
      "0.006316243049999078 0.5307692307692308\n",
      "0.006205678917467594 0.5295857988165681\n",
      "0.0060975092540805536 0.5301775147928994\n",
      "0.005992119025904685 0.5301775147928994\n",
      "0.005888921596730749 0.5295857988165681\n",
      "0.005788776771320651 0.5301775147928994\n",
      "0.00569034202878053 0.5301775147928994\n",
      "0.005595288996119052 0.5301775147928994\n",
      "0.0055021051375661045 0.5319526627218935\n",
      "0.005410015854674081 0.5319526627218935\n",
      "0.005321644925667594 0.5319526627218935\n",
      "0.00523423728494284 0.5319526627218935\n",
      "0.005149053205968812 0.5325443786982249\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9984\\2347817330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss_epoch_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "for i in range(epoch):\n",
    "    loss_epoch_train = 0\n",
    "    for x_batch, y_batch in loader_train:\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch_train += loss.detach().item()\n",
    "        \n",
    "    \n",
    "    loss_epoch_test = 0\n",
    "    model.eval()\n",
    "    pred_test = []\n",
    "    all_label = []\n",
    "    \n",
    "    for x_batch, y_batch in loader_test:\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred,y_batch)\n",
    "        loss_epoch_test += loss.detach().item()\n",
    "        pred_test += list(pred.softmax(dim=1).argmax(dim=1).detach().numpy())\n",
    "        all_label += list(y_batch.detach().numpy())\n",
    "        \n",
    "    train_loss.append(loss_epoch_train/len(loader_train))\n",
    "    test_loss.append(loss_epoch_test/len(loader_test))\n",
    "    pred_test = np.array(pred_test)\n",
    "    all_label = np.array(all_label)\n",
    "    test_accuracy.append((pred_test==all_label).sum()/len(all_label))\n",
    "    print(train_loss[-1],test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e0b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0af874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd878f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d688ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e3120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf5a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea610119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d132742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84208c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57344e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed0b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2623d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f53c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664514c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_an[['time', 'open', 'high', 'low', 'close','TP','SL','pivots_l','pivots_h']].iloc[indeces_test[0]:].copy()\n",
    "df_test['SIGNAL'] = 0\n",
    "for i,idx in enumerate(indeces_test):\n",
    "    if i > 0:\n",
    "#         df_test.SIGNAL.loc[idx] = y_perdict[i]\n",
    "        if df_test.pivots_l[idx-1]==1 and y_perdict[i] ==BUY:\n",
    "            df_test.SIGNAL.loc[idx] = y_perdict[i]\n",
    "        if df_test.pivots_h[idx-1]==1 and y_perdict[i] ==SELL:\n",
    "            df_test.SIGNAL.loc[idx] = y_perdict[i]\n",
    "\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77dc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = GuruTester2(\n",
    "        df_test,\n",
    "        df_m5,\n",
    "        SPREAD,\n",
    "        use_spread=True\n",
    "    )\n",
    "df_res_m5 = gt.run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_m5['balance'] = 100\n",
    "loss_margin = 0.03\n",
    "perv_balance = 100\n",
    "\n",
    "# for index, row in df_res_m5.iterrows():\n",
    "for i in range(len(df_res_m5)):\n",
    "    if(df_res_m5.result[i] == -1):\n",
    "        loss_ratio =1# abs( (df_res_m5['start_price'][i]-df_res_m5['trigger_price'][i])/((df_res_m5['start_price'][i]-df_res_m5['SL'][i])) )\n",
    "#         print(loss_ratio)\n",
    "        df_res_m5['balance'][i] = perv_balance*(1-loss_ratio*loss_margin) \n",
    "    elif(df_res_m5.result[i] == 2):\n",
    "        profit_to_loss = 2#abs( (df_res_m5['start_price'][i]-df_res_m5['trigger_price'][i])/((df_res_m5['start_price'][i]-df_res_m5['SL'][i])) )\n",
    "#         print(profit_to_loss)\n",
    "        df_res_m5['balance'][i] = perv_balance*(1+profit_to_loss*loss_margin) \n",
    "    perv_balance = df_res_m5['balance'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300dbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_m5_plot = df_res_m5#.loc[:100]\n",
    "df_res_m5_plot['time'] = df_res_m5_plot['end_time']\n",
    "cp = CandlePlot(df_res_m5_plot, candles=False)\n",
    "print(\"min balance \",min(df_res_m5['balance']))\n",
    "cp.show_plot(line_traces=['balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efad8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718cddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a644fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

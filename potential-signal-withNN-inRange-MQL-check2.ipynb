{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6d40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from technicals.indicators import *\n",
    "from technicals.patterns import apply_patterns\n",
    "from technicals.patternsInRange import apply_patterns_in_range\n",
    "\n",
    "from guruTester import GuruTester,GuruTester2\n",
    "from plotting import CandlePlot\n",
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime\n",
    "from getCandle import Rates\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c10b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"GBPUSD\"\n",
    "NB_H1_CANDLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31dea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999999998899e-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates = Rates(pair, NB_H1_CANDLES, mt5.TIMEFRAME_H1)\n",
    "SPREAD = rates.get_spread()\n",
    "df_an = rates.get_rates_from_now()\n",
    "df_an.drop(NB_H1_CANDLES-1,inplace=True) \n",
    "df_an.drop(['tick_volume', 'spread', 'real_volume'], axis=1, inplace=True)\n",
    "SPREAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fe9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9e-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPREAD = (SPREAD//1e-5)*1e-5 # todo: do it right!!!\n",
    "SPREAD # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d743e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(df):\n",
    "    candle_patterns = ['HANGING_MAN', 'SHOOTING_STAR',\n",
    "           'SPINNING_TOP', 'MARUBOZU', 'ENGULFING', 'TWEEZER_TOP',\n",
    "           'TWEEZER_BOTTOM', 'MORNING_STAR', 'EVENING_STAR']\n",
    "    df = apply_patterns_in_range(df)\n",
    "    for cp in candle_patterns:\n",
    "        df[cp] = df[cp].astype(float)\n",
    "\n",
    "    df = BollingerBandsFeature(df)\n",
    "    df = ATRFeature(df)\n",
    "    df = KeltnerChannelsFeature(df)\n",
    "    df = RSIFeature(df)\n",
    "    df = MACDFeature(df)\n",
    "    df['pivots_l'] = False\n",
    "    df['pivots_h'] = False\n",
    "\n",
    "    df['low_perv'] = df.low.shift(1)\n",
    "    df['high_perv'] = df.high.shift(1)\n",
    "    df['low_next'] = df.low.shift(-1)\n",
    "    df['high_next'] = df.high.shift(-1)\n",
    "    df['pivots_l'] = (df.low_perv > df.low) & (df.low_next > df.low)\n",
    "    df['pivots_h'] = (df.high_perv < df.high) & (df.high_next < df.high)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.pivots_l = df.pivots_l.astype(float)\n",
    "    df.pivots_h = df.pivots_h.astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c04450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_an = featureExtraction(df_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affc2b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\3582309630.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_an['SL'][i] = df_an.high[i-1]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\3582309630.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_an['TP'][i] = 2*(df_an.close[i] - df_an.high[i-1] ) + df_an.close[i]\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\3582309630.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_an.SIGNAL[i] = BUY\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\3582309630.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_an.SIGNAL[i] = SELL\n"
     ]
    }
   ],
   "source": [
    "BUY = 1\n",
    "SELL = -1\n",
    "NONE = 0\n",
    "\n",
    "df_an['SIGNAL'] = 0\n",
    "df_an['TP'] = 0\n",
    "df_an['SL'] = 0\n",
    "for i in range(1,len(df_an)):\n",
    "    if df_an.pivots_l[i-1]:\n",
    "        for j in range(i,len(df_an)):\n",
    "            if( df_an.low[j] <= df_an.low[i-1] ):\n",
    "                break\n",
    "            else:\n",
    "                if(df_an.high[j] > 2*(df_an.close[i] - df_an.low[i-1] ) + df_an.close[i]):\n",
    "                    df_an.SIGNAL[i] = BUY\n",
    "                    break\n",
    "        \n",
    "        df_an['SL'][i] = df_an.low[i-1] \n",
    "        df_an['TP'][i] = 2*(df_an.close[i] - df_an.low[i-1] ) + df_an.close[i]\n",
    "                    \n",
    "    if df_an.pivots_h[i-1]:\n",
    "        for j in range(i,len(df_an)):\n",
    "            if( df_an.high[j] >= df_an.high[i-1] ):\n",
    "                break\n",
    "            else:\n",
    "                if(df_an.low[j] < 2*(df_an.close[i] - df_an.high[i-1] ) + df_an.close[i]):\n",
    "                    df_an.SIGNAL[i] = SELL\n",
    "                    break\n",
    "                    \n",
    "        df_an['SL'][i] = df_an.high[i-1] \n",
    "        df_an['TP'][i] = 2*(df_an.close[i] - df_an.high[i-1] ) + df_an.close[i]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbaa40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_col = [\n",
    "#     'open', 'high', 'low', 'close',\n",
    "    \n",
    "    'Feat_BB_MA_c', 'Feat_BB_UP_c', 'Feat_BB_LW_c',\n",
    "    'Feat_EMA_c', 'Feat_KeUp_c', 'Feat_KeLo_c',\n",
    "    \n",
    "    'Feat_BB_MA_o', 'Feat_BB_UP_o', 'Feat_BB_LW_o',\n",
    "    'Feat_EMA_o', 'Feat_KeUp_o', 'Feat_KeLo_o', \n",
    "    \n",
    "    'Feat_BB_MA_l', 'Feat_BB_UP_l', 'Feat_BB_LW_l',\n",
    "    'Feat_EMA_l', 'Feat_KeUp_l', 'Feat_KeLo_l',\n",
    "    \n",
    "    'Feat_BB_MA_h', 'Feat_BB_UP_h', 'Feat_BB_LW_h',\n",
    "    'Feat_EMA_h', 'Feat_KeUp_h', 'Feat_KeLo_h',\n",
    "    \n",
    "    'Feat_ATR_14',\n",
    "    'Feat_gains','Feat_wins_rma', 'Feat_losses_rma', 'Feat_RSI_14', \n",
    "#     'Feat_MACD', 'Feat_SIGNAL_MACD', 'Feat_HIST',\n",
    "    \n",
    "        'full_range',# this is added ...\n",
    "       'body_lower', 'body_upper', \n",
    "        'body_bottom_perc', 'body_top_perc',\n",
    "       'body_perc', 'direction', 'body_size', 'low_change', 'high_change',\n",
    "    'mid_point', 'mid_point_prev_2', 'body_size_prev',\n",
    "       'direction_prev', 'direction_prev_2', 'body_perc_prev','body_perc_prev_2',\n",
    "        'HANGING_MAN', 'SHOOTING_STAR', 'SPINNING_TOP',\n",
    "       'MARUBOZU', 'ENGULFING',\n",
    "    'TWEEZER_TOP', 'TWEEZER_BOTTOM',\n",
    "       'MORNING_STAR', 'EVENING_STAR'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a47bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = [] \n",
    "indeces = []\n",
    "for i in range(4,len(df_an)):\n",
    "    if df_an.pivots_h[i-1] or df_an.pivots_l[i-1] :\n",
    "        feature = []\n",
    "        feature.append(df_an.pivots_h[i-1])\n",
    "        feature.append(df_an.pivots_l[i-1])\n",
    "        feature.append(df_an.pivots_h[i-2])\n",
    "        feature.append(df_an.pivots_l[i-2])\n",
    "        feature.append(df_an.pivots_h[i-3])\n",
    "        feature.append(df_an.pivots_l[i-3])\n",
    "        feature.append(df_an.pivots_h[i-4])\n",
    "        feature.append(df_an.pivots_l[i-4])\n",
    "        for fc in feature_col:\n",
    "            feature.append(df_an[fc][i])\n",
    "            feature.append(df_an[fc][i-1])\n",
    "            feature.append(df_an[fc][i-2])\n",
    "            feature.append(df_an[fc][i-3])\n",
    "            feature.append(df_an[fc][i-4])\n",
    "\n",
    "        X.append(feature)\n",
    "        Y.append(df_an.SIGNAL[i])\n",
    "        indeces.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e3f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INDEX = int(0.8*len(X))\n",
    "X_train = X[:SPLIT_INDEX]\n",
    "Y_train = Y[:SPLIT_INDEX]\n",
    "indeces_train = indeces[:SPLIT_INDEX]\n",
    "X_test = X[SPLIT_INDEX:]\n",
    "Y_test = Y[SPLIT_INDEX:]\n",
    "indeces_test = indeces[SPLIT_INDEX:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610f53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier( solver='adam', alpha=1e-4,learning_rate_init=1e-4, # adam\n",
    "                    hidden_layer_sizes=(200,200), \n",
    "                    random_state=1,\n",
    "                    max_iter=2000,\n",
    "                    verbose=True,warm_start = True,\n",
    "                    n_iter_no_change=40,\n",
    "#                     early_stopping = True,\n",
    "#                     validation_fraction = 0.2 # default is 0.1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc192076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.95059229\n",
      "Iteration 2, loss = 0.88998637\n",
      "Iteration 3, loss = 0.84624379\n",
      "Iteration 4, loss = 0.81180068\n",
      "Iteration 5, loss = 0.78524444\n",
      "Iteration 6, loss = 0.76217921\n",
      "Iteration 7, loss = 0.74459829\n",
      "Iteration 8, loss = 0.73117578\n",
      "Iteration 9, loss = 0.72271900\n",
      "Iteration 10, loss = 0.71388224\n",
      "Iteration 11, loss = 0.70928846\n",
      "Iteration 12, loss = 0.70489855\n",
      "Iteration 13, loss = 0.69920256\n",
      "Iteration 14, loss = 0.69700332\n",
      "Iteration 15, loss = 0.69278900\n",
      "Iteration 16, loss = 0.69090581\n",
      "Iteration 17, loss = 0.68850739\n",
      "Iteration 18, loss = 0.68785291\n",
      "Iteration 19, loss = 0.68587450\n",
      "Iteration 20, loss = 0.68296422\n",
      "Iteration 21, loss = 0.68057472\n",
      "Iteration 22, loss = 0.67792771\n",
      "Iteration 23, loss = 0.67631415\n",
      "Iteration 24, loss = 0.67374663\n",
      "Iteration 25, loss = 0.67249386\n",
      "Iteration 26, loss = 0.67230569\n",
      "Iteration 27, loss = 0.66953515\n",
      "Iteration 28, loss = 0.66768726\n",
      "Iteration 29, loss = 0.66663266\n",
      "Iteration 30, loss = 0.66525341\n",
      "Iteration 31, loss = 0.66299818\n",
      "Iteration 32, loss = 0.66150895\n",
      "Iteration 33, loss = 0.66012586\n",
      "Iteration 34, loss = 0.65899694\n",
      "Iteration 35, loss = 0.65824225\n",
      "Iteration 36, loss = 0.65630226\n",
      "Iteration 37, loss = 0.65489778\n",
      "Iteration 38, loss = 0.65199913\n",
      "Iteration 39, loss = 0.65184663\n",
      "Iteration 40, loss = 0.65018825\n",
      "Iteration 41, loss = 0.64740229\n",
      "Iteration 42, loss = 0.64652202\n",
      "Iteration 43, loss = 0.64454521\n",
      "Iteration 44, loss = 0.64435441\n",
      "Iteration 45, loss = 0.64386734\n",
      "Iteration 46, loss = 0.64174822\n",
      "Iteration 47, loss = 0.64018530\n",
      "Iteration 48, loss = 0.63830164\n",
      "Iteration 49, loss = 0.63703052\n",
      "Iteration 50, loss = 0.63538528\n",
      "Iteration 51, loss = 0.63364078\n",
      "Iteration 52, loss = 0.63492764\n",
      "Iteration 53, loss = 0.63188752\n",
      "Iteration 54, loss = 0.63186578\n",
      "Iteration 55, loss = 0.62989253\n",
      "Iteration 56, loss = 0.62845092\n",
      "Iteration 57, loss = 0.62842431\n",
      "Iteration 58, loss = 0.62446861\n",
      "Iteration 59, loss = 0.62377022\n",
      "Iteration 60, loss = 0.62265024\n",
      "Iteration 61, loss = 0.62102779\n",
      "Iteration 62, loss = 0.62064715\n",
      "Iteration 63, loss = 0.61906416\n",
      "Iteration 64, loss = 0.61784018\n",
      "Iteration 65, loss = 0.61655055\n",
      "Iteration 66, loss = 0.61503914\n",
      "Iteration 67, loss = 0.61550908\n",
      "Iteration 68, loss = 0.61439271\n",
      "Iteration 69, loss = 0.61004551\n",
      "Iteration 70, loss = 0.60993174\n",
      "Iteration 71, loss = 0.61072839\n",
      "Iteration 72, loss = 0.60791100\n",
      "Iteration 73, loss = 0.60623740\n",
      "Iteration 74, loss = 0.60627278\n",
      "Iteration 75, loss = 0.60363202\n",
      "Iteration 76, loss = 0.60204325\n",
      "Iteration 77, loss = 0.60111524\n",
      "Iteration 78, loss = 0.60005151\n",
      "Iteration 79, loss = 0.60037754\n",
      "Iteration 80, loss = 0.59855300\n",
      "Iteration 81, loss = 0.59765009\n",
      "Iteration 82, loss = 0.59658080\n",
      "Iteration 83, loss = 0.59293980\n",
      "Iteration 84, loss = 0.59268425\n",
      "Iteration 85, loss = 0.59220305\n",
      "Iteration 86, loss = 0.59011854\n",
      "Iteration 87, loss = 0.59198656\n",
      "Iteration 88, loss = 0.58764834\n",
      "Iteration 89, loss = 0.58780594\n",
      "Iteration 90, loss = 0.58824529\n",
      "Iteration 91, loss = 0.58540120\n",
      "Iteration 92, loss = 0.58623452\n",
      "Iteration 93, loss = 0.58200634\n",
      "Iteration 94, loss = 0.58217073\n",
      "Iteration 95, loss = 0.58208714\n",
      "Iteration 96, loss = 0.58162439\n",
      "Iteration 97, loss = 0.57899136\n",
      "Iteration 98, loss = 0.57705283\n",
      "Iteration 99, loss = 0.57796813\n",
      "Iteration 100, loss = 0.57315562\n",
      "Iteration 101, loss = 0.57504692\n",
      "Iteration 102, loss = 0.57398330\n",
      "Iteration 103, loss = 0.57493470\n",
      "Iteration 104, loss = 0.57167663\n",
      "Iteration 105, loss = 0.56848936\n",
      "Iteration 106, loss = 0.56749132\n",
      "Iteration 107, loss = 0.56723008\n",
      "Iteration 108, loss = 0.56718854\n",
      "Iteration 109, loss = 0.56681748\n",
      "Iteration 110, loss = 0.56539998\n",
      "Iteration 111, loss = 0.56385513\n",
      "Iteration 112, loss = 0.56163065\n",
      "Iteration 113, loss = 0.56004547\n",
      "Iteration 114, loss = 0.55990908\n",
      "Iteration 115, loss = 0.55894478\n",
      "Iteration 116, loss = 0.55721136\n",
      "Iteration 117, loss = 0.55950149\n",
      "Iteration 118, loss = 0.55672376\n",
      "Iteration 119, loss = 0.55538634\n",
      "Iteration 120, loss = 0.55479612\n",
      "Iteration 121, loss = 0.55217908\n",
      "Iteration 122, loss = 0.55112213\n",
      "Iteration 123, loss = 0.54996428\n",
      "Iteration 124, loss = 0.55036341\n",
      "Iteration 125, loss = 0.54961364\n",
      "Iteration 126, loss = 0.54712985\n",
      "Iteration 127, loss = 0.54709437\n",
      "Iteration 128, loss = 0.54623489\n",
      "Iteration 129, loss = 0.54946358\n",
      "Iteration 130, loss = 0.54331142\n",
      "Iteration 131, loss = 0.54150890\n",
      "Iteration 132, loss = 0.54132373\n",
      "Iteration 133, loss = 0.54132310\n",
      "Iteration 134, loss = 0.53893366\n",
      "Iteration 135, loss = 0.54077929\n",
      "Iteration 136, loss = 0.54002607\n",
      "Iteration 137, loss = 0.53554111\n",
      "Iteration 138, loss = 0.53943691\n",
      "Iteration 139, loss = 0.53433281\n",
      "Iteration 140, loss = 0.53192715\n",
      "Iteration 141, loss = 0.53342585\n",
      "Iteration 142, loss = 0.53271638\n",
      "Iteration 143, loss = 0.53198703\n",
      "Iteration 144, loss = 0.52903075\n",
      "Iteration 145, loss = 0.52987094\n",
      "Iteration 146, loss = 0.52846902\n",
      "Iteration 147, loss = 0.53033356\n",
      "Iteration 148, loss = 0.52619122\n",
      "Iteration 149, loss = 0.52457896\n",
      "Iteration 150, loss = 0.52292590\n",
      "Iteration 151, loss = 0.52172352\n",
      "Iteration 152, loss = 0.52281901\n",
      "Iteration 153, loss = 0.51968810\n",
      "Iteration 154, loss = 0.51991611\n",
      "Iteration 155, loss = 0.51729607\n",
      "Iteration 156, loss = 0.51746530\n",
      "Iteration 157, loss = 0.51795189\n",
      "Iteration 158, loss = 0.51662199\n",
      "Iteration 159, loss = 0.51281735\n",
      "Iteration 160, loss = 0.51392599\n",
      "Iteration 161, loss = 0.51351023\n",
      "Iteration 162, loss = 0.51127805\n",
      "Iteration 163, loss = 0.51073949\n",
      "Iteration 164, loss = 0.51025278\n",
      "Iteration 165, loss = 0.51432144\n",
      "Iteration 166, loss = 0.50618373\n",
      "Iteration 167, loss = 0.50550272\n",
      "Iteration 168, loss = 0.50527814\n",
      "Iteration 169, loss = 0.50456634\n",
      "Iteration 170, loss = 0.50563965\n",
      "Iteration 171, loss = 0.50618048\n",
      "Iteration 172, loss = 0.50174653\n",
      "Iteration 173, loss = 0.50234361\n",
      "Iteration 174, loss = 0.50104193\n",
      "Iteration 175, loss = 0.50020790\n",
      "Iteration 176, loss = 0.49773097\n",
      "Iteration 177, loss = 0.49751309\n",
      "Iteration 178, loss = 0.49755222\n",
      "Iteration 179, loss = 0.49509989\n",
      "Iteration 180, loss = 0.49559068\n",
      "Iteration 181, loss = 0.49380557\n",
      "Iteration 182, loss = 0.49398960\n",
      "Iteration 183, loss = 0.49052000\n",
      "Iteration 184, loss = 0.49090947\n",
      "Iteration 185, loss = 0.49054542\n",
      "Iteration 186, loss = 0.48740516\n",
      "Iteration 187, loss = 0.48839643\n",
      "Iteration 188, loss = 0.48778148\n",
      "Iteration 189, loss = 0.49055144\n",
      "Iteration 190, loss = 0.48488224\n",
      "Iteration 191, loss = 0.48551920\n",
      "Iteration 192, loss = 0.48387649\n",
      "Iteration 193, loss = 0.48244206\n",
      "Iteration 194, loss = 0.48225644\n",
      "Iteration 195, loss = 0.48142330\n",
      "Iteration 196, loss = 0.47960224\n",
      "Iteration 197, loss = 0.48006086\n",
      "Iteration 198, loss = 0.48175005\n",
      "Iteration 199, loss = 0.48046832\n",
      "Iteration 200, loss = 0.47812312\n",
      "Iteration 201, loss = 0.47978254\n",
      "Iteration 202, loss = 0.47617508\n",
      "Iteration 203, loss = 0.47378843\n",
      "Iteration 204, loss = 0.47235951\n",
      "Iteration 205, loss = 0.47254521\n",
      "Iteration 206, loss = 0.46974994\n",
      "Iteration 207, loss = 0.46846641\n",
      "Iteration 208, loss = 0.46993287\n",
      "Iteration 209, loss = 0.46647654\n",
      "Iteration 210, loss = 0.46820498\n",
      "Iteration 211, loss = 0.46582201\n",
      "Iteration 212, loss = 0.46516748\n",
      "Iteration 213, loss = 0.46570116\n",
      "Iteration 214, loss = 0.46356492\n",
      "Iteration 215, loss = 0.46139465\n",
      "Iteration 216, loss = 0.46028406\n",
      "Iteration 217, loss = 0.46061349\n",
      "Iteration 218, loss = 0.45897589\n",
      "Iteration 219, loss = 0.45788357\n",
      "Iteration 220, loss = 0.45678098\n",
      "Iteration 221, loss = 0.45639118\n",
      "Iteration 222, loss = 0.45535805\n",
      "Iteration 223, loss = 0.45747130\n",
      "Iteration 224, loss = 0.45517765\n",
      "Iteration 225, loss = 0.45372875\n",
      "Iteration 226, loss = 0.45759489\n",
      "Iteration 227, loss = 0.45580152\n",
      "Iteration 228, loss = 0.44954892\n",
      "Iteration 229, loss = 0.45310389\n",
      "Iteration 230, loss = 0.44863083\n",
      "Iteration 231, loss = 0.44923924\n",
      "Iteration 232, loss = 0.44664838\n",
      "Iteration 233, loss = 0.44535213\n",
      "Iteration 234, loss = 0.44367962\n",
      "Iteration 235, loss = 0.44476348\n",
      "Iteration 236, loss = 0.44373670\n",
      "Iteration 237, loss = 0.44329277\n",
      "Iteration 238, loss = 0.44227017\n",
      "Iteration 239, loss = 0.44252710\n",
      "Iteration 240, loss = 0.44153363\n",
      "Iteration 241, loss = 0.43972505\n",
      "Iteration 242, loss = 0.43803020\n",
      "Iteration 243, loss = 0.43649223\n",
      "Iteration 244, loss = 0.43607852\n",
      "Iteration 245, loss = 0.43659754\n",
      "Iteration 246, loss = 0.43406062\n",
      "Iteration 247, loss = 0.43357951\n",
      "Iteration 248, loss = 0.43430968\n",
      "Iteration 249, loss = 0.43581732\n",
      "Iteration 250, loss = 0.43318344\n",
      "Iteration 251, loss = 0.43258811\n",
      "Iteration 252, loss = 0.42894313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.43229276\n",
      "Iteration 254, loss = 0.42756442\n",
      "Iteration 255, loss = 0.42843831\n",
      "Iteration 256, loss = 0.42630120\n",
      "Iteration 257, loss = 0.42940466\n",
      "Iteration 258, loss = 0.42578101\n",
      "Iteration 259, loss = 0.42308837\n",
      "Iteration 260, loss = 0.42648707\n",
      "Iteration 261, loss = 0.42596828\n",
      "Iteration 262, loss = 0.42492410\n",
      "Iteration 263, loss = 0.42023829\n",
      "Iteration 264, loss = 0.42069900\n",
      "Iteration 265, loss = 0.42006018\n",
      "Iteration 266, loss = 0.41720606\n",
      "Iteration 267, loss = 0.41696323\n",
      "Iteration 268, loss = 0.41725309\n",
      "Iteration 269, loss = 0.41718002\n",
      "Iteration 270, loss = 0.41697436\n",
      "Iteration 271, loss = 0.41340340\n",
      "Iteration 272, loss = 0.41323240\n",
      "Iteration 273, loss = 0.41552015\n",
      "Iteration 274, loss = 0.41074807\n",
      "Iteration 275, loss = 0.41126215\n",
      "Iteration 276, loss = 0.41121536\n",
      "Iteration 277, loss = 0.40827119\n",
      "Iteration 278, loss = 0.41018062\n",
      "Iteration 279, loss = 0.40961272\n",
      "Iteration 280, loss = 0.40707797\n",
      "Iteration 281, loss = 0.40664566\n",
      "Iteration 282, loss = 0.40655686\n",
      "Iteration 283, loss = 0.40882143\n",
      "Iteration 284, loss = 0.40531893\n",
      "Iteration 285, loss = 0.40193576\n",
      "Iteration 286, loss = 0.40131896\n",
      "Iteration 287, loss = 0.40016216\n",
      "Iteration 288, loss = 0.39880572\n",
      "Iteration 289, loss = 0.39886873\n",
      "Iteration 290, loss = 0.39757946\n",
      "Iteration 291, loss = 0.39885353\n",
      "Iteration 292, loss = 0.39918692\n",
      "Iteration 293, loss = 0.39665189\n",
      "Iteration 294, loss = 0.39577825\n",
      "Iteration 295, loss = 0.39557012\n",
      "Iteration 296, loss = 0.39772039\n",
      "Iteration 297, loss = 0.39369130\n",
      "Iteration 298, loss = 0.39020329\n",
      "Iteration 299, loss = 0.39332676\n",
      "Iteration 300, loss = 0.39090234\n",
      "Iteration 301, loss = 0.39111314\n",
      "Iteration 302, loss = 0.38978702\n",
      "Iteration 303, loss = 0.39112651\n",
      "Iteration 304, loss = 0.38722795\n",
      "Iteration 305, loss = 0.38915857\n",
      "Iteration 306, loss = 0.39344957\n",
      "Iteration 307, loss = 0.38620562\n",
      "Iteration 308, loss = 0.38357299\n",
      "Iteration 309, loss = 0.38386839\n",
      "Iteration 310, loss = 0.38402135\n",
      "Iteration 311, loss = 0.38162043\n",
      "Iteration 312, loss = 0.38300516\n",
      "Iteration 313, loss = 0.38066733\n",
      "Iteration 314, loss = 0.38196192\n",
      "Iteration 315, loss = 0.37879678\n",
      "Iteration 316, loss = 0.37886518\n",
      "Iteration 317, loss = 0.37750604\n",
      "Iteration 318, loss = 0.37742176\n",
      "Iteration 319, loss = 0.37503749\n",
      "Iteration 320, loss = 0.37511955\n",
      "Iteration 321, loss = 0.37484736\n",
      "Iteration 322, loss = 0.37268846\n",
      "Iteration 323, loss = 0.37430941\n",
      "Iteration 324, loss = 0.37246939\n",
      "Iteration 325, loss = 0.37195802\n",
      "Iteration 326, loss = 0.36833078\n",
      "Iteration 327, loss = 0.37076118\n",
      "Iteration 328, loss = 0.36804386\n",
      "Iteration 329, loss = 0.36829014\n",
      "Iteration 330, loss = 0.36739075\n",
      "Iteration 331, loss = 0.37310394\n",
      "Iteration 332, loss = 0.36893628\n",
      "Iteration 333, loss = 0.36548470\n",
      "Iteration 334, loss = 0.36366514\n",
      "Iteration 335, loss = 0.36494225\n",
      "Iteration 336, loss = 0.36430275\n",
      "Iteration 337, loss = 0.36228053\n",
      "Iteration 338, loss = 0.36090868\n",
      "Iteration 339, loss = 0.35946912\n",
      "Iteration 340, loss = 0.36063775\n",
      "Iteration 341, loss = 0.36089712\n",
      "Iteration 342, loss = 0.35898382\n",
      "Iteration 343, loss = 0.35761142\n",
      "Iteration 344, loss = 0.35605138\n",
      "Iteration 345, loss = 0.35689533\n",
      "Iteration 346, loss = 0.35511219\n",
      "Iteration 347, loss = 0.35578155\n",
      "Iteration 348, loss = 0.35689916\n",
      "Iteration 349, loss = 0.35193323\n",
      "Iteration 350, loss = 0.35126146\n",
      "Iteration 351, loss = 0.35171956\n",
      "Iteration 352, loss = 0.35229549\n",
      "Iteration 353, loss = 0.35042914\n",
      "Iteration 354, loss = 0.34884545\n",
      "Iteration 355, loss = 0.34806537\n",
      "Iteration 356, loss = 0.35237482\n",
      "Iteration 357, loss = 0.34922957\n",
      "Iteration 358, loss = 0.34688662\n",
      "Iteration 359, loss = 0.34934597\n",
      "Iteration 360, loss = 0.34374832\n",
      "Iteration 361, loss = 0.34488929\n",
      "Iteration 362, loss = 0.34265322\n",
      "Iteration 363, loss = 0.34304383\n",
      "Iteration 364, loss = 0.34206111\n",
      "Iteration 365, loss = 0.34152257\n",
      "Iteration 366, loss = 0.34150244\n",
      "Iteration 367, loss = 0.34105764\n",
      "Iteration 368, loss = 0.33871728\n",
      "Iteration 369, loss = 0.33854901\n",
      "Iteration 370, loss = 0.33808565\n",
      "Iteration 371, loss = 0.33770753\n",
      "Iteration 372, loss = 0.33579740\n",
      "Iteration 373, loss = 0.33748275\n",
      "Iteration 374, loss = 0.33900525\n",
      "Iteration 375, loss = 0.33539347\n",
      "Iteration 376, loss = 0.33276729\n",
      "Iteration 377, loss = 0.33381148\n",
      "Iteration 378, loss = 0.33227133\n",
      "Iteration 379, loss = 0.33101902\n",
      "Iteration 380, loss = 0.33060662\n",
      "Iteration 381, loss = 0.32975362\n",
      "Iteration 382, loss = 0.33228673\n",
      "Iteration 383, loss = 0.32772519\n",
      "Iteration 384, loss = 0.33331808\n",
      "Iteration 385, loss = 0.32750531\n",
      "Iteration 386, loss = 0.32715476\n",
      "Iteration 387, loss = 0.32528022\n",
      "Iteration 388, loss = 0.32425886\n",
      "Iteration 389, loss = 0.32404489\n",
      "Iteration 390, loss = 0.32429956\n",
      "Iteration 391, loss = 0.32113655\n",
      "Iteration 392, loss = 0.32263467\n",
      "Iteration 393, loss = 0.32048794\n",
      "Iteration 394, loss = 0.32405900\n",
      "Iteration 395, loss = 0.32013446\n",
      "Iteration 396, loss = 0.31942806\n",
      "Iteration 397, loss = 0.32040665\n",
      "Iteration 398, loss = 0.32160882\n",
      "Iteration 399, loss = 0.32064347\n",
      "Iteration 400, loss = 0.31937981\n",
      "Iteration 401, loss = 0.31559231\n",
      "Iteration 402, loss = 0.31901541\n",
      "Iteration 403, loss = 0.31683783\n",
      "Iteration 404, loss = 0.31478600\n",
      "Iteration 405, loss = 0.31607095\n",
      "Iteration 406, loss = 0.31395266\n",
      "Iteration 407, loss = 0.31148738\n",
      "Iteration 408, loss = 0.31230222\n",
      "Iteration 409, loss = 0.31195406\n",
      "Iteration 410, loss = 0.31014814\n",
      "Iteration 411, loss = 0.31003365\n",
      "Iteration 412, loss = 0.30782993\n",
      "Iteration 413, loss = 0.30797016\n",
      "Iteration 414, loss = 0.31111229\n",
      "Iteration 415, loss = 0.30836840\n",
      "Iteration 416, loss = 0.30560944\n",
      "Iteration 417, loss = 0.30621963\n",
      "Iteration 418, loss = 0.30564086\n",
      "Iteration 419, loss = 0.31030833\n",
      "Iteration 420, loss = 0.30709879\n",
      "Iteration 421, loss = 0.30590159\n",
      "Iteration 422, loss = 0.30954009\n",
      "Iteration 423, loss = 0.30200628\n",
      "Iteration 424, loss = 0.30078808\n",
      "Iteration 425, loss = 0.29894407\n",
      "Iteration 426, loss = 0.30155844\n",
      "Iteration 427, loss = 0.29954986\n",
      "Iteration 428, loss = 0.30538725\n",
      "Iteration 429, loss = 0.29707581\n",
      "Iteration 430, loss = 0.29934950\n",
      "Iteration 431, loss = 0.29571635\n",
      "Iteration 432, loss = 0.29508889\n",
      "Iteration 433, loss = 0.29447899\n",
      "Iteration 434, loss = 0.29869289\n",
      "Iteration 435, loss = 0.29799023\n",
      "Iteration 436, loss = 0.29550488\n",
      "Iteration 437, loss = 0.30014391\n",
      "Iteration 438, loss = 0.29316395\n",
      "Iteration 439, loss = 0.29484493\n",
      "Iteration 440, loss = 0.29438551\n",
      "Iteration 441, loss = 0.28880490\n",
      "Iteration 442, loss = 0.29033393\n",
      "Iteration 443, loss = 0.29078989\n",
      "Iteration 444, loss = 0.28826295\n",
      "Iteration 445, loss = 0.28809550\n",
      "Iteration 446, loss = 0.28692784\n",
      "Iteration 447, loss = 0.28645216\n",
      "Iteration 448, loss = 0.28617993\n",
      "Iteration 449, loss = 0.28748057\n",
      "Iteration 450, loss = 0.28430169\n",
      "Iteration 451, loss = 0.28268701\n",
      "Iteration 452, loss = 0.28860609\n",
      "Iteration 453, loss = 0.28285145\n",
      "Iteration 454, loss = 0.28632877\n",
      "Iteration 455, loss = 0.28712083\n",
      "Iteration 456, loss = 0.27966949\n",
      "Iteration 457, loss = 0.27995513\n",
      "Iteration 458, loss = 0.28017157\n",
      "Iteration 459, loss = 0.27950199\n",
      "Iteration 460, loss = 0.27960416\n",
      "Iteration 461, loss = 0.28088728\n",
      "Iteration 462, loss = 0.28008404\n",
      "Iteration 463, loss = 0.27631229\n",
      "Iteration 464, loss = 0.27451882\n",
      "Iteration 465, loss = 0.27499642\n",
      "Iteration 466, loss = 0.27533815\n",
      "Iteration 467, loss = 0.27416766\n",
      "Iteration 468, loss = 0.27580098\n",
      "Iteration 469, loss = 0.27279231\n",
      "Iteration 470, loss = 0.27278470\n",
      "Iteration 471, loss = 0.27411632\n",
      "Iteration 472, loss = 0.27347809\n",
      "Iteration 473, loss = 0.27060828\n",
      "Iteration 474, loss = 0.27388079\n",
      "Iteration 475, loss = 0.27141369\n",
      "Iteration 476, loss = 0.26756178\n",
      "Iteration 477, loss = 0.27222254\n",
      "Iteration 478, loss = 0.27045711\n",
      "Iteration 479, loss = 0.26564243\n",
      "Iteration 480, loss = 0.26583125\n",
      "Iteration 481, loss = 0.26929955\n",
      "Iteration 482, loss = 0.26555808\n",
      "Iteration 483, loss = 0.26362443\n",
      "Iteration 484, loss = 0.26396357\n",
      "Iteration 485, loss = 0.26680251\n",
      "Iteration 486, loss = 0.26434757\n",
      "Iteration 487, loss = 0.26099804\n",
      "Iteration 488, loss = 0.26271672\n",
      "Iteration 489, loss = 0.26040072\n",
      "Iteration 490, loss = 0.26167615\n",
      "Iteration 491, loss = 0.26100913\n",
      "Iteration 492, loss = 0.26072757\n",
      "Iteration 493, loss = 0.26048391\n",
      "Iteration 494, loss = 0.26089053\n",
      "Iteration 495, loss = 0.25791735\n",
      "Iteration 496, loss = 0.25940158\n",
      "Iteration 497, loss = 0.26061594\n",
      "Iteration 498, loss = 0.25515581\n",
      "Iteration 499, loss = 0.25903461\n",
      "Iteration 500, loss = 0.25525534\n",
      "Iteration 501, loss = 0.25265581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 502, loss = 0.25517655\n",
      "Iteration 503, loss = 0.25247134\n",
      "Iteration 504, loss = 0.25199745\n",
      "Iteration 505, loss = 0.25283804\n",
      "Iteration 506, loss = 0.25289697\n",
      "Iteration 507, loss = 0.25141753\n",
      "Iteration 508, loss = 0.24957743\n",
      "Iteration 509, loss = 0.25037334\n",
      "Iteration 510, loss = 0.25020568\n",
      "Iteration 511, loss = 0.24679815\n",
      "Iteration 512, loss = 0.24863456\n",
      "Iteration 513, loss = 0.24889551\n",
      "Iteration 514, loss = 0.24884243\n",
      "Iteration 515, loss = 0.24671619\n",
      "Iteration 516, loss = 0.24598388\n",
      "Iteration 517, loss = 0.24431845\n",
      "Iteration 518, loss = 0.24271624\n",
      "Iteration 519, loss = 0.24332111\n",
      "Iteration 520, loss = 0.24256799\n",
      "Iteration 521, loss = 0.24413056\n",
      "Iteration 522, loss = 0.24340135\n",
      "Iteration 523, loss = 0.24106591\n",
      "Iteration 524, loss = 0.24726256\n",
      "Iteration 525, loss = 0.24293189\n",
      "Iteration 526, loss = 0.24047360\n",
      "Iteration 527, loss = 0.24374089\n",
      "Iteration 528, loss = 0.23764377\n",
      "Iteration 529, loss = 0.24043824\n",
      "Iteration 530, loss = 0.24183810\n",
      "Iteration 531, loss = 0.23999016\n",
      "Iteration 532, loss = 0.23565965\n",
      "Iteration 533, loss = 0.23486918\n",
      "Iteration 534, loss = 0.23620374\n",
      "Iteration 535, loss = 0.24040772\n",
      "Iteration 536, loss = 0.24235837\n",
      "Iteration 537, loss = 0.23490344\n",
      "Iteration 538, loss = 0.23298290\n",
      "Iteration 539, loss = 0.23197250\n",
      "Iteration 540, loss = 0.23284549\n",
      "Iteration 541, loss = 0.23387222\n",
      "Iteration 542, loss = 0.23108819\n",
      "Iteration 543, loss = 0.23030747\n",
      "Iteration 544, loss = 0.23084618\n",
      "Iteration 545, loss = 0.23299867\n",
      "Iteration 546, loss = 0.22887082\n",
      "Iteration 547, loss = 0.22874395\n",
      "Iteration 548, loss = 0.22970924\n",
      "Iteration 549, loss = 0.22914177\n",
      "Iteration 550, loss = 0.22746122\n",
      "Iteration 551, loss = 0.23032175\n",
      "Iteration 552, loss = 0.22557240\n",
      "Iteration 553, loss = 0.22490614\n",
      "Iteration 554, loss = 0.22779857\n",
      "Iteration 555, loss = 0.22379347\n",
      "Iteration 556, loss = 0.22569732\n",
      "Iteration 557, loss = 0.22603097\n",
      "Iteration 558, loss = 0.22316612\n",
      "Iteration 559, loss = 0.22298796\n",
      "Iteration 560, loss = 0.22261920\n",
      "Iteration 561, loss = 0.22136375\n",
      "Iteration 562, loss = 0.22359541\n",
      "Iteration 563, loss = 0.22032040\n",
      "Iteration 564, loss = 0.22192507\n",
      "Iteration 565, loss = 0.21757651\n",
      "Iteration 566, loss = 0.21830372\n",
      "Iteration 567, loss = 0.22011232\n",
      "Iteration 568, loss = 0.21838695\n",
      "Iteration 569, loss = 0.22137792\n",
      "Iteration 570, loss = 0.21773365\n",
      "Iteration 571, loss = 0.21592661\n",
      "Iteration 572, loss = 0.21941425\n",
      "Iteration 573, loss = 0.21485223\n",
      "Iteration 574, loss = 0.21376429\n",
      "Iteration 575, loss = 0.21556767\n",
      "Iteration 576, loss = 0.21692561\n",
      "Iteration 577, loss = 0.21451043\n",
      "Iteration 578, loss = 0.21682064\n",
      "Iteration 579, loss = 0.21189796\n",
      "Iteration 580, loss = 0.21542323\n",
      "Iteration 581, loss = 0.21108603\n",
      "Iteration 582, loss = 0.21188875\n",
      "Iteration 583, loss = 0.21096007\n",
      "Iteration 584, loss = 0.21142201\n",
      "Iteration 585, loss = 0.20910337\n",
      "Iteration 586, loss = 0.20973234\n",
      "Iteration 587, loss = 0.20717585\n",
      "Iteration 588, loss = 0.20921527\n",
      "Iteration 589, loss = 0.20862175\n",
      "Iteration 590, loss = 0.20871440\n",
      "Iteration 591, loss = 0.20763299\n",
      "Iteration 592, loss = 0.20652697\n",
      "Iteration 593, loss = 0.21067506\n",
      "Iteration 594, loss = 0.20560439\n",
      "Iteration 595, loss = 0.20785902\n",
      "Iteration 596, loss = 0.20688378\n",
      "Iteration 597, loss = 0.20447511\n",
      "Iteration 598, loss = 0.20297877\n",
      "Iteration 599, loss = 0.20366517\n",
      "Iteration 600, loss = 0.20362845\n",
      "Iteration 601, loss = 0.20553073\n",
      "Iteration 602, loss = 0.20062567\n",
      "Iteration 603, loss = 0.20387766\n",
      "Iteration 604, loss = 0.20517914\n",
      "Iteration 605, loss = 0.20473989\n",
      "Iteration 606, loss = 0.20270328\n",
      "Iteration 607, loss = 0.19900490\n",
      "Iteration 608, loss = 0.20243812\n",
      "Iteration 609, loss = 0.20018397\n",
      "Iteration 610, loss = 0.20167109\n",
      "Iteration 611, loss = 0.19695939\n",
      "Iteration 612, loss = 0.19594625\n",
      "Iteration 613, loss = 0.19485206\n",
      "Iteration 614, loss = 0.19719076\n",
      "Iteration 615, loss = 0.20041526\n",
      "Iteration 616, loss = 0.19653699\n",
      "Iteration 617, loss = 0.19677407\n",
      "Iteration 618, loss = 0.19568719\n",
      "Iteration 619, loss = 0.19185765\n",
      "Iteration 620, loss = 0.19625960\n",
      "Iteration 621, loss = 0.19423936\n",
      "Iteration 622, loss = 0.19181393\n",
      "Iteration 623, loss = 0.19412702\n",
      "Iteration 624, loss = 0.19673510\n",
      "Iteration 625, loss = 0.19463643\n",
      "Iteration 626, loss = 0.19103391\n",
      "Iteration 627, loss = 0.18982812\n",
      "Iteration 628, loss = 0.19272524\n",
      "Iteration 629, loss = 0.18798632\n",
      "Iteration 630, loss = 0.19024051\n",
      "Iteration 631, loss = 0.18904768\n",
      "Iteration 632, loss = 0.18750998\n",
      "Iteration 633, loss = 0.19169411\n",
      "Iteration 634, loss = 0.18920481\n",
      "Iteration 635, loss = 0.19190402\n",
      "Iteration 636, loss = 0.18654342\n",
      "Iteration 637, loss = 0.18776615\n",
      "Iteration 638, loss = 0.18530812\n",
      "Iteration 639, loss = 0.18717893\n",
      "Iteration 640, loss = 0.18855512\n",
      "Iteration 641, loss = 0.18582012\n",
      "Iteration 642, loss = 0.18538910\n",
      "Iteration 643, loss = 0.18318733\n",
      "Iteration 644, loss = 0.18276935\n",
      "Iteration 645, loss = 0.18160392\n",
      "Iteration 646, loss = 0.18047531\n",
      "Iteration 647, loss = 0.18130479\n",
      "Iteration 648, loss = 0.18455255\n",
      "Iteration 649, loss = 0.18131317\n",
      "Iteration 650, loss = 0.18048265\n",
      "Iteration 651, loss = 0.17796786\n",
      "Iteration 652, loss = 0.18372384\n",
      "Iteration 653, loss = 0.17904657\n",
      "Iteration 654, loss = 0.17872424\n",
      "Iteration 655, loss = 0.17742486\n",
      "Iteration 656, loss = 0.17700666\n",
      "Iteration 657, loss = 0.17723385\n",
      "Iteration 658, loss = 0.17579901\n",
      "Iteration 659, loss = 0.17598174\n",
      "Iteration 660, loss = 0.18083464\n",
      "Iteration 661, loss = 0.17700687\n",
      "Iteration 662, loss = 0.17269567\n",
      "Iteration 663, loss = 0.17314955\n",
      "Iteration 664, loss = 0.17610253\n",
      "Iteration 665, loss = 0.17459506\n",
      "Iteration 666, loss = 0.17392338\n",
      "Iteration 667, loss = 0.17252592\n",
      "Iteration 668, loss = 0.17279430\n",
      "Iteration 669, loss = 0.17430483\n",
      "Iteration 670, loss = 0.17280051\n",
      "Iteration 671, loss = 0.16984955\n",
      "Iteration 672, loss = 0.17007382\n",
      "Iteration 673, loss = 0.17224181\n",
      "Iteration 674, loss = 0.17031372\n",
      "Iteration 675, loss = 0.17188411\n",
      "Iteration 676, loss = 0.16840866\n",
      "Iteration 677, loss = 0.17077208\n",
      "Iteration 678, loss = 0.17157546\n",
      "Iteration 679, loss = 0.16762225\n",
      "Iteration 680, loss = 0.16752138\n",
      "Iteration 681, loss = 0.16637041\n",
      "Iteration 682, loss = 0.16763421\n",
      "Iteration 683, loss = 0.16770996\n",
      "Iteration 684, loss = 0.16599501\n",
      "Iteration 685, loss = 0.16565664\n",
      "Iteration 686, loss = 0.16676656\n",
      "Iteration 687, loss = 0.16503563\n",
      "Iteration 688, loss = 0.16448382\n",
      "Iteration 689, loss = 0.16432035\n",
      "Iteration 690, loss = 0.16405627\n",
      "Iteration 691, loss = 0.16385301\n",
      "Iteration 692, loss = 0.16212756\n",
      "Iteration 693, loss = 0.16226810\n",
      "Iteration 694, loss = 0.16210159\n",
      "Iteration 695, loss = 0.16286356\n",
      "Iteration 696, loss = 0.16173058\n",
      "Iteration 697, loss = 0.16008157\n",
      "Iteration 698, loss = 0.16048376\n",
      "Iteration 699, loss = 0.16638565\n",
      "Iteration 700, loss = 0.15888377\n",
      "Iteration 701, loss = 0.15954299\n",
      "Iteration 702, loss = 0.16069660\n",
      "Iteration 703, loss = 0.15957728\n",
      "Iteration 704, loss = 0.15885120\n",
      "Iteration 705, loss = 0.15699957\n",
      "Iteration 706, loss = 0.16196568\n",
      "Iteration 707, loss = 0.15842650\n",
      "Iteration 708, loss = 0.15580285\n",
      "Iteration 709, loss = 0.16151549\n",
      "Iteration 710, loss = 0.15867080\n",
      "Iteration 711, loss = 0.15435118\n",
      "Iteration 712, loss = 0.15894656\n",
      "Iteration 713, loss = 0.16020420\n",
      "Iteration 714, loss = 0.15186680\n",
      "Iteration 715, loss = 0.15363450\n",
      "Iteration 716, loss = 0.15200498\n",
      "Iteration 717, loss = 0.15923737\n",
      "Iteration 718, loss = 0.15566197\n",
      "Iteration 719, loss = 0.15083969\n",
      "Iteration 720, loss = 0.15365270\n",
      "Iteration 721, loss = 0.15254694\n",
      "Iteration 722, loss = 0.15128415\n",
      "Iteration 723, loss = 0.15396128\n",
      "Iteration 724, loss = 0.15156233\n",
      "Iteration 725, loss = 0.15147069\n",
      "Iteration 726, loss = 0.15306969\n",
      "Iteration 727, loss = 0.14950346\n",
      "Iteration 728, loss = 0.14888247\n",
      "Iteration 729, loss = 0.14814506\n",
      "Iteration 730, loss = 0.14746706\n",
      "Iteration 731, loss = 0.14974554\n",
      "Iteration 732, loss = 0.14768938\n",
      "Iteration 733, loss = 0.14767354\n",
      "Iteration 734, loss = 0.14575748\n",
      "Iteration 735, loss = 0.14838964\n",
      "Iteration 736, loss = 0.14720011\n",
      "Iteration 737, loss = 0.14605143\n",
      "Iteration 738, loss = 0.14717365\n",
      "Iteration 739, loss = 0.14362079\n",
      "Iteration 740, loss = 0.14274194\n",
      "Iteration 741, loss = 0.14344486\n",
      "Iteration 742, loss = 0.14330566\n",
      "Iteration 743, loss = 0.14770168\n",
      "Iteration 744, loss = 0.14309568\n",
      "Iteration 745, loss = 0.14253530\n",
      "Iteration 746, loss = 0.14163072\n",
      "Iteration 747, loss = 0.14228147\n",
      "Iteration 748, loss = 0.14024789\n",
      "Iteration 749, loss = 0.13850464\n",
      "Iteration 750, loss = 0.14209787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 751, loss = 0.14079754\n",
      "Iteration 752, loss = 0.14032256\n",
      "Iteration 753, loss = 0.13883729\n",
      "Iteration 754, loss = 0.13942432\n",
      "Iteration 755, loss = 0.14187750\n",
      "Iteration 756, loss = 0.14381075\n",
      "Iteration 757, loss = 0.13944714\n",
      "Iteration 758, loss = 0.13810940\n",
      "Iteration 759, loss = 0.13952078\n",
      "Iteration 760, loss = 0.13848014\n",
      "Iteration 761, loss = 0.13888591\n",
      "Iteration 762, loss = 0.13764821\n",
      "Iteration 763, loss = 0.13533753\n",
      "Iteration 764, loss = 0.13868511\n",
      "Iteration 765, loss = 0.13823777\n",
      "Iteration 766, loss = 0.13538958\n",
      "Iteration 767, loss = 0.13350954\n",
      "Iteration 768, loss = 0.13549015\n",
      "Iteration 769, loss = 0.13258057\n",
      "Iteration 770, loss = 0.13403514\n",
      "Iteration 771, loss = 0.13147538\n",
      "Iteration 772, loss = 0.13775118\n",
      "Iteration 773, loss = 0.13425429\n",
      "Iteration 774, loss = 0.13777280\n",
      "Iteration 775, loss = 0.13713878\n",
      "Iteration 776, loss = 0.13258952\n",
      "Iteration 777, loss = 0.13377650\n",
      "Iteration 778, loss = 0.13103380\n",
      "Iteration 779, loss = 0.12877832\n",
      "Iteration 780, loss = 0.12743778\n",
      "Iteration 781, loss = 0.12930440\n",
      "Iteration 782, loss = 0.12923815\n",
      "Iteration 783, loss = 0.12914145\n",
      "Iteration 784, loss = 0.13409382\n",
      "Iteration 785, loss = 0.13052182\n",
      "Iteration 786, loss = 0.12728507\n",
      "Iteration 787, loss = 0.12856402\n",
      "Iteration 788, loss = 0.12877681\n",
      "Iteration 789, loss = 0.12586534\n",
      "Iteration 790, loss = 0.12520228\n",
      "Iteration 791, loss = 0.12654141\n",
      "Iteration 792, loss = 0.12516757\n",
      "Iteration 793, loss = 0.12338591\n",
      "Iteration 794, loss = 0.12550691\n",
      "Iteration 795, loss = 0.12620458\n",
      "Iteration 796, loss = 0.12326958\n",
      "Iteration 797, loss = 0.12598925\n",
      "Iteration 798, loss = 0.12410127\n",
      "Iteration 799, loss = 0.12111991\n",
      "Iteration 800, loss = 0.12589930\n",
      "Iteration 801, loss = 0.12393243\n",
      "Iteration 802, loss = 0.12126942\n",
      "Iteration 803, loss = 0.12330225\n",
      "Iteration 804, loss = 0.12228006\n",
      "Iteration 805, loss = 0.12158658\n",
      "Iteration 806, loss = 0.12208607\n",
      "Iteration 807, loss = 0.12021508\n",
      "Iteration 808, loss = 0.11916729\n",
      "Iteration 809, loss = 0.12050506\n",
      "Iteration 810, loss = 0.11808403\n",
      "Iteration 811, loss = 0.11860947\n",
      "Iteration 812, loss = 0.11855956\n",
      "Iteration 813, loss = 0.11898074\n",
      "Iteration 814, loss = 0.11820687\n",
      "Iteration 815, loss = 0.11754770\n",
      "Iteration 816, loss = 0.11771206\n",
      "Iteration 817, loss = 0.11758538\n",
      "Iteration 818, loss = 0.11972041\n",
      "Iteration 819, loss = 0.11663055\n",
      "Iteration 820, loss = 0.11490477\n",
      "Iteration 821, loss = 0.11520625\n",
      "Iteration 822, loss = 0.11578940\n",
      "Iteration 823, loss = 0.11601253\n",
      "Iteration 824, loss = 0.11645007\n",
      "Iteration 825, loss = 0.11510528\n",
      "Iteration 826, loss = 0.11524198\n",
      "Iteration 827, loss = 0.11464500\n",
      "Iteration 828, loss = 0.11684128\n",
      "Iteration 829, loss = 0.11224139\n",
      "Iteration 830, loss = 0.11265158\n",
      "Iteration 831, loss = 0.11190350\n",
      "Iteration 832, loss = 0.10969037\n",
      "Iteration 833, loss = 0.11363533\n",
      "Iteration 834, loss = 0.10985480\n",
      "Iteration 835, loss = 0.11316885\n",
      "Iteration 836, loss = 0.11133117\n",
      "Iteration 837, loss = 0.11066038\n",
      "Iteration 838, loss = 0.10872157\n",
      "Iteration 839, loss = 0.10985067\n",
      "Iteration 840, loss = 0.11231773\n",
      "Iteration 841, loss = 0.11213971\n",
      "Iteration 842, loss = 0.11574134\n",
      "Iteration 843, loss = 0.11433639\n",
      "Iteration 844, loss = 0.11088965\n",
      "Iteration 845, loss = 0.11020248\n",
      "Iteration 846, loss = 0.10979311\n",
      "Iteration 847, loss = 0.10966359\n",
      "Iteration 848, loss = 0.11051939\n",
      "Iteration 849, loss = 0.10511323\n",
      "Iteration 850, loss = 0.10742983\n",
      "Iteration 851, loss = 0.10841027\n",
      "Iteration 852, loss = 0.10574543\n",
      "Iteration 853, loss = 0.10604856\n",
      "Iteration 854, loss = 0.10507850\n",
      "Iteration 855, loss = 0.10439103\n",
      "Iteration 856, loss = 0.10829230\n",
      "Iteration 857, loss = 0.10592165\n",
      "Iteration 858, loss = 0.10370740\n",
      "Iteration 859, loss = 0.10369522\n",
      "Iteration 860, loss = 0.10284201\n",
      "Iteration 861, loss = 0.10543862\n",
      "Iteration 862, loss = 0.10878082\n",
      "Iteration 863, loss = 0.10480220\n",
      "Iteration 864, loss = 0.10452368\n",
      "Iteration 865, loss = 0.10350131\n",
      "Iteration 866, loss = 0.10203414\n",
      "Iteration 867, loss = 0.09949743\n",
      "Iteration 868, loss = 0.10129064\n",
      "Iteration 869, loss = 0.10154106\n",
      "Iteration 870, loss = 0.10160985\n",
      "Iteration 871, loss = 0.09955094\n",
      "Iteration 872, loss = 0.10063465\n",
      "Iteration 873, loss = 0.10007853\n",
      "Iteration 874, loss = 0.09804757\n",
      "Iteration 875, loss = 0.09921117\n",
      "Iteration 876, loss = 0.10079461\n",
      "Iteration 877, loss = 0.10687883\n",
      "Iteration 878, loss = 0.10305877\n",
      "Iteration 879, loss = 0.09851373\n",
      "Iteration 880, loss = 0.09821256\n",
      "Iteration 881, loss = 0.09791217\n",
      "Iteration 882, loss = 0.09864929\n",
      "Iteration 883, loss = 0.09647059\n",
      "Iteration 884, loss = 0.09759040\n",
      "Iteration 885, loss = 0.10037124\n",
      "Iteration 886, loss = 0.10207195\n",
      "Iteration 887, loss = 0.09870567\n",
      "Iteration 888, loss = 0.09553292\n",
      "Iteration 889, loss = 0.09459439\n",
      "Iteration 890, loss = 0.09484684\n",
      "Iteration 891, loss = 0.09383892\n",
      "Iteration 892, loss = 0.09556783\n",
      "Iteration 893, loss = 0.09337358\n",
      "Iteration 894, loss = 0.09389057\n",
      "Iteration 895, loss = 0.09485490\n",
      "Iteration 896, loss = 0.09538746\n",
      "Iteration 897, loss = 0.10175276\n",
      "Iteration 898, loss = 0.09460946\n",
      "Iteration 899, loss = 0.09242271\n",
      "Iteration 900, loss = 0.09236464\n",
      "Iteration 901, loss = 0.09222313\n",
      "Iteration 902, loss = 0.09060962\n",
      "Iteration 903, loss = 0.09169650\n",
      "Iteration 904, loss = 0.08995352\n",
      "Iteration 905, loss = 0.08953314\n",
      "Iteration 906, loss = 0.09080896\n",
      "Iteration 907, loss = 0.09245388\n",
      "Iteration 908, loss = 0.08966632\n",
      "Iteration 909, loss = 0.09018684\n",
      "Iteration 910, loss = 0.08984309\n",
      "Iteration 911, loss = 0.08964369\n",
      "Iteration 912, loss = 0.09034697\n",
      "Iteration 913, loss = 0.08861378\n",
      "Iteration 914, loss = 0.09231600\n",
      "Iteration 915, loss = 0.08882185\n",
      "Iteration 916, loss = 0.08891092\n",
      "Iteration 917, loss = 0.08866819\n",
      "Iteration 918, loss = 0.08689527\n",
      "Iteration 919, loss = 0.08659989\n",
      "Iteration 920, loss = 0.08810870\n",
      "Iteration 921, loss = 0.08737452\n",
      "Iteration 922, loss = 0.09167265\n",
      "Iteration 923, loss = 0.09528947\n",
      "Iteration 924, loss = 0.08792294\n",
      "Iteration 925, loss = 0.08446244\n",
      "Iteration 926, loss = 0.08511547\n",
      "Iteration 927, loss = 0.08487609\n",
      "Iteration 928, loss = 0.08496323\n",
      "Iteration 929, loss = 0.08503004\n",
      "Iteration 930, loss = 0.08474295\n",
      "Iteration 931, loss = 0.08569856\n",
      "Iteration 932, loss = 0.08438064\n",
      "Iteration 933, loss = 0.08539688\n",
      "Iteration 934, loss = 0.08253001\n",
      "Iteration 935, loss = 0.08164065\n",
      "Iteration 936, loss = 0.08223915\n",
      "Iteration 937, loss = 0.08427216\n",
      "Iteration 938, loss = 0.08122218\n",
      "Iteration 939, loss = 0.08240668\n",
      "Iteration 940, loss = 0.08255193\n",
      "Iteration 941, loss = 0.08364680\n",
      "Iteration 942, loss = 0.08237367\n",
      "Iteration 943, loss = 0.08101523\n",
      "Iteration 944, loss = 0.08207241\n",
      "Iteration 945, loss = 0.08211428\n",
      "Iteration 946, loss = 0.08180888\n",
      "Iteration 947, loss = 0.08086582\n",
      "Iteration 948, loss = 0.07975536\n",
      "Iteration 949, loss = 0.07934222\n",
      "Iteration 950, loss = 0.07855490\n",
      "Iteration 951, loss = 0.07866011\n",
      "Iteration 952, loss = 0.07903293\n",
      "Iteration 953, loss = 0.07833496\n",
      "Iteration 954, loss = 0.07746957\n",
      "Iteration 955, loss = 0.07744338\n",
      "Iteration 956, loss = 0.07686239\n",
      "Iteration 957, loss = 0.07734950\n",
      "Iteration 958, loss = 0.07877968\n",
      "Iteration 959, loss = 0.07545459\n",
      "Iteration 960, loss = 0.07676503\n",
      "Iteration 961, loss = 0.07608569\n",
      "Iteration 962, loss = 0.07623280\n",
      "Iteration 963, loss = 0.08096217\n",
      "Iteration 964, loss = 0.07562110\n",
      "Iteration 965, loss = 0.07415091\n",
      "Iteration 966, loss = 0.07392059\n",
      "Iteration 967, loss = 0.07399750\n",
      "Iteration 968, loss = 0.07893066\n",
      "Iteration 969, loss = 0.07641272\n",
      "Iteration 970, loss = 0.07502378\n",
      "Iteration 971, loss = 0.07400753\n",
      "Iteration 972, loss = 0.07574273\n",
      "Iteration 973, loss = 0.07527222\n",
      "Iteration 974, loss = 0.07572345\n",
      "Iteration 975, loss = 0.07369790\n",
      "Iteration 976, loss = 0.07266886\n",
      "Iteration 977, loss = 0.07642969\n",
      "Iteration 978, loss = 0.07563000\n",
      "Iteration 979, loss = 0.07270500\n",
      "Iteration 980, loss = 0.07310223\n",
      "Iteration 981, loss = 0.07065003\n",
      "Iteration 982, loss = 0.07226696\n",
      "Iteration 983, loss = 0.07094987\n",
      "Iteration 984, loss = 0.06998985\n",
      "Iteration 985, loss = 0.07076397\n",
      "Iteration 986, loss = 0.07191533\n",
      "Iteration 987, loss = 0.07042954\n",
      "Iteration 988, loss = 0.07345318\n",
      "Iteration 989, loss = 0.07050121\n",
      "Iteration 990, loss = 0.07127297\n",
      "Iteration 991, loss = 0.07101764\n",
      "Iteration 992, loss = 0.07199837\n",
      "Iteration 993, loss = 0.07087953\n",
      "Iteration 994, loss = 0.07197454\n",
      "Iteration 995, loss = 0.06782582\n",
      "Iteration 996, loss = 0.06709124\n",
      "Iteration 997, loss = 0.06928807\n",
      "Iteration 998, loss = 0.06778681\n",
      "Iteration 999, loss = 0.06736967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, loss = 0.06671019\n",
      "Iteration 1001, loss = 0.06770560\n",
      "Iteration 1002, loss = 0.06704662\n",
      "Iteration 1003, loss = 0.06653155\n",
      "Iteration 1004, loss = 0.06889190\n",
      "Iteration 1005, loss = 0.06643258\n",
      "Iteration 1006, loss = 0.06641979\n",
      "Iteration 1007, loss = 0.06613126\n",
      "Iteration 1008, loss = 0.06615759\n",
      "Iteration 1009, loss = 0.06633816\n",
      "Iteration 1010, loss = 0.06666515\n",
      "Iteration 1011, loss = 0.06456407\n",
      "Iteration 1012, loss = 0.06519064\n",
      "Iteration 1013, loss = 0.06427201\n",
      "Iteration 1014, loss = 0.06605009\n",
      "Iteration 1015, loss = 0.06448053\n",
      "Iteration 1016, loss = 0.06440878\n",
      "Iteration 1017, loss = 0.06457584\n",
      "Iteration 1018, loss = 0.06346698\n",
      "Iteration 1019, loss = 0.06503696\n",
      "Iteration 1020, loss = 0.06365141\n",
      "Iteration 1021, loss = 0.06517092\n",
      "Iteration 1022, loss = 0.06200813\n",
      "Iteration 1023, loss = 0.06289725\n",
      "Iteration 1024, loss = 0.06262919\n",
      "Iteration 1025, loss = 0.06100050\n",
      "Iteration 1026, loss = 0.06171122\n",
      "Iteration 1027, loss = 0.06385920\n",
      "Iteration 1028, loss = 0.06237890\n",
      "Iteration 1029, loss = 0.06098657\n",
      "Iteration 1030, loss = 0.06374411\n",
      "Iteration 1031, loss = 0.06161099\n",
      "Iteration 1032, loss = 0.06124845\n",
      "Iteration 1033, loss = 0.05942962\n",
      "Iteration 1034, loss = 0.06388355\n",
      "Iteration 1035, loss = 0.06411133\n",
      "Iteration 1036, loss = 0.06614921\n",
      "Iteration 1037, loss = 0.06113774\n",
      "Iteration 1038, loss = 0.05795179\n",
      "Iteration 1039, loss = 0.05874007\n",
      "Iteration 1040, loss = 0.06110535\n",
      "Iteration 1041, loss = 0.05848332\n",
      "Iteration 1042, loss = 0.05963916\n",
      "Iteration 1043, loss = 0.05848633\n",
      "Iteration 1044, loss = 0.05854054\n",
      "Iteration 1045, loss = 0.05851546\n",
      "Iteration 1046, loss = 0.05830641\n",
      "Iteration 1047, loss = 0.05682679\n",
      "Iteration 1048, loss = 0.05897275\n",
      "Iteration 1049, loss = 0.05985028\n",
      "Iteration 1050, loss = 0.06034116\n",
      "Iteration 1051, loss = 0.05588121\n",
      "Iteration 1052, loss = 0.05546207\n",
      "Iteration 1053, loss = 0.05514659\n",
      "Iteration 1054, loss = 0.05655096\n",
      "Iteration 1055, loss = 0.05840524\n",
      "Iteration 1056, loss = 0.05567640\n",
      "Iteration 1057, loss = 0.05574721\n",
      "Iteration 1058, loss = 0.05811250\n",
      "Iteration 1059, loss = 0.05471643\n",
      "Iteration 1060, loss = 0.05491332\n",
      "Iteration 1061, loss = 0.05586133\n",
      "Iteration 1062, loss = 0.05428205\n",
      "Iteration 1063, loss = 0.05561901\n",
      "Iteration 1064, loss = 0.05292745\n",
      "Iteration 1065, loss = 0.05301417\n",
      "Iteration 1066, loss = 0.05525009\n",
      "Iteration 1067, loss = 0.05280818\n",
      "Iteration 1068, loss = 0.05348695\n",
      "Iteration 1069, loss = 0.05264492\n",
      "Iteration 1070, loss = 0.05489059\n",
      "Iteration 1071, loss = 0.05379896\n",
      "Iteration 1072, loss = 0.05378773\n",
      "Iteration 1073, loss = 0.05316063\n",
      "Iteration 1074, loss = 0.05530361\n",
      "Iteration 1075, loss = 0.05619775\n",
      "Iteration 1076, loss = 0.05319854\n",
      "Iteration 1077, loss = 0.05203799\n",
      "Iteration 1078, loss = 0.05954854\n",
      "Iteration 1079, loss = 0.05390694\n",
      "Iteration 1080, loss = 0.05094365\n",
      "Iteration 1081, loss = 0.05144941\n",
      "Iteration 1082, loss = 0.05135957\n",
      "Iteration 1083, loss = 0.05106927\n",
      "Iteration 1084, loss = 0.05038812\n",
      "Iteration 1085, loss = 0.04956834\n",
      "Iteration 1086, loss = 0.04957713\n",
      "Iteration 1087, loss = 0.05098291\n",
      "Iteration 1088, loss = 0.05178785\n",
      "Iteration 1089, loss = 0.04844305\n",
      "Iteration 1090, loss = 0.04871537\n",
      "Iteration 1091, loss = 0.04998079\n",
      "Iteration 1092, loss = 0.05009496\n",
      "Iteration 1093, loss = 0.05027071\n",
      "Iteration 1094, loss = 0.04913333\n",
      "Iteration 1095, loss = 0.04905482\n",
      "Iteration 1096, loss = 0.05015565\n",
      "Iteration 1097, loss = 0.05064855\n",
      "Iteration 1098, loss = 0.04822660\n",
      "Iteration 1099, loss = 0.05107690\n",
      "Iteration 1100, loss = 0.04778101\n",
      "Iteration 1101, loss = 0.04869299\n",
      "Iteration 1102, loss = 0.04849885\n",
      "Iteration 1103, loss = 0.04749906\n",
      "Iteration 1104, loss = 0.04776677\n",
      "Iteration 1105, loss = 0.04724264\n",
      "Iteration 1106, loss = 0.04678067\n",
      "Iteration 1107, loss = 0.05177476\n",
      "Iteration 1108, loss = 0.04811031\n",
      "Iteration 1109, loss = 0.04611906\n",
      "Iteration 1110, loss = 0.04594174\n",
      "Iteration 1111, loss = 0.04624554\n",
      "Iteration 1112, loss = 0.04672176\n",
      "Iteration 1113, loss = 0.04735930\n",
      "Iteration 1114, loss = 0.04636145\n",
      "Iteration 1115, loss = 0.04474838\n",
      "Iteration 1116, loss = 0.04479180\n",
      "Iteration 1117, loss = 0.04425837\n",
      "Iteration 1118, loss = 0.04445970\n",
      "Iteration 1119, loss = 0.04525163\n",
      "Iteration 1120, loss = 0.04530798\n",
      "Iteration 1121, loss = 0.04578047\n",
      "Iteration 1122, loss = 0.04413345\n",
      "Iteration 1123, loss = 0.04445686\n",
      "Iteration 1124, loss = 0.04423319\n",
      "Iteration 1125, loss = 0.04334107\n",
      "Iteration 1126, loss = 0.04286977\n",
      "Iteration 1127, loss = 0.04382619\n",
      "Iteration 1128, loss = 0.04746347\n",
      "Iteration 1129, loss = 0.04497277\n",
      "Iteration 1130, loss = 0.04483195\n",
      "Iteration 1131, loss = 0.04589055\n",
      "Iteration 1132, loss = 0.04464789\n",
      "Iteration 1133, loss = 0.04328461\n",
      "Iteration 1134, loss = 0.04208793\n",
      "Iteration 1135, loss = 0.04268097\n",
      "Iteration 1136, loss = 0.04374047\n",
      "Iteration 1137, loss = 0.04263963\n",
      "Iteration 1138, loss = 0.04237751\n",
      "Iteration 1139, loss = 0.04296347\n",
      "Iteration 1140, loss = 0.04167345\n",
      "Iteration 1141, loss = 0.04175485\n",
      "Iteration 1142, loss = 0.04084810\n",
      "Iteration 1143, loss = 0.04058046\n",
      "Iteration 1144, loss = 0.04152890\n",
      "Iteration 1145, loss = 0.04499947\n",
      "Iteration 1146, loss = 0.04289201\n",
      "Iteration 1147, loss = 0.04054880\n",
      "Iteration 1148, loss = 0.04003946\n",
      "Iteration 1149, loss = 0.04003974\n",
      "Iteration 1150, loss = 0.04069826\n",
      "Iteration 1151, loss = 0.04326497\n",
      "Iteration 1152, loss = 0.04077692\n",
      "Iteration 1153, loss = 0.04039829\n",
      "Iteration 1154, loss = 0.03905823\n",
      "Iteration 1155, loss = 0.04102911\n",
      "Iteration 1156, loss = 0.03991361\n",
      "Iteration 1157, loss = 0.03956759\n",
      "Iteration 1158, loss = 0.03904994\n",
      "Iteration 1159, loss = 0.03944010\n",
      "Iteration 1160, loss = 0.03982490\n",
      "Iteration 1161, loss = 0.04057153\n",
      "Iteration 1162, loss = 0.04060816\n",
      "Iteration 1163, loss = 0.03757595\n",
      "Iteration 1164, loss = 0.04101770\n",
      "Iteration 1165, loss = 0.03740331\n",
      "Iteration 1166, loss = 0.03793596\n",
      "Iteration 1167, loss = 0.03817545\n",
      "Iteration 1168, loss = 0.03805410\n",
      "Iteration 1169, loss = 0.03756535\n",
      "Iteration 1170, loss = 0.03732566\n",
      "Iteration 1171, loss = 0.03673719\n",
      "Iteration 1172, loss = 0.03780350\n",
      "Iteration 1173, loss = 0.03652064\n",
      "Iteration 1174, loss = 0.03666000\n",
      "Iteration 1175, loss = 0.03787632\n",
      "Iteration 1176, loss = 0.03698280\n",
      "Iteration 1177, loss = 0.04016336\n",
      "Iteration 1178, loss = 0.03691719\n",
      "Iteration 1179, loss = 0.03695114\n",
      "Iteration 1180, loss = 0.03804711\n",
      "Iteration 1181, loss = 0.03557514\n",
      "Iteration 1182, loss = 0.03514692\n",
      "Iteration 1183, loss = 0.03499591\n",
      "Iteration 1184, loss = 0.03927697\n",
      "Iteration 1185, loss = 0.03841224\n",
      "Iteration 1186, loss = 0.03452594\n",
      "Iteration 1187, loss = 0.03499154\n",
      "Iteration 1188, loss = 0.03463010\n",
      "Iteration 1189, loss = 0.03351435\n",
      "Iteration 1190, loss = 0.03409435\n",
      "Iteration 1191, loss = 0.03382482\n",
      "Iteration 1192, loss = 0.03530810\n",
      "Iteration 1193, loss = 0.03477840\n",
      "Iteration 1194, loss = 0.03341875\n",
      "Iteration 1195, loss = 0.03431966\n",
      "Iteration 1196, loss = 0.03681056\n",
      "Iteration 1197, loss = 0.03722642\n",
      "Iteration 1198, loss = 0.03370685\n",
      "Iteration 1199, loss = 0.03343495\n",
      "Iteration 1200, loss = 0.03258126\n",
      "Iteration 1201, loss = 0.03591255\n",
      "Iteration 1202, loss = 0.03309645\n",
      "Iteration 1203, loss = 0.03263419\n",
      "Iteration 1204, loss = 0.03221320\n",
      "Iteration 1205, loss = 0.03172903\n",
      "Iteration 1206, loss = 0.03233820\n",
      "Iteration 1207, loss = 0.03244601\n",
      "Iteration 1208, loss = 0.03412908\n",
      "Iteration 1209, loss = 0.03183152\n",
      "Iteration 1210, loss = 0.03290670\n",
      "Iteration 1211, loss = 0.03156215\n",
      "Iteration 1212, loss = 0.03250029\n",
      "Iteration 1213, loss = 0.03129225\n",
      "Iteration 1214, loss = 0.03140983\n",
      "Iteration 1215, loss = 0.03094445\n",
      "Iteration 1216, loss = 0.03107469\n",
      "Iteration 1217, loss = 0.03157093\n",
      "Iteration 1218, loss = 0.03152967\n",
      "Iteration 1219, loss = 0.03135636\n",
      "Iteration 1220, loss = 0.03091339\n",
      "Iteration 1221, loss = 0.03168006\n",
      "Iteration 1222, loss = 0.03041615\n",
      "Iteration 1223, loss = 0.03349044\n",
      "Iteration 1224, loss = 0.03355795\n",
      "Iteration 1225, loss = 0.03013963\n",
      "Iteration 1226, loss = 0.02925775\n",
      "Iteration 1227, loss = 0.03009470\n",
      "Iteration 1228, loss = 0.03056639\n",
      "Iteration 1229, loss = 0.02987791\n",
      "Iteration 1230, loss = 0.02943465\n",
      "Iteration 1231, loss = 0.03074096\n",
      "Iteration 1232, loss = 0.03030012\n",
      "Iteration 1233, loss = 0.02877430\n",
      "Iteration 1234, loss = 0.02913661\n",
      "Iteration 1235, loss = 0.03007425\n",
      "Iteration 1236, loss = 0.02957811\n",
      "Iteration 1237, loss = 0.03118441\n",
      "Iteration 1238, loss = 0.02904918\n",
      "Iteration 1239, loss = 0.02943844\n",
      "Iteration 1240, loss = 0.02998824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1241, loss = 0.02921715\n",
      "Iteration 1242, loss = 0.02845349\n",
      "Iteration 1243, loss = 0.02905618\n",
      "Iteration 1244, loss = 0.02943566\n",
      "Iteration 1245, loss = 0.02802853\n",
      "Iteration 1246, loss = 0.02751952\n",
      "Iteration 1247, loss = 0.02794128\n",
      "Iteration 1248, loss = 0.02991151\n",
      "Iteration 1249, loss = 0.02749183\n",
      "Iteration 1250, loss = 0.02700046\n",
      "Iteration 1251, loss = 0.02710629\n",
      "Iteration 1252, loss = 0.02629996\n",
      "Iteration 1253, loss = 0.02739656\n",
      "Iteration 1254, loss = 0.02687819\n",
      "Iteration 1255, loss = 0.02766028\n",
      "Iteration 1256, loss = 0.02734299\n",
      "Iteration 1257, loss = 0.02703398\n",
      "Iteration 1258, loss = 0.02691762\n",
      "Iteration 1259, loss = 0.02746089\n",
      "Iteration 1260, loss = 0.02773186\n",
      "Iteration 1261, loss = 0.02553256\n",
      "Iteration 1262, loss = 0.02618664\n",
      "Iteration 1263, loss = 0.02696769\n",
      "Iteration 1264, loss = 0.02602700\n",
      "Iteration 1265, loss = 0.02727868\n",
      "Iteration 1266, loss = 0.02574722\n",
      "Iteration 1267, loss = 0.02604681\n",
      "Iteration 1268, loss = 0.02889024\n",
      "Iteration 1269, loss = 0.02778394\n",
      "Iteration 1270, loss = 0.02551123\n",
      "Iteration 1271, loss = 0.02493214\n",
      "Iteration 1272, loss = 0.02469924\n",
      "Iteration 1273, loss = 0.02490205\n",
      "Iteration 1274, loss = 0.02533900\n",
      "Iteration 1275, loss = 0.02476811\n",
      "Iteration 1276, loss = 0.02520465\n",
      "Iteration 1277, loss = 0.02475839\n",
      "Iteration 1278, loss = 0.02490901\n",
      "Iteration 1279, loss = 0.02451911\n",
      "Iteration 1280, loss = 0.02513177\n",
      "Iteration 1281, loss = 0.02417784\n",
      "Iteration 1282, loss = 0.02439768\n",
      "Iteration 1283, loss = 0.02477919\n",
      "Iteration 1284, loss = 0.02405428\n",
      "Iteration 1285, loss = 0.02332223\n",
      "Iteration 1286, loss = 0.02471254\n",
      "Iteration 1287, loss = 0.02389729\n",
      "Iteration 1288, loss = 0.02467131\n",
      "Iteration 1289, loss = 0.02522934\n",
      "Iteration 1290, loss = 0.02356429\n",
      "Iteration 1291, loss = 0.02390657\n",
      "Iteration 1292, loss = 0.02260165\n",
      "Iteration 1293, loss = 0.02344717\n",
      "Iteration 1294, loss = 0.02253319\n",
      "Iteration 1295, loss = 0.02306179\n",
      "Iteration 1296, loss = 0.02295136\n",
      "Iteration 1297, loss = 0.02404181\n",
      "Iteration 1298, loss = 0.02208526\n",
      "Iteration 1299, loss = 0.02252292\n",
      "Iteration 1300, loss = 0.02330530\n",
      "Iteration 1301, loss = 0.02386012\n",
      "Iteration 1302, loss = 0.02262752\n",
      "Iteration 1303, loss = 0.02259407\n",
      "Iteration 1304, loss = 0.02246234\n",
      "Iteration 1305, loss = 0.02238720\n",
      "Iteration 1306, loss = 0.02261064\n",
      "Iteration 1307, loss = 0.02177332\n",
      "Iteration 1308, loss = 0.02399883\n",
      "Iteration 1309, loss = 0.02403157\n",
      "Iteration 1310, loss = 0.02193733\n",
      "Iteration 1311, loss = 0.02127072\n",
      "Iteration 1312, loss = 0.02136446\n",
      "Iteration 1313, loss = 0.02242048\n",
      "Iteration 1314, loss = 0.02095304\n",
      "Iteration 1315, loss = 0.02285754\n",
      "Iteration 1316, loss = 0.02126248\n",
      "Iteration 1317, loss = 0.02243296\n",
      "Iteration 1318, loss = 0.02050392\n",
      "Iteration 1319, loss = 0.02105453\n",
      "Iteration 1320, loss = 0.02154990\n",
      "Iteration 1321, loss = 0.02050317\n",
      "Iteration 1322, loss = 0.02092202\n",
      "Iteration 1323, loss = 0.02072964\n",
      "Iteration 1324, loss = 0.02041993\n",
      "Iteration 1325, loss = 0.02260838\n",
      "Iteration 1326, loss = 0.02268897\n",
      "Iteration 1327, loss = 0.02069160\n",
      "Iteration 1328, loss = 0.02099974\n",
      "Iteration 1329, loss = 0.01956297\n",
      "Iteration 1330, loss = 0.01987556\n",
      "Iteration 1331, loss = 0.02009754\n",
      "Iteration 1332, loss = 0.02103839\n",
      "Iteration 1333, loss = 0.02011791\n",
      "Iteration 1334, loss = 0.02088251\n",
      "Iteration 1335, loss = 0.02184538\n",
      "Iteration 1336, loss = 0.01993844\n",
      "Iteration 1337, loss = 0.01977766\n",
      "Iteration 1338, loss = 0.01923923\n",
      "Iteration 1339, loss = 0.01903700\n",
      "Iteration 1340, loss = 0.01919406\n",
      "Iteration 1341, loss = 0.01870224\n",
      "Iteration 1342, loss = 0.01873846\n",
      "Iteration 1343, loss = 0.01905496\n",
      "Iteration 1344, loss = 0.01857945\n",
      "Iteration 1345, loss = 0.01872177\n",
      "Iteration 1346, loss = 0.01813277\n",
      "Iteration 1347, loss = 0.01911876\n",
      "Iteration 1348, loss = 0.01943326\n",
      "Iteration 1349, loss = 0.01954391\n",
      "Iteration 1350, loss = 0.01952086\n",
      "Iteration 1351, loss = 0.01929645\n",
      "Iteration 1352, loss = 0.01770795\n",
      "Iteration 1353, loss = 0.01812156\n",
      "Iteration 1354, loss = 0.01849491\n",
      "Iteration 1355, loss = 0.01791274\n",
      "Iteration 1356, loss = 0.01768318\n",
      "Iteration 1357, loss = 0.01838542\n",
      "Iteration 1358, loss = 0.01758348\n",
      "Iteration 1359, loss = 0.01899394\n",
      "Iteration 1360, loss = 0.01910571\n",
      "Iteration 1361, loss = 0.01790955\n",
      "Iteration 1362, loss = 0.01740012\n",
      "Iteration 1363, loss = 0.01800904\n",
      "Iteration 1364, loss = 0.01779472\n",
      "Iteration 1365, loss = 0.01734514\n",
      "Iteration 1366, loss = 0.01702713\n",
      "Iteration 1367, loss = 0.01645556\n",
      "Iteration 1368, loss = 0.01680730\n",
      "Iteration 1369, loss = 0.01750341\n",
      "Iteration 1370, loss = 0.01801345\n",
      "Iteration 1371, loss = 0.01703046\n",
      "Iteration 1372, loss = 0.01745904\n",
      "Iteration 1373, loss = 0.01787105\n",
      "Iteration 1374, loss = 0.01775072\n",
      "Iteration 1375, loss = 0.01611050\n",
      "Iteration 1376, loss = 0.01775294\n",
      "Iteration 1377, loss = 0.01668311\n",
      "Iteration 1378, loss = 0.01679018\n",
      "Iteration 1379, loss = 0.01589050\n",
      "Iteration 1380, loss = 0.01651629\n",
      "Iteration 1381, loss = 0.01687307\n",
      "Iteration 1382, loss = 0.01598954\n",
      "Iteration 1383, loss = 0.01692736\n",
      "Iteration 1384, loss = 0.01588452\n",
      "Iteration 1385, loss = 0.01572055\n",
      "Iteration 1386, loss = 0.01579994\n",
      "Iteration 1387, loss = 0.01653594\n",
      "Iteration 1388, loss = 0.01668966\n",
      "Iteration 1389, loss = 0.01607405\n",
      "Iteration 1390, loss = 0.01703573\n",
      "Iteration 1391, loss = 0.01618623\n",
      "Iteration 1392, loss = 0.01706632\n",
      "Iteration 1393, loss = 0.01531341\n",
      "Iteration 1394, loss = 0.01488021\n",
      "Iteration 1395, loss = 0.01571457\n",
      "Iteration 1396, loss = 0.01513851\n",
      "Iteration 1397, loss = 0.01524779\n",
      "Iteration 1398, loss = 0.01549233\n",
      "Iteration 1399, loss = 0.01499381\n",
      "Iteration 1400, loss = 0.01479675\n",
      "Iteration 1401, loss = 0.01519229\n",
      "Iteration 1402, loss = 0.01740828\n",
      "Iteration 1403, loss = 0.01515918\n",
      "Iteration 1404, loss = 0.01463233\n",
      "Iteration 1405, loss = 0.01425394\n",
      "Iteration 1406, loss = 0.01390646\n",
      "Iteration 1407, loss = 0.01446753\n",
      "Iteration 1408, loss = 0.01417977\n",
      "Iteration 1409, loss = 0.01379495\n",
      "Iteration 1410, loss = 0.01404304\n",
      "Iteration 1411, loss = 0.01454116\n",
      "Iteration 1412, loss = 0.01436553\n",
      "Iteration 1413, loss = 0.01451931\n",
      "Iteration 1414, loss = 0.01478689\n",
      "Iteration 1415, loss = 0.01415933\n",
      "Iteration 1416, loss = 0.01435991\n",
      "Iteration 1417, loss = 0.01375864\n",
      "Iteration 1418, loss = 0.01324621\n",
      "Iteration 1419, loss = 0.01312108\n",
      "Iteration 1420, loss = 0.01392049\n",
      "Iteration 1421, loss = 0.01343728\n",
      "Iteration 1422, loss = 0.01439762\n",
      "Iteration 1423, loss = 0.01326099\n",
      "Iteration 1424, loss = 0.01479376\n",
      "Iteration 1425, loss = 0.01421195\n",
      "Iteration 1426, loss = 0.01555042\n",
      "Iteration 1427, loss = 0.01353877\n",
      "Iteration 1428, loss = 0.01327423\n",
      "Iteration 1429, loss = 0.01328794\n",
      "Iteration 1430, loss = 0.01299574\n",
      "Iteration 1431, loss = 0.01324522\n",
      "Iteration 1432, loss = 0.01382098\n",
      "Iteration 1433, loss = 0.01278154\n",
      "Iteration 1434, loss = 0.01289523\n",
      "Iteration 1435, loss = 0.01325960\n",
      "Iteration 1436, loss = 0.01304824\n",
      "Iteration 1437, loss = 0.01329313\n",
      "Iteration 1438, loss = 0.01270077\n",
      "Iteration 1439, loss = 0.01276325\n",
      "Iteration 1440, loss = 0.01246019\n",
      "Iteration 1441, loss = 0.01231403\n",
      "Iteration 1442, loss = 0.01293136\n",
      "Iteration 1443, loss = 0.01202876\n",
      "Iteration 1444, loss = 0.01236271\n",
      "Iteration 1445, loss = 0.01280543\n",
      "Iteration 1446, loss = 0.01308629\n",
      "Iteration 1447, loss = 0.01262474\n",
      "Iteration 1448, loss = 0.01244977\n",
      "Iteration 1449, loss = 0.01272320\n",
      "Iteration 1450, loss = 0.01264109\n",
      "Iteration 1451, loss = 0.01178414\n",
      "Iteration 1452, loss = 0.01154483\n",
      "Iteration 1453, loss = 0.01285044\n",
      "Iteration 1454, loss = 0.01160384\n",
      "Iteration 1455, loss = 0.01169495\n",
      "Iteration 1456, loss = 0.01145340\n",
      "Iteration 1457, loss = 0.01187679\n",
      "Iteration 1458, loss = 0.01218050\n",
      "Iteration 1459, loss = 0.01263682\n",
      "Iteration 1460, loss = 0.01165138\n",
      "Iteration 1461, loss = 0.01176888\n",
      "Iteration 1462, loss = 0.01314182\n",
      "Iteration 1463, loss = 0.01770355\n",
      "Iteration 1464, loss = 0.01347211\n",
      "Iteration 1465, loss = 0.01332690\n",
      "Iteration 1466, loss = 0.01226111\n",
      "Iteration 1467, loss = 0.01118965\n",
      "Iteration 1468, loss = 0.01107348\n",
      "Iteration 1469, loss = 0.01084507\n",
      "Iteration 1470, loss = 0.01087159\n",
      "Iteration 1471, loss = 0.01073192\n",
      "Iteration 1472, loss = 0.01057043\n",
      "Iteration 1473, loss = 0.01062958\n",
      "Iteration 1474, loss = 0.01089091\n",
      "Iteration 1475, loss = 0.01170922\n",
      "Iteration 1476, loss = 0.01134683\n",
      "Iteration 1477, loss = 0.01080085\n",
      "Iteration 1478, loss = 0.01178727\n",
      "Iteration 1479, loss = 0.01025165\n",
      "Iteration 1480, loss = 0.01054376\n",
      "Iteration 1481, loss = 0.01035407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1482, loss = 0.01042056\n",
      "Iteration 1483, loss = 0.01084947\n",
      "Iteration 1484, loss = 0.01100022\n",
      "Iteration 1485, loss = 0.01067759\n",
      "Iteration 1486, loss = 0.01223192\n",
      "Iteration 1487, loss = 0.01071331\n",
      "Iteration 1488, loss = 0.01019778\n",
      "Iteration 1489, loss = 0.01019853\n",
      "Iteration 1490, loss = 0.01058824\n",
      "Iteration 1491, loss = 0.01084326\n",
      "Iteration 1492, loss = 0.01129981\n",
      "Iteration 1493, loss = 0.01395306\n",
      "Iteration 1494, loss = 0.01050607\n",
      "Iteration 1495, loss = 0.00971561\n",
      "Iteration 1496, loss = 0.00987237\n",
      "Iteration 1497, loss = 0.00970861\n",
      "Iteration 1498, loss = 0.01009847\n",
      "Iteration 1499, loss = 0.00954183\n",
      "Iteration 1500, loss = 0.00950896\n",
      "Iteration 1501, loss = 0.00940409\n",
      "Iteration 1502, loss = 0.00928312\n",
      "Iteration 1503, loss = 0.00937664\n",
      "Iteration 1504, loss = 0.00969416\n",
      "Iteration 1505, loss = 0.00970746\n",
      "Iteration 1506, loss = 0.00958551\n",
      "Iteration 1507, loss = 0.00946793\n",
      "Iteration 1508, loss = 0.01011667\n",
      "Iteration 1509, loss = 0.00921961\n",
      "Iteration 1510, loss = 0.00923615\n",
      "Iteration 1511, loss = 0.00900050\n",
      "Iteration 1512, loss = 0.00959003\n",
      "Iteration 1513, loss = 0.00911604\n",
      "Iteration 1514, loss = 0.00907895\n",
      "Iteration 1515, loss = 0.00929534\n",
      "Iteration 1516, loss = 0.00891521\n",
      "Iteration 1517, loss = 0.00894047\n",
      "Iteration 1518, loss = 0.00914348\n",
      "Iteration 1519, loss = 0.00958961\n",
      "Iteration 1520, loss = 0.00900785\n",
      "Iteration 1521, loss = 0.00888815\n",
      "Iteration 1522, loss = 0.00869571\n",
      "Iteration 1523, loss = 0.00885614\n",
      "Iteration 1524, loss = 0.00912420\n",
      "Iteration 1525, loss = 0.00876576\n",
      "Iteration 1526, loss = 0.00847941\n",
      "Iteration 1527, loss = 0.00914186\n",
      "Iteration 1528, loss = 0.00846104\n",
      "Iteration 1529, loss = 0.00852620\n",
      "Iteration 1530, loss = 0.00876232\n",
      "Iteration 1531, loss = 0.00849526\n",
      "Iteration 1532, loss = 0.00975189\n",
      "Iteration 1533, loss = 0.00939637\n",
      "Iteration 1534, loss = 0.01005594\n",
      "Iteration 1535, loss = 0.00886758\n",
      "Iteration 1536, loss = 0.00826734\n",
      "Iteration 1537, loss = 0.00821601\n",
      "Iteration 1538, loss = 0.00894926\n",
      "Iteration 1539, loss = 0.00861708\n",
      "Iteration 1540, loss = 0.00864444\n",
      "Iteration 1541, loss = 0.00818137\n",
      "Iteration 1542, loss = 0.00880932\n",
      "Iteration 1543, loss = 0.00846443\n",
      "Iteration 1544, loss = 0.00804897\n",
      "Iteration 1545, loss = 0.00817165\n",
      "Iteration 1546, loss = 0.00801238\n",
      "Iteration 1547, loss = 0.00780716\n",
      "Iteration 1548, loss = 0.00781095\n",
      "Iteration 1549, loss = 0.00790512\n",
      "Iteration 1550, loss = 0.00771865\n",
      "Iteration 1551, loss = 0.00822615\n",
      "Iteration 1552, loss = 0.00820400\n",
      "Iteration 1553, loss = 0.00820040\n",
      "Iteration 1554, loss = 0.00849158\n",
      "Iteration 1555, loss = 0.00785184\n",
      "Iteration 1556, loss = 0.00846887\n",
      "Iteration 1557, loss = 0.00803864\n",
      "Iteration 1558, loss = 0.00755779\n",
      "Iteration 1559, loss = 0.00736293\n",
      "Iteration 1560, loss = 0.00774689\n",
      "Iteration 1561, loss = 0.00774610\n",
      "Iteration 1562, loss = 0.00735585\n",
      "Iteration 1563, loss = 0.00752316\n",
      "Iteration 1564, loss = 0.00767700\n",
      "Iteration 1565, loss = 0.00711301\n",
      "Iteration 1566, loss = 0.00763035\n",
      "Iteration 1567, loss = 0.00721440\n",
      "Iteration 1568, loss = 0.00768811\n",
      "Iteration 1569, loss = 0.00723003\n",
      "Iteration 1570, loss = 0.00739818\n",
      "Iteration 1571, loss = 0.00729043\n",
      "Iteration 1572, loss = 0.00761633\n",
      "Iteration 1573, loss = 0.00762928\n",
      "Iteration 1574, loss = 0.00720656\n",
      "Iteration 1575, loss = 0.00732525\n",
      "Iteration 1576, loss = 0.00743284\n",
      "Iteration 1577, loss = 0.00752487\n",
      "Iteration 1578, loss = 0.00699837\n",
      "Iteration 1579, loss = 0.00821709\n",
      "Iteration 1580, loss = 0.00844012\n",
      "Iteration 1581, loss = 0.00711495\n",
      "Iteration 1582, loss = 0.00710032\n",
      "Iteration 1583, loss = 0.00695840\n",
      "Iteration 1584, loss = 0.00732152\n",
      "Iteration 1585, loss = 0.00689162\n",
      "Iteration 1586, loss = 0.00694596\n",
      "Iteration 1587, loss = 0.00637915\n",
      "Iteration 1588, loss = 0.00668724\n",
      "Iteration 1589, loss = 0.00676984\n",
      "Iteration 1590, loss = 0.00717099\n",
      "Iteration 1591, loss = 0.00671235\n",
      "Iteration 1592, loss = 0.00645696\n",
      "Iteration 1593, loss = 0.00661224\n",
      "Iteration 1594, loss = 0.00653016\n",
      "Iteration 1595, loss = 0.00632036\n",
      "Iteration 1596, loss = 0.00622760\n",
      "Iteration 1597, loss = 0.00689242\n",
      "Iteration 1598, loss = 0.00659606\n",
      "Iteration 1599, loss = 0.00656870\n",
      "Iteration 1600, loss = 0.00774323\n",
      "Iteration 1601, loss = 0.00656930\n",
      "Iteration 1602, loss = 0.00641253\n",
      "Iteration 1603, loss = 0.00670911\n",
      "Iteration 1604, loss = 0.00633270\n",
      "Iteration 1605, loss = 0.00615679\n",
      "Iteration 1606, loss = 0.00624445\n",
      "Iteration 1607, loss = 0.00650128\n",
      "Iteration 1608, loss = 0.00618469\n",
      "Iteration 1609, loss = 0.00642313\n",
      "Iteration 1610, loss = 0.00751895\n",
      "Iteration 1611, loss = 0.00680633\n",
      "Iteration 1612, loss = 0.00614633\n",
      "Iteration 1613, loss = 0.00613693\n",
      "Iteration 1614, loss = 0.00590248\n",
      "Iteration 1615, loss = 0.00601217\n",
      "Iteration 1616, loss = 0.00604306\n",
      "Iteration 1617, loss = 0.00588140\n",
      "Iteration 1618, loss = 0.00594173\n",
      "Iteration 1619, loss = 0.00628390\n",
      "Iteration 1620, loss = 0.00722025\n",
      "Iteration 1621, loss = 0.00745219\n",
      "Iteration 1622, loss = 0.00707569\n",
      "Iteration 1623, loss = 0.00615035\n",
      "Iteration 1624, loss = 0.00605745\n",
      "Iteration 1625, loss = 0.00553620\n",
      "Iteration 1626, loss = 0.00570948\n",
      "Iteration 1627, loss = 0.00601444\n",
      "Iteration 1628, loss = 0.00578629\n",
      "Iteration 1629, loss = 0.00564083\n",
      "Iteration 1630, loss = 0.00561753\n",
      "Iteration 1631, loss = 0.00560699\n",
      "Iteration 1632, loss = 0.00567618\n",
      "Iteration 1633, loss = 0.00598521\n",
      "Iteration 1634, loss = 0.00663900\n",
      "Iteration 1635, loss = 0.00692848\n",
      "Iteration 1636, loss = 0.00648920\n",
      "Iteration 1637, loss = 0.00560602\n",
      "Iteration 1638, loss = 0.00533415\n",
      "Iteration 1639, loss = 0.00562874\n",
      "Iteration 1640, loss = 0.00566053\n",
      "Iteration 1641, loss = 0.00544898\n",
      "Iteration 1642, loss = 0.00522415\n",
      "Iteration 1643, loss = 0.00553377\n",
      "Iteration 1644, loss = 0.00521312\n",
      "Iteration 1645, loss = 0.00535092\n",
      "Iteration 1646, loss = 0.00523104\n",
      "Iteration 1647, loss = 0.00538481\n",
      "Iteration 1648, loss = 0.00509078\n",
      "Iteration 1649, loss = 0.00508366\n",
      "Iteration 1650, loss = 0.00577626\n",
      "Iteration 1651, loss = 0.00553814\n",
      "Iteration 1652, loss = 0.00576327\n",
      "Iteration 1653, loss = 0.00703066\n",
      "Iteration 1654, loss = 0.00569651\n",
      "Iteration 1655, loss = 0.00515057\n",
      "Iteration 1656, loss = 0.00512085\n",
      "Iteration 1657, loss = 0.00535746\n",
      "Iteration 1658, loss = 0.00520296\n",
      "Iteration 1659, loss = 0.00501653\n",
      "Iteration 1660, loss = 0.00500327\n",
      "Iteration 1661, loss = 0.00480149\n",
      "Iteration 1662, loss = 0.00514878\n",
      "Iteration 1663, loss = 0.00499061\n",
      "Iteration 1664, loss = 0.00495886\n",
      "Iteration 1665, loss = 0.00508233\n",
      "Iteration 1666, loss = 0.00485760\n",
      "Iteration 1667, loss = 0.00481401\n",
      "Iteration 1668, loss = 0.00514233\n",
      "Iteration 1669, loss = 0.00536509\n",
      "Iteration 1670, loss = 0.00588773\n",
      "Iteration 1671, loss = 0.00477927\n",
      "Iteration 1672, loss = 0.00468347\n",
      "Iteration 1673, loss = 0.00465657\n",
      "Iteration 1674, loss = 0.00493042\n",
      "Iteration 1675, loss = 0.00490286\n",
      "Iteration 1676, loss = 0.00511443\n",
      "Iteration 1677, loss = 0.00488797\n",
      "Iteration 1678, loss = 0.00470146\n",
      "Iteration 1679, loss = 0.00530808\n",
      "Iteration 1680, loss = 0.00497619\n",
      "Iteration 1681, loss = 0.00447950\n",
      "Iteration 1682, loss = 0.00463461\n",
      "Iteration 1683, loss = 0.00474838\n",
      "Iteration 1684, loss = 0.00452663\n",
      "Iteration 1685, loss = 0.00455265\n",
      "Iteration 1686, loss = 0.00517213\n",
      "Iteration 1687, loss = 0.00587042\n",
      "Iteration 1688, loss = 0.00476492\n",
      "Iteration 1689, loss = 0.00449590\n",
      "Iteration 1690, loss = 0.00437708\n",
      "Iteration 1691, loss = 0.00437933\n",
      "Iteration 1692, loss = 0.00438164\n",
      "Iteration 1693, loss = 0.00437294\n",
      "Iteration 1694, loss = 0.00438752\n",
      "Iteration 1695, loss = 0.00427128\n",
      "Iteration 1696, loss = 0.00456196\n",
      "Iteration 1697, loss = 0.00429117\n",
      "Iteration 1698, loss = 0.00436715\n",
      "Iteration 1699, loss = 0.00467378\n",
      "Iteration 1700, loss = 0.00429367\n",
      "Iteration 1701, loss = 0.00436383\n",
      "Iteration 1702, loss = 0.00488034\n",
      "Iteration 1703, loss = 0.00505079\n",
      "Iteration 1704, loss = 0.00526855\n",
      "Iteration 1705, loss = 0.00478540\n",
      "Iteration 1706, loss = 0.00424749\n",
      "Iteration 1707, loss = 0.00427797\n",
      "Iteration 1708, loss = 0.00415080\n",
      "Iteration 1709, loss = 0.00405724\n",
      "Iteration 1710, loss = 0.00406386\n",
      "Iteration 1711, loss = 0.00437079\n",
      "Iteration 1712, loss = 0.00413437\n",
      "Iteration 1713, loss = 0.00468830\n",
      "Iteration 1714, loss = 0.00485157\n",
      "Iteration 1715, loss = 0.00427875\n",
      "Iteration 1716, loss = 0.00402520\n",
      "Iteration 1717, loss = 0.00388892\n",
      "Iteration 1718, loss = 0.00425435\n",
      "Iteration 1719, loss = 0.00431552\n",
      "Iteration 1720, loss = 0.00414923\n",
      "Iteration 1721, loss = 0.00397002\n",
      "Iteration 1722, loss = 0.00395949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1723, loss = 0.00375588\n",
      "Iteration 1724, loss = 0.00382527\n",
      "Iteration 1725, loss = 0.00397038\n",
      "Iteration 1726, loss = 0.00424944\n",
      "Iteration 1727, loss = 0.00383898\n",
      "Iteration 1728, loss = 0.00384678\n",
      "Iteration 1729, loss = 0.00428288\n",
      "Iteration 1730, loss = 0.00405770\n",
      "Iteration 1731, loss = 0.00386814\n",
      "Iteration 1732, loss = 0.00380508\n",
      "Iteration 1733, loss = 0.00403257\n",
      "Iteration 1734, loss = 0.00400527\n",
      "Iteration 1735, loss = 0.00405358\n",
      "Iteration 1736, loss = 0.00371342\n",
      "Iteration 1737, loss = 0.00377286\n",
      "Iteration 1738, loss = 0.00392437\n",
      "Iteration 1739, loss = 0.00377725\n",
      "Iteration 1740, loss = 0.00371332\n",
      "Iteration 1741, loss = 0.00385210\n",
      "Iteration 1742, loss = 0.00363504\n",
      "Iteration 1743, loss = 0.00367836\n",
      "Iteration 1744, loss = 0.00378431\n",
      "Iteration 1745, loss = 0.00373049\n",
      "Iteration 1746, loss = 0.00366742\n",
      "Iteration 1747, loss = 0.00355433\n",
      "Iteration 1748, loss = 0.00350080\n",
      "Iteration 1749, loss = 0.00363417\n",
      "Iteration 1750, loss = 0.00364578\n",
      "Iteration 1751, loss = 0.00361473\n",
      "Iteration 1752, loss = 0.00371197\n",
      "Iteration 1753, loss = 0.00376775\n",
      "Iteration 1754, loss = 0.00353917\n",
      "Iteration 1755, loss = 0.00348965\n",
      "Iteration 1756, loss = 0.00357422\n",
      "Iteration 1757, loss = 0.00365042\n",
      "Iteration 1758, loss = 0.00350984\n",
      "Iteration 1759, loss = 0.00340078\n",
      "Iteration 1760, loss = 0.00364586\n",
      "Iteration 1761, loss = 0.00340148\n",
      "Iteration 1762, loss = 0.00345786\n",
      "Iteration 1763, loss = 0.00362224\n",
      "Iteration 1764, loss = 0.00348415\n",
      "Training loss did not improve more than tol=0.000100 for 40 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(200, 200), learning_rate_init=0.0001,\n",
       "              max_iter=2000, n_iter_no_change=40, random_state=1, verbose=True,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be6d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"coefs_0.csv\", clf.coefs_[0], delimiter=\",\")\n",
    "# np.savetxt(\"coefs_1.csv\", clf.coefs_[1], delimiter=\",\")\n",
    "# np.savetxt(\"coefs_2.csv\", clf.coefs_[2], delimiter=\",\")\n",
    "# np.savetxt(\"intercepts_0.csv\", clf.intercepts_[0], delimiter=\",\")\n",
    "# np.savetxt(\"intercepts_1.csv\", clf.intercepts_[1], delimiter=\",\")\n",
    "# np.savetxt(\"intercepts_2.csv\", clf.intercepts_[2], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a7e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_perdict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7807b198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c5eead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.553757225433526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa03b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135, 207,   7],\n",
       "       [159, 651, 236],\n",
       "       [  9, 154, 172]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(Y_test, y_perdict)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664514c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\1801883316.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.SIGNAL.loc[idx] = y_perdict[i]\n"
     ]
    }
   ],
   "source": [
    "df_test = df_an[['time', 'open', 'high', 'low', 'close','TP','SL','pivots_l','pivots_h']].iloc[indeces_test[0]:].copy()\n",
    "df_test['SIGNAL'] = 0\n",
    "for i,idx in enumerate(indeces_test):\n",
    "    if i > 0:\n",
    "        if df_test.pivots_h[idx-1] or df_test.pivots_l[idx-1] :\n",
    "            df_test.SIGNAL.loc[idx] = y_perdict[i]\n",
    "\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b68e8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = Rates(pair, 13*len(df_test), mt5.TIMEFRAME_M5)\n",
    "df_m5 = rates.get_rates_from_now()\n",
    "df_m5.reset_index(drop=True, inplace=True)\n",
    "df_m5.drop(['tick_volume', 'spread', 'real_volume'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77dc800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data...\n",
      "run_test...\n",
      "Result:\n",
      "win rate:  0.37716763005780346\n",
      "-1.0    431\n",
      " 2.0    261\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gt = GuruTester2(\n",
    "        df_test,\n",
    "        df_m5,\n",
    "        SPREAD,\n",
    "        use_spread=True\n",
    "    )\n",
    "df_res_m5 = gt.run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4625892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\413402749.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\meysam\\AppData\\Local\\Temp\\ipykernel_8584\\413402749.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_res_m5['balance'] = 100\n",
    "loss_margin = 0.03\n",
    "perv_balance = 100\n",
    "\n",
    "# for index, row in df_res_m5.iterrows():\n",
    "for i in range(len(df_res_m5)):\n",
    "    if(df_res_m5.result[i] == -1):\n",
    "        loss_ratio = abs( (df_res_m5['start_price'][i]-df_res_m5['trigger_price'][i])/((df_res_m5['start_price'][i]-df_res_m5['SL'][i])) )\n",
    "#         print(loss_ratio)\n",
    "        df_res_m5['balance'][i] = perv_balance*(1-loss_ratio*loss_margin) \n",
    "    elif(df_res_m5.result[i] == 2):\n",
    "        profit_to_loss = abs( (df_res_m5['start_price'][i]-df_res_m5['trigger_price'][i])/((df_res_m5['start_price'][i]-df_res_m5['SL'][i])) )\n",
    "#         print(profit_to_loss)\n",
    "        df_res_m5['balance'][i] = perv_balance*(1+profit_to_loss*loss_margin) \n",
    "    perv_balance = df_res_m5['balance'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "300dbdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min balance  61.59953739124289\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "shape": "spline",
          "width": 2
         },
         "name": "balance",
         "type": "scatter",
         "x": [
          "s22-08-04 10:05",
          "s22-08-04 16:00",
          "s22-08-05 12:25",
          "s22-08-08 03:00",
          "s22-08-08 08:50",
          "s22-08-08 10:05",
          "s22-08-08 10:45",
          "s22-08-09 02:10",
          "s22-08-09 08:30",
          "s22-08-09 17:40",
          "s22-08-09 17:50",
          "s22-08-10 02:00",
          "s22-08-10 10:00",
          "s22-08-10 11:25",
          "s22-08-10 15:30",
          "s22-08-10 15:30",
          "s22-08-10 17:30",
          "s22-08-11 09:15",
          "s22-08-11 15:30",
          "s22-08-12 03:25",
          "s22-08-12 05:00",
          "s22-08-12 09:00",
          "s22-08-12 10:45",
          "s22-08-12 12:15",
          "s22-08-12 17:00",
          "s22-08-15 02:55",
          "s22-08-15 08:55",
          "s22-08-15 20:45",
          "s22-08-15 23:35",
          "s22-08-16 10:00",
          "s22-08-16 10:00",
          "s22-08-16 10:00",
          "s22-08-16 16:00",
          "s22-08-17 02:05",
          "s22-08-17 03:50",
          "s22-08-17 07:50",
          "s22-08-17 14:10",
          "s22-08-18 09:35",
          "s22-08-18 09:35",
          "s22-08-18 11:45",
          "s22-08-18 16:30",
          "s22-08-18 17:00",
          "s22-08-19 03:10",
          "s22-08-19 03:10",
          "s22-08-19 07:20",
          "s22-08-19 11:05",
          "s22-08-22 03:55",
          "s22-08-22 09:00",
          "s22-08-22 13:00",
          "s22-08-22 15:30",
          "s22-08-22 16:50",
          "s22-08-23 01:50",
          "s22-08-23 07:55",
          "s22-08-23 09:00",
          "s22-08-23 16:20",
          "s22-08-23 16:45",
          "s22-08-23 17:00",
          "s22-08-24 03:10",
          "s22-08-24 10:20",
          "s22-08-24 13:00",
          "s22-08-25 02:05",
          "s22-08-25 15:30",
          "s22-08-25 23:00",
          "s22-08-26 02:45",
          "s22-08-26 08:10",
          "s22-08-26 09:45",
          "s22-08-26 15:35",
          "s22-08-26 15:35",
          "s22-08-26 15:35",
          "s22-08-26 17:35",
          "s22-08-26 19:40",
          "s22-08-29 07:35",
          "s22-08-29 17:05",
          "s22-08-30 02:45",
          "s22-08-30 10:35",
          "s22-08-30 10:40",
          "s22-08-30 17:40",
          "s22-08-31 07:00",
          "s22-08-31 15:25",
          "s22-09-01 04:30",
          "s22-09-01 08:50",
          "s22-09-01 13:30",
          "s22-09-01 13:30",
          "s22-09-01 13:35",
          "s22-09-01 17:00",
          "s22-09-02 10:05",
          "s22-09-02 12:55",
          "s22-09-02 19:40",
          "s22-09-05 07:45",
          "s22-09-05 08:00",
          "s22-09-05 08:25",
          "s22-09-05 11:10",
          "s22-09-05 15:40",
          "s22-09-05 23:40",
          "s22-09-06 01:00",
          "s22-09-06 15:55",
          "s22-09-06 16:00",
          "s22-09-07 01:50",
          "s22-09-07 03:15",
          "s22-09-07 12:25",
          "s22-09-07 14:05",
          "s22-09-08 01:10",
          "s22-09-08 06:05",
          "s22-09-09 03:35",
          "s22-09-09 06:55",
          "s22-09-09 14:30",
          "s22-09-12 00:40",
          "s22-09-12 09:00",
          "s22-09-13 09:10",
          "s22-09-13 09:20",
          "s22-09-13 14:10",
          "s22-09-13 21:00",
          "s22-09-14 09:35",
          "s22-09-14 22:25",
          "s22-09-15 00:00",
          "s22-09-15 03:10",
          "s22-09-15 12:10",
          "s22-09-15 13:30",
          "s22-09-15 15:05",
          "s22-09-15 15:25",
          "s22-09-15 16:20",
          "s22-09-16 08:50",
          "s22-09-16 09:15",
          "s22-09-16 13:50",
          "s22-09-19 08:35",
          "s22-09-19 09:05",
          "s22-09-19 12:50",
          "s22-09-19 16:50",
          "s22-09-19 20:05",
          "s22-09-19 22:00",
          "s22-09-20 09:00",
          "s22-09-20 12:45",
          "s22-09-20 15:25",
          "s22-09-20 16:25",
          "s22-09-21 07:55",
          "s22-09-21 09:00",
          "s22-09-21 09:00",
          "s22-09-21 09:00",
          "s22-09-21 17:30",
          "s22-09-21 17:30",
          "s22-09-21 21:00",
          "s22-09-21 23:00",
          "s22-09-22 02:10",
          "s22-09-22 09:55",
          "s22-09-22 10:35",
          "s22-09-22 16:35",
          "s22-09-23 10:00",
          "s22-09-23 16:45",
          "s22-09-26 00:05",
          "s22-09-26 03:55",
          "s22-09-26 09:00",
          "s22-09-26 10:05",
          "s22-09-26 15:45",
          "s22-09-26 18:30",
          "s22-09-27 02:55",
          "s22-09-27 08:40",
          "s22-09-27 15:55",
          "s22-09-27 16:30",
          "s22-09-27 19:05",
          "s22-09-28 01:00",
          "s22-09-28 05:05",
          "s22-09-28 05:30",
          "s22-09-28 10:55",
          "s22-09-28 13:00",
          "s22-09-28 13:00",
          "s22-09-28 13:00",
          "s22-09-28 13:00",
          "s22-09-28 22:25",
          "s22-09-29 16:00",
          "s22-09-29 16:15",
          "s22-09-29 23:55",
          "s22-09-30 07:15",
          "s22-09-30 13:25",
          "s22-09-30 13:45",
          "s22-09-30 21:55",
          "s22-10-03 00:25",
          "s22-10-03 02:00",
          "s22-10-03 07:00",
          "s22-10-03 08:40",
          "s22-10-03 23:00",
          "s22-10-04 01:10",
          "s22-10-04 02:00",
          "s22-10-04 04:50",
          "s22-10-04 14:00",
          "s22-10-04 18:25",
          "s22-10-05 01:10",
          "s22-10-05 02:00",
          "s22-10-05 03:50",
          "s22-10-05 05:00",
          "s22-10-05 09:35",
          "s22-10-05 09:45",
          "s22-10-05 09:45",
          "s22-10-05 13:10",
          "s22-10-06 11:10",
          "s22-10-06 11:40",
          "s22-10-06 16:10",
          "s22-10-06 16:20",
          "s22-10-07 03:10",
          "s22-10-07 09:10",
          "s22-10-07 09:20",
          "s22-10-07 15:30",
          "s22-10-07 15:45",
          "s22-10-07 15:45",
          "s22-10-07 17:00",
          "s22-10-07 20:00",
          "s22-10-10 03:25",
          "s22-10-10 22:00",
          "s22-10-11 11:00",
          "s22-10-11 14:20",
          "s22-10-11 14:20",
          "s22-10-11 21:55",
          "s22-10-11 21:55",
          "s22-10-12 03:00",
          "s22-10-12 07:00",
          "s22-10-13 03:00",
          "s22-10-13 09:00",
          "s22-10-13 12:25",
          "s22-10-13 14:25",
          "s22-10-13 14:30",
          "s22-10-13 18:15",
          "s22-10-14 02:35",
          "s22-10-14 02:55",
          "s22-10-14 04:40",
          "s22-10-14 10:05",
          "s22-10-14 12:25",
          "s22-10-14 14:40",
          "s22-10-14 19:55",
          "s22-10-17 01:00",
          "s22-10-17 05:00",
          "s22-10-17 08:05",
          "s22-10-17 15:40",
          "s22-10-17 19:40",
          "s22-10-18 03:00",
          "s22-10-18 06:45",
          "s22-10-19 01:55",
          "s22-10-19 09:55",
          "s22-10-19 11:10",
          "s22-10-19 17:25",
          "s22-10-20 07:15",
          "s22-10-20 11:00",
          "s22-10-20 11:30",
          "s22-10-20 15:20",
          "s22-10-20 17:15",
          "s22-10-20 19:00",
          "s22-10-21 15:05",
          "s22-10-21 18:20",
          "s22-10-24 19:35",
          "s22-10-25 05:35",
          "s22-10-25 08:10",
          "s22-10-25 08:10",
          "s22-10-25 11:35",
          "s22-10-25 11:35",
          "s22-10-25 16:15",
          "s22-10-26 01:50",
          "s22-10-26 03:50",
          "s22-10-26 09:05",
          "s22-10-26 10:15",
          "s22-10-26 15:55",
          "s22-10-26 18:40",
          "s22-10-27 00:05",
          "s22-10-27 02:50",
          "s22-10-27 07:50",
          "s22-10-27 09:30",
          "s22-10-27 09:35",
          "s22-10-27 15:30",
          "s22-10-27 21:45",
          "s22-10-28 03:05",
          "s22-10-28 08:10",
          "s22-10-28 16:05",
          "s22-10-31 10:15",
          "s22-10-31 12:30",
          "s22-10-31 13:50",
          "s22-11-01 02:15",
          "s22-11-01 03:30",
          "s22-11-01 12:25",
          "s22-11-01 12:25",
          "s22-11-01 20:00",
          "s22-11-01 22:00",
          "s22-11-02 08:15",
          "s22-11-02 10:25",
          "s22-11-02 20:00",
          "s22-11-03 08:50",
          "s22-11-03 20:15",
          "s22-11-03 20:15",
          "s22-11-03 22:10",
          "s22-11-04 09:45",
          "s22-11-04 14:20",
          "s22-11-04 14:30",
          "s22-11-04 15:00",
          "s22-11-07 07:30",
          "s22-11-07 07:30",
          "s22-11-07 09:30",
          "s22-11-07 13:30",
          "s22-11-07 15:15",
          "s22-11-08 11:00",
          "s22-11-08 13:00",
          "s22-11-08 17:40",
          "s22-11-09 05:00",
          "s22-11-09 09:55",
          "s22-11-09 11:15",
          "s22-11-09 15:20",
          "s22-11-09 19:00",
          "s22-11-10 01:20",
          "s22-11-10 15:10",
          "s22-11-10 15:20",
          "s22-11-10 15:20",
          "s22-11-10 15:30",
          "s22-11-10 15:35",
          "s22-11-10 19:30",
          "s22-11-10 23:05",
          "s22-11-11 02:30",
          "s22-11-11 12:00",
          "s22-11-11 13:30",
          "s22-11-11 14:25",
          "s22-11-11 18:50",
          "s22-11-11 20:10",
          "s22-11-14 00:05",
          "s22-11-14 03:15",
          "s22-11-14 06:00",
          "s22-11-14 06:10",
          "s22-11-14 10:10",
          "s22-11-14 15:50",
          "s22-11-14 15:50",
          "s22-11-14 19:50",
          "s22-11-15 07:05",
          "s22-11-15 09:00",
          "s22-11-15 09:20",
          "s22-11-15 19:00",
          "s22-11-16 15:30",
          "s22-11-17 04:20",
          "s22-11-17 10:00",
          "s22-11-17 11:30",
          "s22-11-17 13:35",
          "s22-11-17 15:00",
          "s22-11-17 19:00",
          "s22-11-17 19:50",
          "s22-11-18 02:00",
          "s22-11-18 08:30",
          "s22-11-18 11:20",
          "s22-11-18 15:20",
          "s22-11-18 22:00",
          "s22-11-21 02:05",
          "s22-11-21 06:35",
          "s22-11-21 10:00",
          "s22-11-21 21:25",
          "s22-11-22 01:00",
          "s22-11-22 14:25",
          "s22-11-23 03:25",
          "s22-11-23 05:55",
          "s22-11-23 06:00",
          "s22-11-23 13:30",
          "s22-11-23 16:45",
          "s22-11-25 02:10",
          "s22-11-25 04:35",
          "s22-11-25 10:00",
          "s22-11-25 15:20",
          "s22-11-25 15:30",
          "s22-11-28 03:30",
          "s22-11-28 09:10",
          "s22-11-28 19:10",
          "s22-11-29 20:15",
          "s22-11-29 23:10",
          "s22-11-30 01:40",
          "s22-11-30 11:00",
          "s22-11-30 15:55",
          "s22-11-30 21:05",
          "s22-11-30 21:15",
          "s22-12-01 02:45",
          "s22-12-02 01:10",
          "s22-12-02 01:15",
          "s22-12-02 07:40",
          "s22-12-02 07:45",
          "s22-12-02 09:40",
          "s22-12-02 15:30",
          "s22-12-05 02:15",
          "s22-12-05 05:10",
          "s22-12-05 10:10",
          "s22-12-06 06:15",
          "s22-12-06 08:20",
          "s22-12-06 12:40",
          "s22-12-06 14:00",
          "s22-12-06 17:15",
          "s22-12-06 20:30",
          "s22-12-06 20:55",
          "s22-12-07 02:30",
          "s22-12-07 08:05",
          "s22-12-07 08:05",
          "s22-12-07 08:05",
          "s22-12-07 09:35",
          "s22-12-08 03:00",
          "s22-12-08 05:10",
          "s22-12-08 08:15",
          "s22-12-08 10:55",
          "s22-12-08 15:25",
          "s22-12-08 17:05",
          "s22-12-08 17:35",
          "s22-12-08 20:50",
          "s22-12-09 14:25",
          "s22-12-09 15:20",
          "s22-12-09 15:30",
          "s22-12-09 15:30",
          "s22-12-09 17:35",
          "s22-12-12 01:05",
          "s22-12-12 09:00",
          "s22-12-12 09:25",
          "s22-12-12 16:35",
          "s22-12-12 20:30",
          "s22-12-13 05:50",
          "s22-12-13 15:30",
          "s22-12-13 15:30",
          "s22-12-13 15:30",
          "s22-12-14 02:25",
          "s22-12-14 07:15",
          "s22-12-14 08:45",
          "s22-12-14 10:50",
          "s22-12-15 10:00",
          "s22-12-15 17:00",
          "s22-12-16 10:25",
          "s22-12-19 00:05",
          "s22-12-19 11:05",
          "s22-12-19 18:45",
          "s22-12-20 01:30",
          "s22-12-20 04:00",
          "s22-12-20 07:20",
          "s22-12-21 08:50",
          "s22-12-21 13:30",
          "s22-12-21 14:20",
          "s22-12-21 18:25",
          "s22-12-21 18:25",
          "s22-12-22 02:00",
          "s22-12-22 08:20",
          "s22-12-22 11:15",
          "s22-12-22 16:30",
          "s22-12-23 06:00",
          "s22-12-23 13:15",
          "s22-12-23 15:30",
          "s22-12-23 17:30",
          "s22-12-27 00:30",
          "s22-12-27 01:10",
          "s22-12-27 03:50",
          "s22-12-27 08:50",
          "s22-12-27 08:50",
          "s22-12-27 10:00",
          "s22-12-28 01:00",
          "s22-12-28 09:25",
          "s22-12-28 12:45",
          "s22-12-28 22:50",
          "s22-12-29 08:35",
          "s22-12-29 10:05",
          "s22-12-29 11:55",
          "s22-12-30 00:20",
          "s22-12-30 06:00",
          "s22-12-30 08:30",
          "s22-12-30 09:55",
          "s22-12-30 10:00",
          "s22-12-30 15:20",
          "s22-12-30 15:30",
          "s22-12-30 16:15",
          "s23-01-03 09:50",
          "s23-01-03 10:00",
          "s23-01-03 10:00",
          "s23-01-03 10:05",
          "s23-01-03 10:30",
          "s23-01-03 13:15",
          "s23-01-03 22:00",
          "s23-01-04 09:10",
          "s23-01-04 09:40",
          "s23-01-04 17:05",
          "s23-01-05 02:50",
          "s23-01-05 04:00",
          "s23-01-05 15:15",
          "s23-01-05 22:00",
          "s23-01-06 09:40",
          "s23-01-06 11:10",
          "s23-01-06 15:30",
          "s23-01-09 01:00",
          "s23-01-09 17:35",
          "s23-01-09 17:35",
          "s23-01-09 19:15",
          "s23-01-09 21:00",
          "s23-01-10 02:50",
          "s23-01-10 09:10",
          "s23-01-10 11:00",
          "s23-01-11 06:40",
          "s23-01-11 06:40",
          "s23-01-11 10:50",
          "s23-01-12 09:15",
          "s23-01-12 11:10",
          "s23-01-12 11:25",
          "s23-01-12 11:50",
          "s23-01-13 00:05",
          "s23-01-13 03:35",
          "s23-01-13 04:15",
          "s23-01-16 03:55",
          "s23-01-16 08:05",
          "s23-01-16 09:30",
          "s23-01-16 19:00",
          "s23-01-17 02:10",
          "s23-01-17 03:35",
          "s23-01-17 09:40",
          "s23-01-17 13:40",
          "s23-01-18 04:40",
          "s23-01-18 08:10",
          "s23-01-18 11:45",
          "s23-01-18 13:35",
          "s23-01-18 13:35",
          "s23-01-18 15:30",
          "s23-01-19 09:55",
          "s23-01-19 13:50",
          "s23-01-19 17:00",
          "s23-01-23 02:50",
          "s23-01-23 11:00",
          "s23-01-23 12:30",
          "s23-01-23 20:50",
          "s23-01-24 03:40",
          "s23-01-24 07:25",
          "s23-01-24 11:45",
          "s23-01-24 22:10",
          "s23-01-25 08:20",
          "s23-01-25 09:40",
          "s23-01-25 09:40",
          "s23-01-25 09:45",
          "s23-01-25 09:45",
          "s23-01-26 01:00",
          "s23-01-26 06:00",
          "s23-01-26 09:15",
          "s23-01-26 10:20",
          "s23-01-26 17:35",
          "s23-01-27 01:20",
          "s23-01-27 03:05",
          "s23-01-27 10:00",
          "s23-01-27 15:00",
          "s23-01-30 01:50",
          "s23-01-30 09:15",
          "s23-01-30 19:15",
          "s23-01-30 21:10",
          "s23-01-31 02:30",
          "s23-01-31 06:30",
          "s23-01-31 09:10",
          "s23-01-31 10:15",
          "s23-01-31 13:25",
          "s23-01-31 17:05",
          "s23-01-31 17:10",
          "s23-02-01 13:00",
          "s23-02-01 15:45",
          "s23-02-01 18:15",
          "s23-02-01 21:00",
          "s23-02-01 21:00",
          "s23-02-02 19:50",
          "s23-02-02 21:45",
          "s23-02-03 01:00",
          "s23-02-03 06:00",
          "s23-02-03 11:35",
          "s23-02-03 14:45",
          "s23-02-03 15:30",
          "s23-02-03 19:40",
          "s23-02-06 17:35",
          "s23-02-07 03:00",
          "s23-02-07 17:45",
          "s23-02-08 07:05",
          "s23-02-08 09:25",
          "s23-02-08 09:55",
          "s23-02-08 11:00",
          "s23-02-08 16:50",
          "s23-02-08 22:10",
          "s23-02-09 10:10",
          "s23-02-09 20:40",
          "s23-02-10 10:00",
          "s23-02-10 12:05",
          "s23-02-10 12:05",
          "s23-02-10 17:45",
          "s23-02-14 01:55",
          "s23-02-14 09:00",
          "s23-02-14 15:30",
          "s23-02-15 08:30",
          "s23-02-15 09:00",
          "s23-02-15 18:40",
          "s23-02-15 23:10",
          "s23-02-16 02:30",
          "s23-02-16 08:35",
          "s23-02-16 10:05",
          "s23-02-16 21:05",
          "s23-02-17 02:25",
          "s23-02-17 08:10",
          "s23-02-17 08:25",
          "s23-02-17 19:25",
          "s23-02-20 15:35",
          "s23-02-21 01:25",
          "s23-02-21 01:25",
          "s23-02-21 02:05",
          "s23-02-21 03:10",
          "s23-02-21 09:00",
          "s23-02-21 09:05",
          "s23-02-21 09:20",
          "s23-02-21 11:20",
          "s23-02-21 11:30",
          "s23-02-21 13:45",
          "s23-02-21 15:10",
          "s23-02-22 03:05",
          "s23-02-22 10:25",
          "s23-02-22 10:35",
          "s23-02-22 17:35",
          "s23-02-22 18:10",
          "s23-02-22 21:00",
          "s23-02-23 00:10",
          "s23-02-23 10:05",
          "s23-02-23 17:45",
          "s23-02-24 05:00",
          "s23-02-24 16:00",
          "s23-02-24 16:25",
          "s23-02-24 23:00",
          "s23-02-27 02:55",
          "s23-02-27 05:30",
          "s23-02-27 05:40",
          "s23-02-27 10:00",
          "s23-02-27 10:00",
          "s23-02-27 13:15",
          "s23-02-27 15:30",
          "s23-02-27 15:45",
          "s23-02-27 19:55",
          "s23-02-28 05:00",
          "s23-02-28 06:25",
          "s23-02-28 15:00",
          "s23-02-28 18:10",
          "s23-03-01 09:45",
          "s23-03-01 12:40",
          "s23-03-02 14:50",
          "s23-03-02 14:50",
          "s23-03-03 08:05",
          "s23-03-03 17:00",
          "s23-03-06 02:10",
          "s23-03-06 04:05",
          "s23-03-06 15:20",
          "s23-03-07 01:00",
          "s23-03-07 10:20",
          "s23-03-07 12:25",
          "s23-03-07 17:00",
          "s23-03-08 02:05",
          "s23-03-08 04:50",
          "s23-03-08 14:10",
          "s23-03-08 17:00",
          "s23-03-08 19:00",
          "s23-03-09 07:10",
          "s23-03-09 10:30",
          "s23-03-09 10:40",
          "s23-03-09 12:00",
          "s23-03-10 04:25",
          "s23-03-10 04:30",
          "s23-03-10 09:00",
          "s23-03-10 09:30",
          "s23-03-10 11:40",
          "s23-03-13 00:05",
          "s23-03-13 04:25",
          "s23-03-13 12:25",
          "s23-03-13 16:40",
          "s23-03-14 01:55",
          "s23-03-14 08:10",
          "s23-03-14 14:30",
          "s23-03-15 11:30",
          "s23-03-15 12:35",
          "s23-03-15 16:00",
          "s23-03-16 02:05",
          "s23-03-16 06:10",
          "s23-03-16 11:15",
          "s23-03-17 03:10",
          "s23-03-17 05:40",
          "s23-03-17 09:00",
          "s23-03-17 15:00",
          "s23-03-20 03:40",
          "s23-03-20 09:00",
          "s23-03-20 10:50",
          "s23-03-20 12:55",
          "s23-03-21 05:30",
          "s23-03-21 15:05",
          "s23-03-21 15:40",
          "s23-03-22 00:55",
          "s23-03-22 09:00",
          "s23-03-22 16:00",
          "s23-03-22 19:30",
          "s23-03-22 19:35",
          "s23-03-22 20:35",
          "s23-03-23 02:50",
          "s23-03-23 07:05",
          "s23-03-23 14:45",
          "s23-03-23 19:20",
          "s23-03-23 20:55",
          "s23-03-24 03:45",
          "s23-03-24 10:05",
          "s23-03-24 21:20",
          "s23-03-24 21:20",
          "s23-03-27 09:10",
          "s23-03-27 11:30"
         ],
         "xaxis": "x",
         "y": [
          97,
          97.13302857142857,
          94.2190377142857,
          91.39246658285712,
          88.6506925853714,
          85.99117180781026,
          91.06640586634461,
          88.33441369035427,
          85.68438127964363,
          83.11384984125432,
          80.6204343460167,
          80.94054489415541,
          78.51232854733074,
          82.96611882128907,
          89.75274734087049,
          87.06016492064437,
          84.44835997302503,
          81.91490917383427,
          86.95115914526274,
          92.29069511531011,
          92.62128865005154,
          98.76231358659665,
          95.79944417899874,
          102.66952384123766,
          102.82994497223996,
          99.74504662307275,
          96.75269522438057,
          102.6771410826396,
          99.5968268501604,
          106.3415825508219,
          103.15133507429724,
          111.58480686498748,
          108.23726265903785,
          104.99014477926671,
          101.84044043588871,
          107.39537355057381,
          114.41120215915768,
          121.7187563615807,
          129.58801549379507,
          125.70037502898121,
          135.60495879632538,
          131.53681003243562,
          127.59070573146255,
          123.76298455951867,
          131.3707680221483,
          127.42964498148385,
          135.2472389320325,
          131.18982176407152,
          141.68500750519658,
          137.43445728004068,
          133.31142356163946,
          129.31208085479028,
          125.43271842914658,
          121.66973687627217,
          118.019644769984,
          130.62722160476017,
          138.84305691842317,
          134.67776521087046,
          130.63743225454434,
          138.8225032312023,
          134.65782813426623,
          130.61809329023822,
          138.21026996273704,
          147.60856832020207,
          143.180311270596,
          138.88490193247813,
          134.71835487450377,
          130.67680422826865,
          138.1412947428586,
          133.99705590057283,
          129.97714422355565,
          126.07782989684898,
          122.29549499994351,
          129.58081234494097,
          125.69338797459274,
          121.92258633535495,
          129.18873509049772,
          136.06803523406808,
          131.98599417704602,
          139.8491880350845,
          135.65371239403197,
          131.584101022211,
          127.63657799154467,
          135.2162270845805,
          131.15974027204308,
          127.22494806388178,
          123.40819962196532,
          119.70595363330636,
          116.11477502430716,
          123.11657354052798,
          130.71942168579025,
          126.79783903521654,
          134.4665723400648,
          130.43257516986284,
          126.51959791476696,
          122.72400997732395,
          129.95699591968838,
          126.05828604209772,
          122.27653746083479,
          118.60824133700974,
          125.71465579672025,
          121.94321612281864,
          118.28491963913407,
          124.84246957000508,
          132.17135123684847,
          128.206210699743,
          124.36002437875071,
          120.62922364738819,
          117.01034693796653,
          123.93783706994715,
          120.21970195784873,
          116.61311089911327,
          113.11471757213987,
          109.72127604497567,
          119.26030943174284,
          126.54843945257244,
          122.75198626899527,
          119.0694266809254,
          115.49734388049764,
          112.0324235640827,
          120.32759024499668,
          116.71776253764678,
          123.94617446510156,
          131.34753174030348,
          127.40710578809437,
          123.58489261445153,
          130.90526782296388,
          126.97810978827496,
          123.16876649462671,
          119.4737034997879,
          115.88949239479426,
          112.41280762295042,
          109.04042339426191,
          105.76921069243404,
          112.29164535180198,
          108.92289599124791,
          105.65520911151047,
          102.48555283816516,
          99.4109862530202,
          96.42865666542959,
          93.5357969654667,
          93.55861057448264,
          90.75185225724816,
          88.02929668953071,
          85.38841778884479,
          82.82676525517944,
          80.34196229752405,
          77.93170342859833,
          75.59375232574037,
          81.20964054909143,
          78.77335133261869,
          83.83312768784023,
          89.10549158184108,
          86.43232683438585,
          93.21246269495015,
          99.52798088930862,
          96.54214146262936,
          102.96470145798432,
          99.87576041424478,
          96.87948760181743,
          93.9731029737629,
          91.15390988455002,
          96.63327268983271,
          93.73427450913772,
          90.92224627386359,
          99.27539533212304,
          96.29713347215935,
          102.58942561821716,
          99.51174284967064,
          105.66958890720409,
          102.49950123998796,
          107.9569071168201,
          104.7181999033155,
          101.57665390621602,
          98.52935428902954,
          95.57347366035866,
          92.7062694505479,
          89.92508136703145,
          87.2273289260205,
          91.58869537232225,
          88.84103451115259,
          86.175803475818,
          83.59052937154345,
          84.0920725477727,
          89.30369180169606,
          86.62458104764518,
          84.02584361621582,
          81.50506830772935,
          82.10541254488095,
          87.04476990273974,
          84.43342680565755,
          81.90042400148782,
          79.44341128144319,
          77.06010894299989,
          74.7483056747099,
          72.5058565044686,
          70.33068080933454,
          74.93581147450236,
          72.68773713026728,
          70.50710501635926,
          74.7169285918492,
          72.47542073409372,
          70.30115811207091,
          70.602758759527,
          68.48467599674119,
          66.43013571683895,
          66.85287294412797,
          67.49354630984251,
          65.46873992054724,
          63.504677722930815,
          61.59953739124289,
          65.61641740436053,
          63.64792488222972,
          72.90828820200507,
          77.2073631270202,
          78.93996930742999,
          84.01043943629948,
          89.01847554579959,
          95.16010216567666,
          92.30529910070636,
          89.53614012768517,
          86.85005592385461,
          84.24455424613897,
          81.7172176187548,
          87.33034511863652,
          84.71043476507742,
          82.1691217221251,
          88.13094799818606,
          88.77548776712813,
          86.11222313411427,
          83.52885644009085,
          88.60971515596326,
          97.87345810408999,
          94.93725436096729,
          92.08913673013826,
          89.32646262823411,
          86.64666874938709,
          91.5038334375674,
          88.75871843444037,
          86.09595688140716,
          83.51307817496495,
          81.007685829716,
          86.00835258958921,
          86.04454848947663,
          83.46321203479232,
          80.95931567374855,
          78.53053620353609,
          83.52714944110247,
          81.02133495786939,
          78.5906949091333,
          83.24038343264239,
          88.3332187145805,
          93.55357921958247,
          99.3053918678961,
          105.23005253526867,
          102.07315095921061,
          108.27777218782342,
          105.02943902218871,
          101.87855585152305,
          110.91848404679914,
          117.48970516049737,
          124.64125243113817,
          120.90201485820403,
          117.2749544124579,
          113.75670578008416,
          110.34400460668164,
          107.03368446848118,
          103.82267393442675,
          110.11058099113244,
          116.95808274651813,
          113.44934026412258,
          110.0458600561989,
          116.50188384616165,
          123.49199687693066,
          119.78723697062273,
          116.19361986150405,
          116.2878309046349,
          112.79919597749586,
          109.41522009817098,
          106.13276349522584,
          102.94878059036907,
          109.2331322403204,
          105.95613827311078,
          102.77745412491745,
          99.69413050116992,
          96.70330658613483,
          93.80220738855078,
          100.3442327205687,
          97.33390573895163,
          94.41388856678307,
          91.58147190977958,
          88.8340277524862,
          86.16900691991161,
          83.58393671231426,
          89.0971553192988,
          89.3181715185404,
          94.61691169376192,
          91.77840434294906,
          89.02505221266058,
          86.35430064628076,
          92.40765162227716,
          92.93717861471941,
          98.34612241009745,
          95.39573873779453,
          92.5338665756607,
          89.75785057839087,
          102.37811387954251,
          99.30677046315623,
          107.95941255046817,
          114.52722201367814,
          111.09140535326779,
          107.75866319266976,
          113.81726215818756,
          110.40274429344193,
          107.09066196463867,
          113.40752069324851,
          125.47579270664576,
          121.71151892544638,
          118.06017335768298,
          114.51836815695249,
          122.13492000135382,
          129.88876721129913,
          125.99210419496015,
          133.01166428582314,
          129.02131435724846,
          125.150674926531,
          133.21283670862957,
          129.2164516073707,
          125.33995805914957,
          121.57975931737508,
          117.93236653785382,
          114.39439554171821,
          110.96256367546667,
          107.63368676520267,
          104.40467616224659,
          110.99173454759803,
          114.32148658402967,
          110.89184198650878,
          107.56508672691352,
          114.87139450459232,
          121.00720801593492,
          117.37699177545687,
          124.36782731502437,
          126.5593574759638,
          133.60697659815446,
          129.59876730020983,
          125.71080428120354,
          121.93948015276743,
          118.2812957481844,
          114.73285687573888,
          111.29087116946671,
          118.49318868357844,
          114.93839302307109,
          120.2383300346913,
          116.63118013365056,
          113.13224472964104,
          109.73827738775181,
          116.4060705464204,
          112.91388843002778,
          120.03237270061679,
          116.43140151959828,
          121.44301401979803,
          128.70067985764766,
          136.88080781470114,
          132.7743835802601,
          128.7911520728523,
          124.92741751066673,
          132.2161275752473,
          145.04648852668274,
          140.69509387088226,
          151.21831596040542,
          146.68176648159326,
          157.36858089668254,
          183.58071278429728,
          178.07329140076834,
          172.7310926587453,
          167.54915987898292,
          175.89310804095606,
          170.61631479972738,
          165.49782535573556,
          160.5328905950635,
          155.7169038772116,
          151.04539676089524,
          160.3339100771712,
          155.52389277485605,
          150.85817599161035,
          161.0205313015896,
          156.1899153625419,
          151.50421790166564,
          146.95909136461566,
          153.18887893333473,
          148.59321256533468,
          144.13541618837465,
          139.8113537027234,
          135.6170130916417,
          143.50785012726055,
          139.20261462344274,
          135.02653618473946,
          143.91305770111904,
          139.59566597008546,
          135.4077959909829,
          131.3455621112534,
          127.4051952479158,
          123.58303939047832,
          119.87554820876397,
          116.27928176250106,
          123.62210307380023,
          119.91343998158622,
          128.8517448620552,
          140.99951478429128,
          162.81733444038812,
          157.93281440717647,
          153.19482997496118,
          148.59898507571233,
          144.14101552344096,
          139.81678505773772,
          135.62228150600558,
          145.44933862496504,
          154.33593846046702,
          163.01430484300792,
          158.12387569771766,
          166.52940803743869,
          161.53352579631553,
          156.68752002242607,
          165.51150141316438,
          160.54615637076944,
          170.2402809720112,
          165.13307254285084,
          160.1790803665653,
          168.15395372949695,
          181.4140940807434,
          175.9716712583211,
          187.6210693702235,
          181.9924372891168,
          192.48376602695998,
          186.7092530461512,
          199.18002202319823,
          211.22067899362273,
          204.88405862381404,
          198.73753686509963,
          192.77541075914664,
          204.83942033568874,
          198.69423772561808,
          192.73341059384953,
          186.95140827603404,
          198.1118408306939,
          192.16848560577307,
          186.4034310375999,
          180.81132810647188,
          191.75573143715178,
          210.32448264593805,
          204.0147481665599,
          197.89430572156311,
          191.9574765499162,
          186.19875225341872,
          180.61278968581615,
          175.19440599524165,
          169.9385738153844,
          187.43544937541725,
          181.81238589415472,
          176.35801431733006,
          186.9161879498083,
          198.16225434124337,
          209.10334051178725,
          202.83024029643363,
          196.74533308754062,
          209.61932118740012,
          203.33074155177812,
          197.23081930522477,
          197.52879392431905,
          191.60293010658947,
          191.90904129670034,
          186.15177005779933,
          180.56721695606535,
          197.97082318608733,
          192.0316984905047,
          203.75179825388201,
          215.82736354489256,
          235.92163532321203,
          237.67419604275614,
          230.54397016147345,
          249.5889068269844,
          250.28543400882782,
          263.45113355121134,
          255.547599544675,
          247.88117155833473,
          240.44473641158467,
          256.8946750855962,
          249.1878348330283,
          264.22186103051905,
          256.29520519960346,
          248.60634904361535,
          263.1601790605459,
          281.8539503516692,
          273.3983318411191,
          290.53309857928156,
          281.8171056219031,
          273.362592453246,
          265.16171467964864,
          257.2068632392592,
          249.4906573420814,
          242.00593762181893,
          234.74575949316434,
          248.7878885859929,
          263.3952917586856,
          255.493433005925,
          272.7226348746615,
          264.5409558284216,
          256.60472715356894,
          248.90658533896186,
          265.23077432696584,
          265.6116908645628,
          281.2352256940208,
          272.7981689232002,
          264.6142238555042,
          256.67579713983906,
          248.97552322564388,
          264.89685273717606,
          256.9499471550608,
          249.24144874040894,
          241.76420527819667,
          256.1393742406861,
          248.4551930134655,
          241.00153722306152,
          242.64034767617832,
          235.36113724589296,
          228.30030312851616,
          221.45129403466066,
          214.80775521362085,
          229.30727869054382,
          235.42213945562497,
          228.35947527195623,
          221.50869101379755,
          214.86343028338362,
          208.4175273748821,
          202.16500155363562,
          196.10005150702654,
          207.63444036338626,
          219.00242597328307,
          232.32121399395507,
          225.3515775741364,
          238.7645034713495,
          253.61524392433043,
          272.00234910886786,
          286.62519539696245,
          278.02643953505356,
          294.6311522372396,
          285.7922176701224,
          277.2184511400187,
          268.90189760581814,
          269.98406377911033,
          270.2411914589016,
          262.13395571513456,
          277.73911776629495,
          269.4069442333061,
          285.335956761279,
          276.77587805844064,
          268.4726017166874,
          260.41842366518676,
          275.6715027655983,
          267.40135768263036,
          283.8723326636145,
          285.6132071898941,
          303.4594846582561,
          322.00113757407274,
          312.3411034468505,
          331.31979591900307,
          355.8109552333361,
          345.13662657633597,
          334.7825277790459,
          324.73905194567453,
          314.9968803873043,
          305.5469739756852,
          327.1849097703765,
          317.3693624772652,
          307.8482816029472,
          325.5721936981798,
          315.80502788723436,
          306.33087705061735,
          327.0874347542209,
          317.2748117115943,
          307.75656736024644,
          298.52387033943904,
          289.56815422925587,
          307.99877593763324,
          298.75881265950426,
          289.7960482797191,
          281.1021668313275,
          272.6691018263877,
          264.48902877159605,
          256.55435790844814,
          248.85772717119468,
          241.39199535605883,
          255.61688079668318,
          276.2934462655715,
          293.0036738957138,
          284.2135636788424,
          275.6871567684771,
          291.33080008278534,
          282.59087608030177,
          300.8986040030509,
          318.54746443015665,
          308.99104049725196,
          299.7213092823344,
          290.7296700038644,
          282.0077799037484,
          273.54754650663597,
          275.99807661075766,
          292.5043114732884,
          310.7473435309653,
          301.4249232250363,
          292.3821755282852,
          283.6107102624366,
          275.1023889545635,
          266.8493172859266,
          258.84383776734876,
          251.0785226343283,
          243.54616695529845,
          258.39956641900994,
          250.64757942643965,
          243.12815204364645,
          235.83430748233704,
          228.75927825786692,
          241.92839346568715,
          255.61462829603167,
          272.7962719432876,
          264.61238378498894,
          256.67401227143927,
          248.97379190329607,
          241.5045781461972,
          253.70055934258363,
          273.1509355588583,
          288.14247527790593,
          279.49820101956874,
          271.1132549889817,
          262.9798573393122,
          294.70010817302233,
          285.85910492783165,
          277.2833317799967,
          292.635857429286,
          283.8567817064074,
          284.8152591511309,
          302.44301437967573,
          293.36972394828547,
          310.2849929095976,
          310.3345064722952,
          301.0244712781263,
          318.2359881064984,
          308.68890846330345,
          327.36809525384194,
          346.52903477720207,
          433.8543515410543,
          420.83872099482267,
          408.213559364978,
          434.42791253825794,
          421.3950751621102,
          446.7980424289562,
          433.3941011560875,
          420.3922781214049,
          449.32892427026854,
          451.8954910857003,
          477.34919629787584,
          463.02872040893953,
          449.1378587966713,
          435.66372303277114,
          461.66209715401214,
          488.4682834403732,
          514.3745477585461,
          498.9433113257897,
          483.975011986016,
          469.4557616264355,
          498.4278886296666,
          528.1512102808737,
          561.6255827634661,
          544.7768152805621,
          528.4335108221452,
          512.5805054974808,
          497.2030903325563,
          482.28699762257963,
          509.7367902910071,
          540.0318612938077,
          573.4543056227039,
          556.2506764540228,
          589.9184805551861,
          623.8896482285405,
          667.1771458479172,
          647.1618314724797,
          627.7469765283053,
          608.9145672324561,
          590.6471302154824,
          572.9277163090179,
          605.2998897274653
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "font": {
         "color": "#e1e1e1",
         "size": 8
        },
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 10
        },
        "paper_bgcolor": "#2c303c",
        "plot_bgcolor": "#2c303c",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1400,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "gridcolor": "#1f292f",
         "nticks": 5,
         "rangeslider": {
          "visible": false
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "#1f292f"
        },
        "yaxis2": {
         "anchor": "x",
         "gridcolor": "#1f292f",
         "overlaying": "y",
         "side": "right"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"e95c0ff1-a346-4c28-a630-91fcf6e86435\" class=\"plotly-graph-div\" style=\"height:600px; width:1400px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e95c0ff1-a346-4c28-a630-91fcf6e86435\")) {                    Plotly.newPlot(                        \"e95c0ff1-a346-4c28-a630-91fcf6e86435\",                        [{\"line\":{\"shape\":\"spline\",\"width\":2},\"name\":\"balance\",\"x\":[\"s22-08-04 10:05\",\"s22-08-04 16:00\",\"s22-08-05 12:25\",\"s22-08-08 03:00\",\"s22-08-08 08:50\",\"s22-08-08 10:05\",\"s22-08-08 10:45\",\"s22-08-09 02:10\",\"s22-08-09 08:30\",\"s22-08-09 17:40\",\"s22-08-09 17:50\",\"s22-08-10 02:00\",\"s22-08-10 10:00\",\"s22-08-10 11:25\",\"s22-08-10 15:30\",\"s22-08-10 15:30\",\"s22-08-10 17:30\",\"s22-08-11 09:15\",\"s22-08-11 15:30\",\"s22-08-12 03:25\",\"s22-08-12 05:00\",\"s22-08-12 09:00\",\"s22-08-12 10:45\",\"s22-08-12 12:15\",\"s22-08-12 17:00\",\"s22-08-15 02:55\",\"s22-08-15 08:55\",\"s22-08-15 20:45\",\"s22-08-15 23:35\",\"s22-08-16 10:00\",\"s22-08-16 10:00\",\"s22-08-16 10:00\",\"s22-08-16 16:00\",\"s22-08-17 02:05\",\"s22-08-17 03:50\",\"s22-08-17 07:50\",\"s22-08-17 14:10\",\"s22-08-18 09:35\",\"s22-08-18 09:35\",\"s22-08-18 11:45\",\"s22-08-18 16:30\",\"s22-08-18 17:00\",\"s22-08-19 03:10\",\"s22-08-19 03:10\",\"s22-08-19 07:20\",\"s22-08-19 11:05\",\"s22-08-22 03:55\",\"s22-08-22 09:00\",\"s22-08-22 13:00\",\"s22-08-22 15:30\",\"s22-08-22 16:50\",\"s22-08-23 01:50\",\"s22-08-23 07:55\",\"s22-08-23 09:00\",\"s22-08-23 16:20\",\"s22-08-23 16:45\",\"s22-08-23 17:00\",\"s22-08-24 03:10\",\"s22-08-24 10:20\",\"s22-08-24 13:00\",\"s22-08-25 02:05\",\"s22-08-25 15:30\",\"s22-08-25 23:00\",\"s22-08-26 02:45\",\"s22-08-26 08:10\",\"s22-08-26 09:45\",\"s22-08-26 15:35\",\"s22-08-26 15:35\",\"s22-08-26 15:35\",\"s22-08-26 17:35\",\"s22-08-26 19:40\",\"s22-08-29 07:35\",\"s22-08-29 17:05\",\"s22-08-30 02:45\",\"s22-08-30 10:35\",\"s22-08-30 10:40\",\"s22-08-30 17:40\",\"s22-08-31 07:00\",\"s22-08-31 15:25\",\"s22-09-01 04:30\",\"s22-09-01 08:50\",\"s22-09-01 13:30\",\"s22-09-01 13:30\",\"s22-09-01 13:35\",\"s22-09-01 17:00\",\"s22-09-02 10:05\",\"s22-09-02 12:55\",\"s22-09-02 19:40\",\"s22-09-05 07:45\",\"s22-09-05 08:00\",\"s22-09-05 08:25\",\"s22-09-05 11:10\",\"s22-09-05 15:40\",\"s22-09-05 23:40\",\"s22-09-06 01:00\",\"s22-09-06 15:55\",\"s22-09-06 16:00\",\"s22-09-07 01:50\",\"s22-09-07 03:15\",\"s22-09-07 12:25\",\"s22-09-07 14:05\",\"s22-09-08 01:10\",\"s22-09-08 06:05\",\"s22-09-09 03:35\",\"s22-09-09 06:55\",\"s22-09-09 14:30\",\"s22-09-12 00:40\",\"s22-09-12 09:00\",\"s22-09-13 09:10\",\"s22-09-13 09:20\",\"s22-09-13 14:10\",\"s22-09-13 21:00\",\"s22-09-14 09:35\",\"s22-09-14 22:25\",\"s22-09-15 00:00\",\"s22-09-15 03:10\",\"s22-09-15 12:10\",\"s22-09-15 13:30\",\"s22-09-15 15:05\",\"s22-09-15 15:25\",\"s22-09-15 16:20\",\"s22-09-16 08:50\",\"s22-09-16 09:15\",\"s22-09-16 13:50\",\"s22-09-19 08:35\",\"s22-09-19 09:05\",\"s22-09-19 12:50\",\"s22-09-19 16:50\",\"s22-09-19 20:05\",\"s22-09-19 22:00\",\"s22-09-20 09:00\",\"s22-09-20 12:45\",\"s22-09-20 15:25\",\"s22-09-20 16:25\",\"s22-09-21 07:55\",\"s22-09-21 09:00\",\"s22-09-21 09:00\",\"s22-09-21 09:00\",\"s22-09-21 17:30\",\"s22-09-21 17:30\",\"s22-09-21 21:00\",\"s22-09-21 23:00\",\"s22-09-22 02:10\",\"s22-09-22 09:55\",\"s22-09-22 10:35\",\"s22-09-22 16:35\",\"s22-09-23 10:00\",\"s22-09-23 16:45\",\"s22-09-26 00:05\",\"s22-09-26 03:55\",\"s22-09-26 09:00\",\"s22-09-26 10:05\",\"s22-09-26 15:45\",\"s22-09-26 18:30\",\"s22-09-27 02:55\",\"s22-09-27 08:40\",\"s22-09-27 15:55\",\"s22-09-27 16:30\",\"s22-09-27 19:05\",\"s22-09-28 01:00\",\"s22-09-28 05:05\",\"s22-09-28 05:30\",\"s22-09-28 10:55\",\"s22-09-28 13:00\",\"s22-09-28 13:00\",\"s22-09-28 13:00\",\"s22-09-28 13:00\",\"s22-09-28 22:25\",\"s22-09-29 16:00\",\"s22-09-29 16:15\",\"s22-09-29 23:55\",\"s22-09-30 07:15\",\"s22-09-30 13:25\",\"s22-09-30 13:45\",\"s22-09-30 21:55\",\"s22-10-03 00:25\",\"s22-10-03 02:00\",\"s22-10-03 07:00\",\"s22-10-03 08:40\",\"s22-10-03 23:00\",\"s22-10-04 01:10\",\"s22-10-04 02:00\",\"s22-10-04 04:50\",\"s22-10-04 14:00\",\"s22-10-04 18:25\",\"s22-10-05 01:10\",\"s22-10-05 02:00\",\"s22-10-05 03:50\",\"s22-10-05 05:00\",\"s22-10-05 09:35\",\"s22-10-05 09:45\",\"s22-10-05 09:45\",\"s22-10-05 13:10\",\"s22-10-06 11:10\",\"s22-10-06 11:40\",\"s22-10-06 16:10\",\"s22-10-06 16:20\",\"s22-10-07 03:10\",\"s22-10-07 09:10\",\"s22-10-07 09:20\",\"s22-10-07 15:30\",\"s22-10-07 15:45\",\"s22-10-07 15:45\",\"s22-10-07 17:00\",\"s22-10-07 20:00\",\"s22-10-10 03:25\",\"s22-10-10 22:00\",\"s22-10-11 11:00\",\"s22-10-11 14:20\",\"s22-10-11 14:20\",\"s22-10-11 21:55\",\"s22-10-11 21:55\",\"s22-10-12 03:00\",\"s22-10-12 07:00\",\"s22-10-13 03:00\",\"s22-10-13 09:00\",\"s22-10-13 12:25\",\"s22-10-13 14:25\",\"s22-10-13 14:30\",\"s22-10-13 18:15\",\"s22-10-14 02:35\",\"s22-10-14 02:55\",\"s22-10-14 04:40\",\"s22-10-14 10:05\",\"s22-10-14 12:25\",\"s22-10-14 14:40\",\"s22-10-14 19:55\",\"s22-10-17 01:00\",\"s22-10-17 05:00\",\"s22-10-17 08:05\",\"s22-10-17 15:40\",\"s22-10-17 19:40\",\"s22-10-18 03:00\",\"s22-10-18 06:45\",\"s22-10-19 01:55\",\"s22-10-19 09:55\",\"s22-10-19 11:10\",\"s22-10-19 17:25\",\"s22-10-20 07:15\",\"s22-10-20 11:00\",\"s22-10-20 11:30\",\"s22-10-20 15:20\",\"s22-10-20 17:15\",\"s22-10-20 19:00\",\"s22-10-21 15:05\",\"s22-10-21 18:20\",\"s22-10-24 19:35\",\"s22-10-25 05:35\",\"s22-10-25 08:10\",\"s22-10-25 08:10\",\"s22-10-25 11:35\",\"s22-10-25 11:35\",\"s22-10-25 16:15\",\"s22-10-26 01:50\",\"s22-10-26 03:50\",\"s22-10-26 09:05\",\"s22-10-26 10:15\",\"s22-10-26 15:55\",\"s22-10-26 18:40\",\"s22-10-27 00:05\",\"s22-10-27 02:50\",\"s22-10-27 07:50\",\"s22-10-27 09:30\",\"s22-10-27 09:35\",\"s22-10-27 15:30\",\"s22-10-27 21:45\",\"s22-10-28 03:05\",\"s22-10-28 08:10\",\"s22-10-28 16:05\",\"s22-10-31 10:15\",\"s22-10-31 12:30\",\"s22-10-31 13:50\",\"s22-11-01 02:15\",\"s22-11-01 03:30\",\"s22-11-01 12:25\",\"s22-11-01 12:25\",\"s22-11-01 20:00\",\"s22-11-01 22:00\",\"s22-11-02 08:15\",\"s22-11-02 10:25\",\"s22-11-02 20:00\",\"s22-11-03 08:50\",\"s22-11-03 20:15\",\"s22-11-03 20:15\",\"s22-11-03 22:10\",\"s22-11-04 09:45\",\"s22-11-04 14:20\",\"s22-11-04 14:30\",\"s22-11-04 15:00\",\"s22-11-07 07:30\",\"s22-11-07 07:30\",\"s22-11-07 09:30\",\"s22-11-07 13:30\",\"s22-11-07 15:15\",\"s22-11-08 11:00\",\"s22-11-08 13:00\",\"s22-11-08 17:40\",\"s22-11-09 05:00\",\"s22-11-09 09:55\",\"s22-11-09 11:15\",\"s22-11-09 15:20\",\"s22-11-09 19:00\",\"s22-11-10 01:20\",\"s22-11-10 15:10\",\"s22-11-10 15:20\",\"s22-11-10 15:20\",\"s22-11-10 15:30\",\"s22-11-10 15:35\",\"s22-11-10 19:30\",\"s22-11-10 23:05\",\"s22-11-11 02:30\",\"s22-11-11 12:00\",\"s22-11-11 13:30\",\"s22-11-11 14:25\",\"s22-11-11 18:50\",\"s22-11-11 20:10\",\"s22-11-14 00:05\",\"s22-11-14 03:15\",\"s22-11-14 06:00\",\"s22-11-14 06:10\",\"s22-11-14 10:10\",\"s22-11-14 15:50\",\"s22-11-14 15:50\",\"s22-11-14 19:50\",\"s22-11-15 07:05\",\"s22-11-15 09:00\",\"s22-11-15 09:20\",\"s22-11-15 19:00\",\"s22-11-16 15:30\",\"s22-11-17 04:20\",\"s22-11-17 10:00\",\"s22-11-17 11:30\",\"s22-11-17 13:35\",\"s22-11-17 15:00\",\"s22-11-17 19:00\",\"s22-11-17 19:50\",\"s22-11-18 02:00\",\"s22-11-18 08:30\",\"s22-11-18 11:20\",\"s22-11-18 15:20\",\"s22-11-18 22:00\",\"s22-11-21 02:05\",\"s22-11-21 06:35\",\"s22-11-21 10:00\",\"s22-11-21 21:25\",\"s22-11-22 01:00\",\"s22-11-22 14:25\",\"s22-11-23 03:25\",\"s22-11-23 05:55\",\"s22-11-23 06:00\",\"s22-11-23 13:30\",\"s22-11-23 16:45\",\"s22-11-25 02:10\",\"s22-11-25 04:35\",\"s22-11-25 10:00\",\"s22-11-25 15:20\",\"s22-11-25 15:30\",\"s22-11-28 03:30\",\"s22-11-28 09:10\",\"s22-11-28 19:10\",\"s22-11-29 20:15\",\"s22-11-29 23:10\",\"s22-11-30 01:40\",\"s22-11-30 11:00\",\"s22-11-30 15:55\",\"s22-11-30 21:05\",\"s22-11-30 21:15\",\"s22-12-01 02:45\",\"s22-12-02 01:10\",\"s22-12-02 01:15\",\"s22-12-02 07:40\",\"s22-12-02 07:45\",\"s22-12-02 09:40\",\"s22-12-02 15:30\",\"s22-12-05 02:15\",\"s22-12-05 05:10\",\"s22-12-05 10:10\",\"s22-12-06 06:15\",\"s22-12-06 08:20\",\"s22-12-06 12:40\",\"s22-12-06 14:00\",\"s22-12-06 17:15\",\"s22-12-06 20:30\",\"s22-12-06 20:55\",\"s22-12-07 02:30\",\"s22-12-07 08:05\",\"s22-12-07 08:05\",\"s22-12-07 08:05\",\"s22-12-07 09:35\",\"s22-12-08 03:00\",\"s22-12-08 05:10\",\"s22-12-08 08:15\",\"s22-12-08 10:55\",\"s22-12-08 15:25\",\"s22-12-08 17:05\",\"s22-12-08 17:35\",\"s22-12-08 20:50\",\"s22-12-09 14:25\",\"s22-12-09 15:20\",\"s22-12-09 15:30\",\"s22-12-09 15:30\",\"s22-12-09 17:35\",\"s22-12-12 01:05\",\"s22-12-12 09:00\",\"s22-12-12 09:25\",\"s22-12-12 16:35\",\"s22-12-12 20:30\",\"s22-12-13 05:50\",\"s22-12-13 15:30\",\"s22-12-13 15:30\",\"s22-12-13 15:30\",\"s22-12-14 02:25\",\"s22-12-14 07:15\",\"s22-12-14 08:45\",\"s22-12-14 10:50\",\"s22-12-15 10:00\",\"s22-12-15 17:00\",\"s22-12-16 10:25\",\"s22-12-19 00:05\",\"s22-12-19 11:05\",\"s22-12-19 18:45\",\"s22-12-20 01:30\",\"s22-12-20 04:00\",\"s22-12-20 07:20\",\"s22-12-21 08:50\",\"s22-12-21 13:30\",\"s22-12-21 14:20\",\"s22-12-21 18:25\",\"s22-12-21 18:25\",\"s22-12-22 02:00\",\"s22-12-22 08:20\",\"s22-12-22 11:15\",\"s22-12-22 16:30\",\"s22-12-23 06:00\",\"s22-12-23 13:15\",\"s22-12-23 15:30\",\"s22-12-23 17:30\",\"s22-12-27 00:30\",\"s22-12-27 01:10\",\"s22-12-27 03:50\",\"s22-12-27 08:50\",\"s22-12-27 08:50\",\"s22-12-27 10:00\",\"s22-12-28 01:00\",\"s22-12-28 09:25\",\"s22-12-28 12:45\",\"s22-12-28 22:50\",\"s22-12-29 08:35\",\"s22-12-29 10:05\",\"s22-12-29 11:55\",\"s22-12-30 00:20\",\"s22-12-30 06:00\",\"s22-12-30 08:30\",\"s22-12-30 09:55\",\"s22-12-30 10:00\",\"s22-12-30 15:20\",\"s22-12-30 15:30\",\"s22-12-30 16:15\",\"s23-01-03 09:50\",\"s23-01-03 10:00\",\"s23-01-03 10:00\",\"s23-01-03 10:05\",\"s23-01-03 10:30\",\"s23-01-03 13:15\",\"s23-01-03 22:00\",\"s23-01-04 09:10\",\"s23-01-04 09:40\",\"s23-01-04 17:05\",\"s23-01-05 02:50\",\"s23-01-05 04:00\",\"s23-01-05 15:15\",\"s23-01-05 22:00\",\"s23-01-06 09:40\",\"s23-01-06 11:10\",\"s23-01-06 15:30\",\"s23-01-09 01:00\",\"s23-01-09 17:35\",\"s23-01-09 17:35\",\"s23-01-09 19:15\",\"s23-01-09 21:00\",\"s23-01-10 02:50\",\"s23-01-10 09:10\",\"s23-01-10 11:00\",\"s23-01-11 06:40\",\"s23-01-11 06:40\",\"s23-01-11 10:50\",\"s23-01-12 09:15\",\"s23-01-12 11:10\",\"s23-01-12 11:25\",\"s23-01-12 11:50\",\"s23-01-13 00:05\",\"s23-01-13 03:35\",\"s23-01-13 04:15\",\"s23-01-16 03:55\",\"s23-01-16 08:05\",\"s23-01-16 09:30\",\"s23-01-16 19:00\",\"s23-01-17 02:10\",\"s23-01-17 03:35\",\"s23-01-17 09:40\",\"s23-01-17 13:40\",\"s23-01-18 04:40\",\"s23-01-18 08:10\",\"s23-01-18 11:45\",\"s23-01-18 13:35\",\"s23-01-18 13:35\",\"s23-01-18 15:30\",\"s23-01-19 09:55\",\"s23-01-19 13:50\",\"s23-01-19 17:00\",\"s23-01-23 02:50\",\"s23-01-23 11:00\",\"s23-01-23 12:30\",\"s23-01-23 20:50\",\"s23-01-24 03:40\",\"s23-01-24 07:25\",\"s23-01-24 11:45\",\"s23-01-24 22:10\",\"s23-01-25 08:20\",\"s23-01-25 09:40\",\"s23-01-25 09:40\",\"s23-01-25 09:45\",\"s23-01-25 09:45\",\"s23-01-26 01:00\",\"s23-01-26 06:00\",\"s23-01-26 09:15\",\"s23-01-26 10:20\",\"s23-01-26 17:35\",\"s23-01-27 01:20\",\"s23-01-27 03:05\",\"s23-01-27 10:00\",\"s23-01-27 15:00\",\"s23-01-30 01:50\",\"s23-01-30 09:15\",\"s23-01-30 19:15\",\"s23-01-30 21:10\",\"s23-01-31 02:30\",\"s23-01-31 06:30\",\"s23-01-31 09:10\",\"s23-01-31 10:15\",\"s23-01-31 13:25\",\"s23-01-31 17:05\",\"s23-01-31 17:10\",\"s23-02-01 13:00\",\"s23-02-01 15:45\",\"s23-02-01 18:15\",\"s23-02-01 21:00\",\"s23-02-01 21:00\",\"s23-02-02 19:50\",\"s23-02-02 21:45\",\"s23-02-03 01:00\",\"s23-02-03 06:00\",\"s23-02-03 11:35\",\"s23-02-03 14:45\",\"s23-02-03 15:30\",\"s23-02-03 19:40\",\"s23-02-06 17:35\",\"s23-02-07 03:00\",\"s23-02-07 17:45\",\"s23-02-08 07:05\",\"s23-02-08 09:25\",\"s23-02-08 09:55\",\"s23-02-08 11:00\",\"s23-02-08 16:50\",\"s23-02-08 22:10\",\"s23-02-09 10:10\",\"s23-02-09 20:40\",\"s23-02-10 10:00\",\"s23-02-10 12:05\",\"s23-02-10 12:05\",\"s23-02-10 17:45\",\"s23-02-14 01:55\",\"s23-02-14 09:00\",\"s23-02-14 15:30\",\"s23-02-15 08:30\",\"s23-02-15 09:00\",\"s23-02-15 18:40\",\"s23-02-15 23:10\",\"s23-02-16 02:30\",\"s23-02-16 08:35\",\"s23-02-16 10:05\",\"s23-02-16 21:05\",\"s23-02-17 02:25\",\"s23-02-17 08:10\",\"s23-02-17 08:25\",\"s23-02-17 19:25\",\"s23-02-20 15:35\",\"s23-02-21 01:25\",\"s23-02-21 01:25\",\"s23-02-21 02:05\",\"s23-02-21 03:10\",\"s23-02-21 09:00\",\"s23-02-21 09:05\",\"s23-02-21 09:20\",\"s23-02-21 11:20\",\"s23-02-21 11:30\",\"s23-02-21 13:45\",\"s23-02-21 15:10\",\"s23-02-22 03:05\",\"s23-02-22 10:25\",\"s23-02-22 10:35\",\"s23-02-22 17:35\",\"s23-02-22 18:10\",\"s23-02-22 21:00\",\"s23-02-23 00:10\",\"s23-02-23 10:05\",\"s23-02-23 17:45\",\"s23-02-24 05:00\",\"s23-02-24 16:00\",\"s23-02-24 16:25\",\"s23-02-24 23:00\",\"s23-02-27 02:55\",\"s23-02-27 05:30\",\"s23-02-27 05:40\",\"s23-02-27 10:00\",\"s23-02-27 10:00\",\"s23-02-27 13:15\",\"s23-02-27 15:30\",\"s23-02-27 15:45\",\"s23-02-27 19:55\",\"s23-02-28 05:00\",\"s23-02-28 06:25\",\"s23-02-28 15:00\",\"s23-02-28 18:10\",\"s23-03-01 09:45\",\"s23-03-01 12:40\",\"s23-03-02 14:50\",\"s23-03-02 14:50\",\"s23-03-03 08:05\",\"s23-03-03 17:00\",\"s23-03-06 02:10\",\"s23-03-06 04:05\",\"s23-03-06 15:20\",\"s23-03-07 01:00\",\"s23-03-07 10:20\",\"s23-03-07 12:25\",\"s23-03-07 17:00\",\"s23-03-08 02:05\",\"s23-03-08 04:50\",\"s23-03-08 14:10\",\"s23-03-08 17:00\",\"s23-03-08 19:00\",\"s23-03-09 07:10\",\"s23-03-09 10:30\",\"s23-03-09 10:40\",\"s23-03-09 12:00\",\"s23-03-10 04:25\",\"s23-03-10 04:30\",\"s23-03-10 09:00\",\"s23-03-10 09:30\",\"s23-03-10 11:40\",\"s23-03-13 00:05\",\"s23-03-13 04:25\",\"s23-03-13 12:25\",\"s23-03-13 16:40\",\"s23-03-14 01:55\",\"s23-03-14 08:10\",\"s23-03-14 14:30\",\"s23-03-15 11:30\",\"s23-03-15 12:35\",\"s23-03-15 16:00\",\"s23-03-16 02:05\",\"s23-03-16 06:10\",\"s23-03-16 11:15\",\"s23-03-17 03:10\",\"s23-03-17 05:40\",\"s23-03-17 09:00\",\"s23-03-17 15:00\",\"s23-03-20 03:40\",\"s23-03-20 09:00\",\"s23-03-20 10:50\",\"s23-03-20 12:55\",\"s23-03-21 05:30\",\"s23-03-21 15:05\",\"s23-03-21 15:40\",\"s23-03-22 00:55\",\"s23-03-22 09:00\",\"s23-03-22 16:00\",\"s23-03-22 19:30\",\"s23-03-22 19:35\",\"s23-03-22 20:35\",\"s23-03-23 02:50\",\"s23-03-23 07:05\",\"s23-03-23 14:45\",\"s23-03-23 19:20\",\"s23-03-23 20:55\",\"s23-03-24 03:45\",\"s23-03-24 10:05\",\"s23-03-24 21:20\",\"s23-03-24 21:20\",\"s23-03-27 09:10\",\"s23-03-27 11:30\"],\"y\":[97.0,97.13302857142857,94.2190377142857,91.39246658285712,88.6506925853714,85.99117180781026,91.06640586634461,88.33441369035427,85.68438127964363,83.11384984125432,80.6204343460167,80.94054489415541,78.51232854733074,82.96611882128907,89.75274734087049,87.06016492064437,84.44835997302503,81.91490917383427,86.95115914526274,92.29069511531011,92.62128865005154,98.76231358659665,95.79944417899874,102.66952384123766,102.82994497223996,99.74504662307275,96.75269522438057,102.6771410826396,99.5968268501604,106.3415825508219,103.15133507429724,111.58480686498748,108.23726265903785,104.99014477926671,101.84044043588871,107.39537355057381,114.41120215915768,121.7187563615807,129.58801549379507,125.70037502898121,135.60495879632538,131.53681003243562,127.59070573146255,123.76298455951867,131.3707680221483,127.42964498148385,135.2472389320325,131.18982176407152,141.68500750519658,137.43445728004068,133.31142356163946,129.31208085479028,125.43271842914658,121.66973687627217,118.019644769984,130.62722160476017,138.84305691842317,134.67776521087046,130.63743225454434,138.8225032312023,134.65782813426623,130.61809329023822,138.21026996273704,147.60856832020207,143.180311270596,138.88490193247813,134.71835487450377,130.67680422826865,138.1412947428586,133.99705590057283,129.97714422355565,126.07782989684898,122.29549499994351,129.58081234494097,125.69338797459274,121.92258633535495,129.18873509049772,136.06803523406808,131.98599417704602,139.8491880350845,135.65371239403197,131.584101022211,127.63657799154467,135.2162270845805,131.15974027204308,127.22494806388178,123.40819962196532,119.70595363330636,116.11477502430716,123.11657354052798,130.71942168579025,126.79783903521654,134.4665723400648,130.43257516986284,126.51959791476696,122.72400997732395,129.95699591968838,126.05828604209772,122.27653746083479,118.60824133700974,125.71465579672025,121.94321612281864,118.28491963913407,124.84246957000508,132.17135123684847,128.206210699743,124.36002437875071,120.62922364738819,117.01034693796653,123.93783706994715,120.21970195784873,116.61311089911327,113.11471757213987,109.72127604497567,119.26030943174284,126.54843945257244,122.75198626899527,119.0694266809254,115.49734388049764,112.0324235640827,120.32759024499668,116.71776253764678,123.94617446510156,131.34753174030348,127.40710578809437,123.58489261445153,130.90526782296388,126.97810978827496,123.16876649462671,119.4737034997879,115.88949239479426,112.41280762295042,109.04042339426191,105.76921069243404,112.29164535180198,108.92289599124791,105.65520911151047,102.48555283816516,99.4109862530202,96.42865666542959,93.5357969654667,93.55861057448264,90.75185225724816,88.02929668953071,85.38841778884479,82.82676525517944,80.34196229752405,77.93170342859833,75.59375232574037,81.20964054909143,78.77335133261869,83.83312768784023,89.10549158184108,86.43232683438585,93.21246269495015,99.52798088930862,96.54214146262936,102.96470145798432,99.87576041424478,96.87948760181743,93.9731029737629,91.15390988455002,96.63327268983271,93.73427450913772,90.92224627386359,99.27539533212304,96.29713347215935,102.58942561821716,99.51174284967064,105.66958890720409,102.49950123998796,107.9569071168201,104.7181999033155,101.57665390621602,98.52935428902954,95.57347366035866,92.7062694505479,89.92508136703145,87.2273289260205,91.58869537232225,88.84103451115259,86.175803475818,83.59052937154345,84.0920725477727,89.30369180169606,86.62458104764518,84.02584361621582,81.50506830772935,82.10541254488095,87.04476990273974,84.43342680565755,81.90042400148782,79.44341128144319,77.06010894299989,74.7483056747099,72.5058565044686,70.33068080933454,74.93581147450236,72.68773713026728,70.50710501635926,74.7169285918492,72.47542073409372,70.30115811207091,70.602758759527,68.48467599674119,66.43013571683895,66.85287294412797,67.49354630984251,65.46873992054724,63.504677722930815,61.59953739124289,65.61641740436053,63.64792488222972,72.90828820200507,77.2073631270202,78.93996930742999,84.01043943629948,89.01847554579959,95.16010216567666,92.30529910070636,89.53614012768517,86.85005592385461,84.24455424613897,81.7172176187548,87.33034511863652,84.71043476507742,82.1691217221251,88.13094799818606,88.77548776712813,86.11222313411427,83.52885644009085,88.60971515596326,97.87345810408999,94.93725436096729,92.08913673013826,89.32646262823411,86.64666874938709,91.5038334375674,88.75871843444037,86.09595688140716,83.51307817496495,81.007685829716,86.00835258958921,86.04454848947663,83.46321203479232,80.95931567374855,78.53053620353609,83.52714944110247,81.02133495786939,78.5906949091333,83.24038343264239,88.3332187145805,93.55357921958247,99.3053918678961,105.23005253526867,102.07315095921061,108.27777218782342,105.02943902218871,101.87855585152305,110.91848404679914,117.48970516049737,124.64125243113817,120.90201485820403,117.2749544124579,113.75670578008416,110.34400460668164,107.03368446848118,103.82267393442675,110.11058099113244,116.95808274651813,113.44934026412258,110.0458600561989,116.50188384616165,123.49199687693066,119.78723697062273,116.19361986150405,116.2878309046349,112.79919597749586,109.41522009817098,106.13276349522584,102.94878059036907,109.2331322403204,105.95613827311078,102.77745412491745,99.69413050116992,96.70330658613483,93.80220738855078,100.3442327205687,97.33390573895163,94.41388856678307,91.58147190977958,88.8340277524862,86.16900691991161,83.58393671231426,89.0971553192988,89.3181715185404,94.61691169376192,91.77840434294906,89.02505221266058,86.35430064628076,92.40765162227716,92.93717861471941,98.34612241009745,95.39573873779453,92.5338665756607,89.75785057839087,102.37811387954251,99.30677046315623,107.95941255046817,114.52722201367814,111.09140535326779,107.75866319266976,113.81726215818756,110.40274429344193,107.09066196463867,113.40752069324851,125.47579270664576,121.71151892544638,118.06017335768298,114.51836815695249,122.13492000135382,129.88876721129913,125.99210419496015,133.01166428582314,129.02131435724846,125.150674926531,133.21283670862957,129.2164516073707,125.33995805914957,121.57975931737508,117.93236653785382,114.39439554171821,110.96256367546667,107.63368676520267,104.40467616224659,110.99173454759803,114.32148658402967,110.89184198650878,107.56508672691352,114.87139450459232,121.00720801593492,117.37699177545687,124.36782731502437,126.5593574759638,133.60697659815446,129.59876730020983,125.71080428120354,121.93948015276743,118.2812957481844,114.73285687573888,111.29087116946671,118.49318868357844,114.93839302307109,120.2383300346913,116.63118013365056,113.13224472964104,109.73827738775181,116.4060705464204,112.91388843002778,120.03237270061679,116.43140151959828,121.44301401979803,128.70067985764766,136.88080781470114,132.7743835802601,128.7911520728523,124.92741751066673,132.2161275752473,145.04648852668274,140.69509387088226,151.21831596040542,146.68176648159326,157.36858089668254,183.58071278429728,178.07329140076834,172.7310926587453,167.54915987898292,175.89310804095606,170.61631479972738,165.49782535573556,160.5328905950635,155.7169038772116,151.04539676089524,160.3339100771712,155.52389277485605,150.85817599161035,161.0205313015896,156.1899153625419,151.50421790166564,146.95909136461566,153.18887893333473,148.59321256533468,144.13541618837465,139.8113537027234,135.6170130916417,143.50785012726055,139.20261462344274,135.02653618473946,143.91305770111904,139.59566597008546,135.4077959909829,131.3455621112534,127.4051952479158,123.58303939047832,119.87554820876397,116.27928176250106,123.62210307380023,119.91343998158622,128.8517448620552,140.99951478429128,162.81733444038812,157.93281440717647,153.19482997496118,148.59898507571233,144.14101552344096,139.81678505773772,135.62228150600558,145.44933862496504,154.33593846046702,163.01430484300792,158.12387569771766,166.52940803743869,161.53352579631553,156.68752002242607,165.51150141316438,160.54615637076944,170.2402809720112,165.13307254285084,160.1790803665653,168.15395372949695,181.4140940807434,175.9716712583211,187.6210693702235,181.9924372891168,192.48376602695998,186.7092530461512,199.18002202319823,211.22067899362273,204.88405862381404,198.73753686509963,192.77541075914664,204.83942033568874,198.69423772561808,192.73341059384953,186.95140827603404,198.1118408306939,192.16848560577307,186.4034310375999,180.81132810647188,191.75573143715178,210.32448264593805,204.0147481665599,197.89430572156311,191.9574765499162,186.19875225341872,180.61278968581615,175.19440599524165,169.9385738153844,187.43544937541725,181.81238589415472,176.35801431733006,186.9161879498083,198.16225434124337,209.10334051178725,202.83024029643363,196.74533308754062,209.61932118740012,203.33074155177812,197.23081930522477,197.52879392431905,191.60293010658947,191.90904129670034,186.15177005779933,180.56721695606535,197.97082318608733,192.0316984905047,203.75179825388201,215.82736354489256,235.92163532321203,237.67419604275614,230.54397016147345,249.5889068269844,250.28543400882782,263.45113355121134,255.547599544675,247.88117155833473,240.44473641158467,256.8946750855962,249.1878348330283,264.22186103051905,256.29520519960346,248.60634904361535,263.1601790605459,281.8539503516692,273.3983318411191,290.53309857928156,281.8171056219031,273.362592453246,265.16171467964864,257.2068632392592,249.4906573420814,242.00593762181893,234.74575949316434,248.7878885859929,263.3952917586856,255.493433005925,272.7226348746615,264.5409558284216,256.60472715356894,248.90658533896186,265.23077432696584,265.6116908645628,281.2352256940208,272.7981689232002,264.6142238555042,256.67579713983906,248.97552322564388,264.89685273717606,256.9499471550608,249.24144874040894,241.76420527819667,256.1393742406861,248.4551930134655,241.00153722306152,242.64034767617832,235.36113724589296,228.30030312851616,221.45129403466066,214.80775521362085,229.30727869054382,235.42213945562497,228.35947527195623,221.50869101379755,214.86343028338362,208.4175273748821,202.16500155363562,196.10005150702654,207.63444036338626,219.00242597328307,232.32121399395507,225.3515775741364,238.7645034713495,253.61524392433043,272.00234910886786,286.62519539696245,278.02643953505356,294.6311522372396,285.7922176701224,277.2184511400187,268.90189760581814,269.98406377911033,270.2411914589016,262.13395571513456,277.73911776629495,269.4069442333061,285.335956761279,276.77587805844064,268.4726017166874,260.41842366518676,275.6715027655983,267.40135768263036,283.8723326636145,285.6132071898941,303.4594846582561,322.00113757407274,312.3411034468505,331.31979591900307,355.8109552333361,345.13662657633597,334.7825277790459,324.73905194567453,314.9968803873043,305.5469739756852,327.1849097703765,317.3693624772652,307.8482816029472,325.5721936981798,315.80502788723436,306.33087705061735,327.0874347542209,317.2748117115943,307.75656736024644,298.52387033943904,289.56815422925587,307.99877593763324,298.75881265950426,289.7960482797191,281.1021668313275,272.6691018263877,264.48902877159605,256.55435790844814,248.85772717119468,241.39199535605883,255.61688079668318,276.2934462655715,293.0036738957138,284.2135636788424,275.6871567684771,291.33080008278534,282.59087608030177,300.8986040030509,318.54746443015665,308.99104049725196,299.7213092823344,290.7296700038644,282.0077799037484,273.54754650663597,275.99807661075766,292.5043114732884,310.7473435309653,301.4249232250363,292.3821755282852,283.6107102624366,275.1023889545635,266.8493172859266,258.84383776734876,251.0785226343283,243.54616695529845,258.39956641900994,250.64757942643965,243.12815204364645,235.83430748233704,228.75927825786692,241.92839346568715,255.61462829603167,272.7962719432876,264.61238378498894,256.67401227143927,248.97379190329607,241.5045781461972,253.70055934258363,273.1509355588583,288.14247527790593,279.49820101956874,271.1132549889817,262.9798573393122,294.70010817302233,285.85910492783165,277.2833317799967,292.635857429286,283.8567817064074,284.8152591511309,302.44301437967573,293.36972394828547,310.2849929095976,310.3345064722952,301.0244712781263,318.2359881064984,308.68890846330345,327.36809525384194,346.52903477720207,433.8543515410543,420.83872099482267,408.213559364978,434.42791253825794,421.3950751621102,446.7980424289562,433.3941011560875,420.3922781214049,449.32892427026854,451.8954910857003,477.34919629787584,463.02872040893953,449.1378587966713,435.66372303277114,461.66209715401214,488.4682834403732,514.3745477585461,498.9433113257897,483.975011986016,469.4557616264355,498.4278886296666,528.1512102808737,561.6255827634661,544.7768152805621,528.4335108221452,512.5805054974808,497.2030903325563,482.28699762257963,509.7367902910071,540.0318612938077,573.4543056227039,556.2506764540228,589.9184805551861,623.8896482285405,667.1771458479172,647.1618314724797,627.7469765283053,608.9145672324561,590.6471302154824,572.9277163090179,605.2998897274653],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"rangeslider\":{\"visible\":false},\"gridcolor\":\"#1f292f\",\"nticks\":5},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"gridcolor\":\"#1f292f\"},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"gridcolor\":\"#1f292f\"},\"margin\":{\"l\":10,\"r\":10,\"b\":10,\"t\":10},\"font\":{\"size\":8,\"color\":\"#e1e1e1\"},\"width\":1400,\"height\":600,\"paper_bgcolor\":\"#2c303c\",\"plot_bgcolor\":\"#2c303c\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e95c0ff1-a346-4c28-a630-91fcf6e86435');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res_m5_plot = df_res_m5#.loc[:100]\n",
    "df_res_m5_plot['time'] = df_res_m5_plot['end_time']\n",
    "cp = CandlePlot(df_res_m5_plot, candles=False)\n",
    "print(\"min balance \",min(df_res_m5['balance']))\n",
    "cp.show_plot(line_traces=['balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efad8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718cddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31420dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
